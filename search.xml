<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>新安装ChromeOS之后需要做的事情</title>
      <link href="/2020/03/03/chromeos-setup/"/>
      <url>/2020/03/03/chromeos-setup/</url>
      
        <content type="html"><![CDATA[<p>最近“被迫”研究ChromeOS——这个东东在国内往实在是太痛苦了！！不管怎么样，把最近玩ChromeOS的过程记个流水账。防止自己遗忘，也给国内同样想玩ChromeOS的玩家提供点参考——国内可以搜到的东西实在是太少了。<br>下面所有的步骤，都默认读者是可以无障碍访问互联网的，对于GFW这件事情，这篇文章基本上帮不上忙，因为我自己没有找到一个完美解决的办法。</p><h2 id="安装ChromeOS"><a href="#安装ChromeOS" class="headerlink" title="安装ChromeOS"></a>安装ChromeOS</h2><h3 id="从源码使用cros-sdk编译"><a href="#从源码使用cros-sdk编译" class="headerlink" title="从源码使用cros_sdk编译"></a>从源码使用cros_sdk编译</h3><p>这个不多说了，再华丽的描述都不及Google的<a href="https://chromium.googlesource.com/chromiumos/docs/+/master/developer_guide.md" target="_blank" rel="noopener">官方文档</a>非常的详细。</p><h3 id="Google-partner账户"><a href="#Google-partner账户" class="headerlink" title="Google partner账户"></a>Google partner账户</h3><p>另外，如果不想自己编译，可以选择下载Google的<a href="https://www.google.com/chromeos/partner/fe/#release" target="_blank" rel="noopener">FE built</a></p><h2 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h2><p>登录时须要有网络，或许是因为ChromeOS的bug，在登录时的网络窗口是无法设置代理的。还是那么那句话，没有办法解决网络的问题。</p><h2 id="配置开始"><a href="#配置开始" class="headerlink" title="配置开始"></a>配置开始</h2><p>上面都是准备工作，这里我们正式开始配置ChromeBook了。</p><h3 id="安装Linux-Beta"><a href="#安装Linux-Beta" class="headerlink" title="安装Linux Beta"></a>安装Linux Beta</h3><p>点“开始”(或许ChromeOS里左下角那个按钮不叫“开始”)，输入Linux 或者 Terminal 出现一个终端的图标，点它。<br>这是ChromeOS会联网下载Guest的镜像或者是镜像里的容器。</p><p>大概过10分钟，就会弹出来一个类似Linux下terminal的窗口，可以输入命令了 ———— 这就是Linux 虚拟机，基于CrosVM的虚拟机。</p><h3 id="安装Chromebrew"><a href="#安装Chromebrew" class="headerlink" title="安装Chromebrew"></a>安装Chromebrew</h3><p>使用CTRL+ALT+F2 切换到终端；或者打开浏览器 CTRL+ALT+T 输入shell 都可以通过终端操作ChromeOS。但此时你会惊讶的发现，其实啥装不了。官方的安装需要通过cros_sdk 来编译(emerge)和部署(deploy)，但这样不够灵活，也非常的慢。<br>强烈推荐<a href="http://skycocker.github.io/chromebrew/" target="_blank" rel="noopener">Chromebrew</a> <a href="https://github.com/skycocker/chromebrew.git" target="_blank" rel="noopener">git</a></p><p>安装方法也很简单，切换到chronos用户，然后输入<br><code>curl -Ls http://skycocker.github.io/chromebrew/</code><br>然后等就好了。<br>然后需要安装软件大概有：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crew install vim</span><br><span class="line">crew install git</span><br></pre></td></tr></table></figure></p><h3 id="安装Crouton"><a href="#安装Crouton" class="headerlink" title="安装Crouton"></a>安装Crouton</h3><p><a href="https://github.com/dnschneid/crouton.git" target="_blank" rel="noopener">Crouton</a>是Chrome下的一个choot，可以让用户在ChromeOS里安装Linux Distribution的文件系统，比如Ubuntu Debain 等，对于想在ChromeOS的Host环境里做点hack事情的玩家，还是很方便的！<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/dnschneid/crouton.git</span><br><span class="line">./installer/crouton    # 查看help</span><br><span class="line">./installer/crouton -r help  #列出所有的可以用的&apos;release&apos;</span><br><span class="line">./installer/crouton -t help  #列出所有的可以用的&apos;target&apos;</span><br></pre></td></tr></table></figure></p><p>通常我这样安装:<br>注意，需要在桌面环境的shell里面运行，而不是CTRL+ALT+F2的VT！！<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./installer/crouton -r buster -t xfce</span><br></pre></td></tr></table></figure></p><p>然后就是等就好了 :) 中间会让输入一个常用用户名和密码，结束之后这样用：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">enter-chroot    #进入chroot环境</span><br><span class="line">startxfce4      #启动桌面</span><br></pre></td></tr></table></figure></p><p>好了现在就看像使用Debian一样，使用Chromebook了。<br>如果想要退出chroot的环境，使用快捷键 CTRL+ALT+SHIFT+F1，回到native的桌面</p><h3 id="读写分区"><a href="#读写分区" class="headerlink" title="读写分区"></a>读写分区</h3><p>默认的ChromeOS的分区是只读的，这样给他重新挂载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mount -o remount,rw /</span><br><span class="line">mount -o remount,exec /mnt/stateful_partition/</span><br></pre></td></tr></table></figure></p><h3 id="清空iptable规则"><a href="#清空iptable规则" class="headerlink" title="清空iptable规则"></a>清空iptable规则</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">iptables -F</span><br><span class="line">iptables -P INPUT ACCEPT</span><br><span class="line">iptables -P OUTPUT ACCEPT</span><br><span class="line">iptables -P FORWARD ACCEPT</span><br></pre></td></tr></table></figure><h3 id="安装pip3"><a href="#安装pip3" class="headerlink" title="安装pip3"></a>安装pip3</h3><p><code>crew install python3-pip 或者 python2-pip</code></p><h3 id="安装paramiko-–-python的一个包"><a href="#安装paramiko-–-python的一个包" class="headerlink" title="安装paramiko – python的一个包"></a>安装paramiko – python的一个包</h3><p><code>pip3 install paramiko</code></p><h3 id="Chroot中-安装apitrace"><a href="#Chroot中-安装apitrace" class="headerlink" title="Chroot中 安装apitrace"></a>Chroot中 安装apitrace</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/apitrace/apitrace.git</span><br><span class="line">sudo apt install libx11-dev automake gcc cmake</span><br><span class="line">cmake .</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>至此，基本上，一个ChromeBook已经可以用起来了。如果谁还有那些新奇好玩的用法，欢迎留言</p><h2 id="安装其他benchmark"><a href="#安装其他benchmark" class="headerlink" title="安装其他benchmark"></a>安装其他benchmark</h2><h3 id="glmark2"><a href="#glmark2" class="headerlink" title="glmark2"></a>glmark2</h3><p>source code: <a href="https://github.com/glmark2/glmark2.git" target="_blank" rel="noopener">https://github.com/glmark2/glmark2.git</a></p><p>Chroot 中编译：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install libx11-dev libjpeg-dev libpng*</span><br><span class="line"></span><br><span class="line">./waf configure --with-flavors x11-gl</span><br><span class="line">sudo ./waf install</span><br></pre></td></tr></table></figure></p><p>VM 中编译：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">apt install libjpeg-dev pkg-config libpng* libdrm-dev libgbm-dev libwayland-client0 libudev-dev libx11-dev</span><br><span class="line"></span><br><span class="line">./waf configure --with-flavors x11-gl</span><br><span class="line">sudo ./waf install</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> ChromeOS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ChromeOS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>春城外来车辆管理系统</title>
      <link href="/2020/02/27/chuncheng-parking/"/>
      <url>/2020/02/27/chuncheng-parking/</url>
      
        <content type="html"><![CDATA[<p>许久没更新了，刚好由于新冠肺炎，让我有一段完整的时间可以学点新东西，然后顺手帮小区居委、业委、物业做了套关于外来车辆管理的小系统。<br>把项目的来龙去脉、实现过程做个流水账，防止自己遗忘。</p><h2 id="项目的由来（需求）"><a href="#项目的由来（需求）" class="headerlink" title="项目的由来（需求）"></a>项目的由来（需求）</h2><p>几年前搬到春城，小区真如名字般美好，小区内部特有的商业街更是给日常生活增添了不少便利。但随之而来的问题也比较烦，就是外来车辆（包括业主访客、商业街工作人员、外来消费等等）让小区变的越来越拥挤，于是新的外来车辆管理规则成了当务之急。这里要感谢新来的居委孙书记，大刀阔斧的变革，到任几个月就制定了新的外来车辆规则以及定价规范，同时已经线上线下与业主以及商铺充分沟通讨论。为了配合新的外车收费规则，于是有了这个项目。</p><h2 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h2><h3 id="用户页面"><a href="#用户页面" class="headerlink" title="用户页面"></a>用户页面</h3><ol><li>注册申请、登录</li><li>1小时停车优惠券申请、直系亲属车优惠券申请</li></ol><h3 id="管理员页面"><a href="#管理员页面" class="headerlink" title="管理员页面"></a>管理员页面</h3><ol><li>登录</li><li>用户申请订单的审批、打印</li><li>用户权限、信息显示、修改</li></ol><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><h3 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h3><ol><li>Ant-design </li></ol>]]></content>
      
      
      <categories>
          
          <category> 业余 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ant-design antd TS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>QEMU虚拟机网络模拟</title>
      <link href="/2019/12/26/network-in-vm/"/>
      <url>/2019/12/26/network-in-vm/</url>
      
        <content type="html"><![CDATA[<p>当我们创建和使用虚拟机时，通常都伴随着虚拟机的联网问题。下面就帮大家梳理下QEMU虚拟机中几种网络的模拟和用法。</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>QEMU可以模拟多种网卡设备(例如PCI或者ISA设备)，同时可将这些虚拟网卡与host上的虚拟网络设备(或者虚拟的hub)连接起来。各种不同类型的网络设备既可以为虚拟机提供真实的网络访问(例如TAP、SLiRP user模式)，也可以是同一个host上面的不同虚拟机之间的访问(Socket)。<br>常见的网络设备实现有4种：</p><ol><li>User模式: <code>-net user</code> (如果没有指定<code>-net xx</code>这是默认配置)。</li><li>TAP(Terminal Access Point): 这是QEMU推荐的虚拟机联网的虚拟网络设备的后端实现。可以认为虚拟网卡直接与其相连。TAP接口的行为应该与真实的网络设备一样，一旦将TAP绑定到“网桥”(bridge)上之后，他们就可以网络通信了。</li><li>Hubs: hub实现将多个网络设备连接起来，比如QEMU的虚拟网卡(TAP设备)，将虚拟机中的多个网卡相连，或者host的网络设备通过参数<code>-netdev hubport</code>或者<code>-nic hubport</code>相连。</li><li>Socket: 通过参数<code>-netdev socket</code> (或<code>-nic socket</code>或<code>-net socket</code>) 可以实现多个虚拟机之间的互联。</li></ol><p>对于虚拟机上网，以上四种QEMU网络相关的模拟，这里暂时只关心前两个(3、4实际还没有用到过:p,如有必要日后补充)，User模式以及TAP接口。下面详细介绍下如何使用这两种方式搭建不同类型的网络供虚拟机使用。</p><h2 id="NAT方式"><a href="#NAT方式" class="headerlink" title="NAT方式"></a>NAT方式</h2><p>如图所示，NAT方式与家里上网的方式有点类似，虚拟机在一个子网内(192.168.122.255)，宿主机看做双网卡(虚拟了一个网卡),这也是QEMU默认就支持的。</p><h3 id="QEMU默认的NAT-SLiRP"><a href="#QEMU默认的NAT-SLiRP" class="headerlink" title="QEMU默认的NAT (SLiRP)"></a>QEMU默认的NAT (SLiRP)</h3><p>首先，在我们没有为QEMU指定任何网络参数的情况下，我们很多时候依然可以使用网络，拓扑结构如下图所示：<br><img src="/2019/12/26/network-in-vm/network-nat1.png" alt=""><br>  这是因为通常在编译QEMU的时候，默认会编译模块<code>SLiRP</code>(除非显式的指定<code>--disable-slirp</code>)，这样QEMU在创建虚拟机的时候，即便用户不指定，也会有默认的参数<code>-net=user</code>。user mode的NAT网络优缺点很明显：</p><ol><li>设置最为简单，不需要额外的配置就能满足虚拟机最基本的网络需求。</li><li>缺点是这个NAT网络也仅仅是“最基本“的需求。slirp模块有许多网络协议不支持，最常见的ICMP不支持，所以，在虚拟机中是无法使用<code>ping</code>的；另外，performance大概就更不需要奢求太多。</li></ol><h3 id="通过TAP配置NAT"><a href="#通过TAP配置NAT" class="headerlink" title="通过TAP配置NAT"></a>通过TAP配置NAT</h3><p>拓扑结构跟user模式一模一样，见下图：<br><img src="/2019/12/26/network-in-vm/network-nat.png" alt=""></p><ol><li><p>确保已安装libvirt-clients和libvirt-daemon</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Ubuntu:</span><br><span class="line">apt-get install libvirt-clients//使用virsh</span><br><span class="line">apt-get install libvirt-daemon//使用libvirtd</span><br><span class="line">apt-get install qemu-system-common//使用qemu-bridge-helper</span><br></pre></td></tr></table></figure><p>确保libvirt-daemon服务开启</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start libvirtd</span><br><span class="line">systemctl enable libvirtd</span><br></pre></td></tr></table></figure><p>如果libvirtd启动成功的话会出现一个虚拟桥virbr0和virbr0-nic：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#ip a</span><br><span class="line"></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span><br><span class="line">    link/ether d4:5d:df:07:c1:07 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.239.48.54/24 brd 10.239.48.255 scope global dynamic noprefixroute eno1</span><br><span class="line">       valid_lft 12387sec preferred_lft 12387sec</span><br><span class="line">    inet6 fe80::d65d:dfff:fe07:c107/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: virbr0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000</span><br><span class="line">    link/ether 52:54:00:d3:6d:2d brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: virbr0-nic: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc fq_codel master virbr0 state DOWN group default qlen 1000</span><br><span class="line">    link/ether 52:54:00:d3:6d:2d brd ff:ff:ff:ff:ff:ff</span><br></pre></td></tr></table></figure></li><li><p>使用virsh配置网络<br>在没有进行任何网络配置之前，应该是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#virsh net-list --all</span><br><span class="line"></span><br><span class="line"> Name                 State      Autostart     Persistent</span><br><span class="line">----------------------------------------------------------</span><br></pre></td></tr></table></figure><p>一个比较偷懒的办法是使用现成的配置文件default.xml，内容如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;network&gt;</span><br><span class="line">  &lt;name&gt;default&lt;/name&gt;</span><br><span class="line">  &lt;uuid&gt;417b7ead-6342-40a4-b29f-02fa2d4df491&lt;/uuid&gt;</span><br><span class="line">  &lt;forward mode=&apos;nat&apos;/&gt;</span><br><span class="line">  &lt;bridge name=&apos;virbr0&apos; stp=&apos;on&apos; delay=&apos;0&apos;/&gt;</span><br><span class="line">  &lt;mac address=&apos;52:54:00:d3:6d:2d&apos;/&gt;</span><br><span class="line">  &lt;ip address=&apos;192.168.122.1&apos; netmask=&apos;255.255.255.0&apos;&gt;</span><br><span class="line">    &lt;dhcp&gt;</span><br><span class="line">      &lt;range start=&apos;192.168.122.2&apos; end=&apos;192.168.122.254&apos;/&gt;</span><br><span class="line">    &lt;/dhcp&gt;</span><br><span class="line">  &lt;/ip&gt;</span><br><span class="line">&lt;/network&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#virsh net-define default.xml</span><br><span class="line">#virsh net-start default</span><br><span class="line">#virsh net-list --all</span><br><span class="line"></span><br><span class="line"> Name                 State      Autostart     Persistent</span><br><span class="line">----------------------------------------------------------</span><br><span class="line"> default              active     yes           yes</span><br></pre></td></tr></table></figure><p>如果看到看到上面的结果，那么“虚拟桥”（virt bridge）就配置成功了。<br>实际上虚拟机通过NAT联网的时候，各个网络设备之间的关系如图所示:<br><img src="/2019/12/26/network-in-vm/network-nat2.png" alt=""></p></li><li><p>QEMU创建虚拟机</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x86_64 --enable-kvm -M q35 -m 4G -smp 1 -hda /root/ubuntu1904.qcow -vnc :7 \</span><br><span class="line">-device virtio-net-pci,netdev=nic0,mac=00:16:3e:0c:12:78 \</span><br><span class="line">-netdev tap,id=nic0,br=br0,helper=/usr/local/libexec/qemu-bridge-helper,vhost=on</span><br></pre></td></tr></table></figure><p>因为使用了工具qemu-bridge-helper，它需要一个配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/etc/qemu/bridge.conf:</span><br><span class="line"></span><br><span class="line">#把我们有可能用得到的网桥名字都列在这里。</span><br><span class="line"></span><br><span class="line">allow br0</span><br><span class="line">allow br1</span><br><span class="line">allow virbr0</span><br></pre></td></tr></table></figure><p>顺利的话，虚拟机起来之后会DHCP得到一个IP例如<code>192.168.122.177</code>。</p></li></ol><h2 id="Bridge方式"><a href="#Bridge方式" class="headerlink" title="Bridge方式"></a>Bridge方式</h2><p>如图所示，bridge方式是让虚拟机获得跟host一样网段的IP地址，就像是host的一个“网上邻居”一样。既然是使用TAP那么思路跟上面”通过TAP配置NAT”是一样的，配置”网桥“。但区别是这个网桥是需要跟网卡”绑定“的。下面用两种方法做网卡和网桥的”绑定“，但最后的效果是一样的。<br><img src="/2019/12/26/network-in-vm/network-bridge.png" alt=""></p><h3 id="通过TAP配置Bridge方法1"><a href="#通过TAP配置Bridge方法1" class="headerlink" title="通过TAP配置Bridge方法1"></a>通过TAP配置Bridge方法1</h3><p>首先使用’ip’工具来配置，注意这种方法是临时的，一旦重启系统，这些配置需要重新做。</p><ol><li><p>创建一个“网桥”(bridge),取名br0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip link add name br0 type bridge</span><br><span class="line">ip link set br0 up</span><br></pre></td></tr></table></figure></li><li><p>把物理网卡绑定到网桥上:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip link set dev enp3s0f1 master br0//enp3s0f1 是网卡interface的名字</span><br></pre></td></tr></table></figure><p>这步之后，可以通过<code>ip a</code>查看，br0 和 enp3s0f1具有相同的mac地址。</p></li><li><p>重启网络服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart NetworkManager</span><br></pre></td></tr></table></figure><p>正常情况下，网络重启之后，br0会拿到IP，而之前的enp3s0f1不会拿到IP了。如果不是，执行下面命令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ifdown enp3s0f1</span><br><span class="line">ifdown br0</span><br><span class="line">ifup br0</span><br><span class="line">ifup enp3s0f1</span><br><span class="line">systemctl restart NetworkManager</span><br></pre></td></tr></table></figure></li><li><p>QEMU创建虚拟机</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x86_64 --enable-kvm -M q35 -m 4G -smp 1 -hda /root/ubuntu1904.qcow -vnc :7 \</span><br><span class="line">-device virtio-net-pci,netdev=nic0,mac=00:16:3e:0c:12:78 \</span><br><span class="line">-netdev tap,id=nic0,br=br0,helper=/usr/local/libexec/qemu-bridge-helper,vhost=on</span><br></pre></td></tr></table></figure><p>吼吼，创建虚拟机的步骤与NAT时，没有区别，除了注意一下网桥的名字之外。</p></li><li><p>(选做)如果想要删掉“网桥”执行下面的步骤：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ip link set dev enp3s0f1 nomaster</span><br><span class="line">ip link set dev br0 down</span><br><span class="line">ip link del br0</span><br></pre></td></tr></table></figure></li></ol><h3 id="通过TAP配置Bridge方法2"><a href="#通过TAP配置Bridge方法2" class="headerlink" title="通过TAP配置Bridge方法2"></a>通过TAP配置Bridge方法2</h3><p>这里借用工具nmcli来配置，参考了<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-network_bridging_using_the_networkmanager_command_line_tool_nmcli" target="_blank" rel="noopener">USING THE NETWORKMANAGER COMMAND LINE TOOL, NMCLI</a></p><ol><li><p>简单来说执行下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#nmcli con add type bridge ifname br0</span><br><span class="line">#nmcli con add type ethernet ifname enp3s0f1 master bridge-br0</span><br><span class="line">#nmcli connection down enp3s0f1</span><br><span class="line">#nmcli connection up bridge-br0</span><br><span class="line"></span><br><span class="line">#systemctl restart NetworkManager</span><br></pre></td></tr></table></figure><p>这样应该就创建好网桥br1了</p></li><li><p>QEMU创建虚拟机的步骤还是跟之前的一样。<br>这个方法的优点就是系统重启之后，配置还在。</p></li></ol><h2 id="pass-through物理网卡"><a href="#pass-through物理网卡" class="headerlink" title="pass-through物理网卡"></a>pass-through物理网卡</h2><p>这种方法的网络拓扑结构跟bridge方式是一样的，不过这次虚拟机成为货真价实的网上邻居，因为它使用的是物理网卡。如果host上恰好有一个多余的网卡，不妨试下这个方法，它拥有理论上跟host一样的网络性能，使用虚拟机的网卡驱动。<br>pass-through物理网卡虽然实现起来相对复杂，但用起来却比较容易：</p><ol><li><p>确保host没有加载对应网卡的驱动<br>不过通常这都不太可能，可以参考<a href="vfio-pci.sh">这个脚本</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># ./vfio-pci.sh -h &lt;B:D:F&gt;</span><br></pre></td></tr></table></figure></li><li><p>QEMU创建虚拟机</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x86_64 --enable-kvm -M q35 -m 4G -smp 1 -hda /root/ubuntu1904.qcow -vnc :7 \</span><br><span class="line">-device vfio-pci,host=81:00.0,romfile=</span><br></pre></td></tr></table></figure><p>相比几种方法，去掉了复杂的网络参数，仅仅加上了一个设备，并且指定其B:D:F是需要被pass-through给虚拟机的网卡对应的B:D:F的即可(例子中为81:00.0)。</p></li></ol><p>参考文献：<br><a href="https://qemu.weilnetz.de/doc/qemu-doc.html#Using-TAP-network-interfaces" target="_blank" rel="noopener">2.9 Network emulation</a><br><a href="https://www.qemu.org/2018/05/31/nic-parameter/" target="_blank" rel="noopener">QEMU’s new -nic command line option</a><br><a href="https://wiki.qemu.org/Documentation/Networking" target="_blank" rel="noopener">Documentation/Networking</a><br><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-network_bridging_using_the_networkmanager_command_line_tool_nmcli" target="_blank" rel="noopener">9.2.USING THE NETWORKMANAGER COMMAND LINE TOOL, NMCLI</a></p>]]></content>
      
      
      <categories>
          
          <category> QEMU KVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> qemu kvm network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>利用虚拟机(QEMU)实现宿主机快速重启</title>
      <link href="/2019/12/18/fast-restart/"/>
      <url>/2019/12/18/fast-restart/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么这么做？"><a href="#为什么这么做？" class="headerlink" title="为什么这么做？"></a>为什么这么做？</h2><ol><li>系统完成一次重启的时间太久。</li><li>越来越频繁的安全相关的紧急的升级，包括Firmware/microcode/OS/VMM/QEMU。</li><li>运行中断给“云”服务提供商带来不好的用户体验。</li></ol><h2 id="目前已有的类似方案"><a href="#目前已有的类似方案" class="headerlink" title="目前已有的类似方案"></a>目前已有的类似方案</h2><ol><li>Live patch在线补丁；</li><li>虚拟机热迁移；</li></ol><p>这里暂且不评价各个方案的优劣，仅仅是想提供一个选择3！ 重点是，简单快捷，包教包会。</p><h2 id="方案的工作流程"><a href="#方案的工作流程" class="headerlink" title="方案的工作流程"></a>方案的工作流程</h2><ol><li>运行QEMU创建VM，在VM中进行任何操作。</li><li>将现有的虚拟机（VM）保存（Snapshot）到内存（pmem）中。</li><li>退出qemu，并且可以使用kexec软重启系统，同时可以升级内核、QEMU、Microcode 等。</li><li>重新运行QEMU，恢复VM使其继续执行。</li></ol><div id="flowchart-0" class="flow-chart"></div><h3 id="内核准备"><a href="#内核准备" class="headerlink" title="内核准备"></a>内核准备</h3><h4 id="编译内核"><a href="#编译内核" class="headerlink" title="编译内核"></a>编译内核</h4><p>大概率需要重新编译一个内核，确保所有的所需kernel config都打开。<br>主要是三类内核Configure： NVDIMM，DAX和PMEM相关的都打开吧。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">CONFIG_X86_PMEM_LEGACY_DEVICE=y</span><br><span class="line">CONFIG_X86_PMEM_LEGACY=m</span><br><span class="line">CONFIG_BLK_DEV_PMEM=m</span><br><span class="line">CONFIG_ARCH_HAS_PMEM_API=y</span><br><span class="line"></span><br><span class="line">CONFIG_DAX_DRIVER=y</span><br><span class="line">CONFIG_DAX=y</span><br><span class="line">CONFIG_DEV_DAX=y</span><br><span class="line">CONFIG_DEV_DAX_PMEM=m</span><br><span class="line">CONFIG_DEV_DAX_KMEM=m</span><br><span class="line">CONFIG_DEV_DAX_PMEM_COMPAT=m</span><br><span class="line">CONFIG_FS_DAX=y</span><br><span class="line">CONFIG_FS_DAX_PMD=y</span><br><span class="line"></span><br><span class="line">CONFIG_LIBNVDIMM=m</span><br><span class="line">CONFIG_NVDIMM_PFN=y</span><br><span class="line">CONFIG_NVDIMM_DAX=y</span><br><span class="line">CONFIG_NVDIMM_KEYS=y</span><br></pre></td></tr></table></figure></p><h4 id="内核参数"><a href="#内核参数" class="headerlink" title="内核参数"></a>内核参数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">memmap=2G!4G</span><br></pre></td></tr></table></figure><p>含义是，需要在内存中4G的位置开始，预留2G的内存空间。<a href="https://docs.pmem.io/persistent-memory/getting-started-guide/creating-development-environments/linux-environments/linux-memmap" target="_blank" rel="noopener">了解更详细的memmap用法及含义</a>。</p><h3 id="QEMU准备"><a href="#QEMU准备" class="headerlink" title="QEMU准备"></a>QEMU准备</h3><h4 id="下载QEMU"><a href="#下载QEMU" class="headerlink" title="下载QEMU"></a>下载QEMU</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone git://git.qemu.org/qemu.git</span><br></pre></td></tr></table></figure><p>其中包含了几个子模块，会在编译过程中下载。但是如果在墙内的网络环境中，通常这会失败，下面是墙内的步骤：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone git://git.qemu.org/qemu.git</span><br><span class="line">cd qemu</span><br><span class="line">git submodule init</span><br><span class="line">git submodule update --recursive</span><br></pre></td></tr></table></figure></p><p>如果在<code>git submodule update</code>的过程中出现某个module下载失败，需要手动下载到相应的目录里，路径通常在错误日志中会提到<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone http://git.qemu.org/git/seabios.git/  roms/seabios</span><br><span class="line">git submodule update --recursive</span><br></pre></td></tr></table></figure></p><p>直到这样的状态就可以放心编译QEMU了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">git submodule status --recursive</span><br><span class="line">65cc4d2748a2c2e6f27f1cf39e07a5dbabd80ebf dtc (v1.4.0)</span><br><span class="line">87eea99e443b389c978cf37efc52788bf03a0ee0 pixman (pixman-0.32.6)</span><br><span class="line">b4c93802a5b2c72f096649c497ec9ff5708e4456 roms/SLOF (qemu-slof-20141202-63-gb4c9380)</span><br><span class="line">4e03af8ec2d497e725566a91fd5c19dd604c18a6 roms/ipxe (v1.0.0-2016-g4e03af8)</span><br><span class="line">3caee1794ac3f742315823d8447d21f33ce019e9 roms/openbios (3caee17)</span><br><span class="line">c559da7c8eec5e45ef1f67978827af6f0b9546f5 roms/openhackware (heads/master)</span><br><span class="line">c87a92639b28ac42bc8f6c67443543b405dc479b roms/qemu-palcode (heads/master)</span><br><span class="line">33fbe13a3e2a01e0ba1087a8feed801a0451db21 roms/seabios (rel-1.8.2)</span><br><span class="line">23d474943dcd55d0550a3d20b3d30e9040a4f15b roms/sgabios (heads/master)</span><br><span class="line">2072e7262965bb48d7fffb1e283101e6ed8b21a8 roms/u-boot (v2014.07-rc1-79-g2072e72)</span><br><span class="line">19ea12c230ded95928ecaef0db47a82231c2e485 roms/vgabios (heads/master)</span><br></pre></td></tr></table></figure></p><h4 id="编译QEMU"><a href="#编译QEMU" class="headerlink" title="编译QEMU"></a>编译QEMU</h4><p>QEMU的编译并没有什么特别的，参数都可以“顾名思义” :)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure --target-list=x86_64-softmmu --enable-kvm --enable-libpmem --enable-vnc --enable-gtk --disable-werror</span><br><span class="line"></span><br><span class="line">make</span><br></pre></td></tr></table></figure></p><h3 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h3><p>可以通过DAX设备（DAX device）或者DAX文件（DAX file)两种方式来达到同样的效果。</p><h4 id="方法一：DEV-device实现方法"><a href="#方法一：DEV-device实现方法" class="headerlink" title="方法一：DEV device实现方法"></a>方法一：DEV device实现方法</h4><p>使用<code>/dev/dax0.0</code>作为vNVDIMM的后端（backend）</p><ol><li>创建虚拟机<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x86_64-softmmu/qemu-system-x86_64 \</span><br><span class="line">        --enable-kvm \</span><br><span class="line">   -M q35 \</span><br><span class="line">        -m 2G -smp 1 \</span><br><span class="line">        -hda ubuntu-1904.qcow2 \</span><br><span class="line">        -object memory-backend-file,id=dimm0,size=4g,mem-path=/dev/dax0.0,share=on,pmem=on,align=2M \</span><br><span class="line">        -numa node,memdev=dimm0,cpus=0 \</span><br><span class="line">        -monitor stdio \</span><br><span class="line">        -vnc :7</span><br></pre></td></tr></table></figure></li></ol><p>两点说明：</p><ul><li><p><code>-object memory-backend-file,id=dimm0,size=4g,mem-path=/dev/dax0.0,share=on,pmem=on,align=2M</code>意思是：</p><ul><li>创建一个容量为<code>4g</code>的后端存储设备，设备节点路径是<code>/dev/dax0.0</code>，所以对这个虚拟NVDIMMM设备（vNDVIMM）设备的访问，都会走到<code>/dev/dax0.0</code></li><li><code>share=on</code> 控制虚拟机写操作的可见性。如果share=on，那么虚拟机对这个存储设备的“写”操作会提交到设备上，同时，如果有其他虚拟机使用同一个存储设备，上面的“写”操作同样会被“看”到。如果share=off,那么虚拟机的“写”操作不会被提交到存储设备，也因此其他虚拟机无法“看“到此虚拟机”写“的内容。</li><li><code>pmem=on</code> 同时需要满足QEMU编译的时候，打开了libpmem支持（–enable-libpmem）, 此时QEMU会保证虚拟机的对vNVDIMM设备的“写”操作的“持续性”；但如果这时候QEMU并没有enable libpmep，虚拟机会创建失败并且提示”lack of libpmem support”。</li><li><code>align=2M</code> DAX设备需要2M对齐。</li></ul></li><li><p><code>-numa node,memdev=dimm0,cpus=0</code> 意思是：<br>描述虚拟机的numa结构，这里主要是为了使用上一步创建的vNVDIMM作为虚拟机的内存。<br><a href="https://docs.pmem.io/persistent-memory/getting-started-guide/creating-development-environments/virtualization/qemu" target="_blank" rel="noopener">了解更详细的vNVDIMM用法及含义</a>。</p></li></ul><p>这样虚拟机就创建好了，登录虚拟机（通过vncview :7）做点你想要做的事情。</p><ol start="2"><li><p>保存虚拟机现场<br>在QEMU console中输入HMP命令，并且退出QEMU</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(qemu) migrate_set_capability x-ignore-shared on//设置QEMU在保存VM的时候，忽略share=on的那些内存。这里指代不保存VM的pmem。</span><br><span class="line">(qemu) stop//停止虚拟机</span><br><span class="line">(qemu) savevm s0//保存虚拟机snapshot为s0</span><br><span class="line">(qemu) q//退出QEMU</span><br></pre></td></tr></table></figure></li><li><p>升级操作系统<br>这个时候，可以对宿主机为所欲为，比如更新QEMU，更新microcode，安装新kernel，kexec软重启。<br>kexec的使用方法:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kernel_image=&quot;/boot/vmlinuz-`uname -r`&quot;   </span><br><span class="line">initrd_image=&quot;/boot/initrd.img-`uname -r`&quot;</span><br><span class="line">sudo kexec -l $kernel_image --reuse-cmdline --initrd=$initrd_image</span><br></pre></td></tr></table></figure></li><li><p>重启QEMU，恢复虚拟机现场</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x86_64-softmmu/qemu-system-x86_64 \</span><br><span class="line">        --enable-kvm \</span><br><span class="line">        -M q35 \</span><br><span class="line">        -m 4G -smp 1 \</span><br><span class="line">        -hda $IMAGE_PATH/ubuntu-1904.qcow2 \</span><br><span class="line">        -object memory-backend-file,id=dimm0,size=4g,mem-path=/dev/dax0.0,share=on,pmem=on,align=2M \</span><br><span class="line">        -numa node,memdev=dimm0,cpus=0 \</span><br><span class="line">        -S \</span><br><span class="line">        -monitor stdio \</span><br><span class="line">        -vnc :7</span><br></pre></td></tr></table></figure><p>在QEMU console中输入HMP命令，重新加载snapshot s0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(qemu) stop</span><br><span class="line">(qemu) loadvm s0</span><br><span class="line">(qemu) c</span><br></pre></td></tr></table></figure></li></ol><h4 id="方法二：DAX-file实现方法"><a href="#方法二：DAX-file实现方法" class="headerlink" title="方法二：DAX file实现方法"></a>方法二：DAX file实现方法</h4><p>使用DAX file实现时，是用一个支持文件（支持影射为pmem）作为后端。“写”操作的“持续性”是“宿主机”的内核来支持（v4.15之后）。</p><ol start="0"><li><p>创建虚拟机前的准备工作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkfs.ext4 -b 4096 -E stride=512 -F /dev/pmem0//格式化pmem设备</span><br><span class="line">mount -t ext4 -o dax /dev/pmem0 /dax//把pmem设备mount到一个目录，支持DAX</span><br></pre></td></tr></table></figure></li><li><p>创建虚拟机</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x86_64-softmmu/qemu-system-x86_64 \</span><br><span class="line">--enable-kvm \</span><br><span class="line">-M q35 \</span><br><span class="line">-m 4G -smp 1 \</span><br><span class="line">-hda $IMAGE_PATH/ubuntu-1904.qcow2 \</span><br><span class="line">-enable-dax -mem-path /dax \</span><br><span class="line">-device vfio-pci,host=81:00.0,romfile= \</span><br><span class="line">-monitor stdio \</span><br><span class="line">-vnc :7</span><br></pre></td></tr></table></figure></li></ol><ul><li><code>-mem-path /dax</code> ：为虚拟机分配内存，使用一个临时创建的文件路径。这里是指之前mount的pmem0设备</li><li><code>-enable-dax</code>： 正在努力upstream…… :p</li></ul><ol start="2"><li><p>保存虚拟机现场<br>在QEMU console中输入HMP命令，并且退出QEMU</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(qemu) migrate_set_capability x-ignore-shared on//设置QEMU在保存VM的时候，忽略share=on的那些内存。这里指代不保存VM的pmem。</span><br><span class="line">(qemu) stop//停止虚拟机</span><br><span class="line">(qemu) savevm s0 -dax-no-save//保存虚拟机snapshot为s0</span><br><span class="line">(qemu) q//退出QEMU</span><br></pre></td></tr></table></figure></li><li><p>升级操作系统<br>这个时候，可以对宿主机为所欲为，比如更新QEMU，更新microcode，安装新kernel，kexec软重启。<br>kexec的使用方法:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kernel_image=&quot;/boot/vmlinuz-`uname -r`&quot;   </span><br><span class="line">initrd_image=&quot;/boot/initrd.img-`uname -r`&quot;</span><br><span class="line">sudo kexec -l $kernel_image --reuse-cmdline --initrd=$initrd_image</span><br></pre></td></tr></table></figure></li><li><p>重启QEMU，恢复虚拟机现场</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x86_64-softmmu/qemu-system-x86_64 \</span><br><span class="line">--enable-kvm \</span><br><span class="line">-M q35 \</span><br><span class="line">-m 4G -smp 1 \</span><br><span class="line">-hda $IMAGE_PATH/ubuntu-1904.qcow2 \</span><br><span class="line">-enable-dax -mem-path /dax \</span><br><span class="line">-loadvm s0,mode=dax \</span><br><span class="line">-device vfio-pci,host=81:00.0,romfile= \</span><br><span class="line">-monitor stdio \</span><br><span class="line">-vnc :7</span><br></pre></td></tr></table></figure></li></ol><ul><li><code>-loadvm</code> 正在努力upstream…… :p</li></ul><p>至此，虚拟机又可以接着之前的地方呼啸的跑下去了。效果看下面的视频吧：</p><p><iframe height="360" width="640" src="https://player.youku.com/embed/XNDQ3MTkyMTYzNg==" frameborder="0" 'allowfullscreen'=""></iframe><br><a href="http://v.youku.com/v_show/id_XNDQ3MTkyMTYzNg==.html?spm=a2h3j.8428770.3416059.1" target="_blank" rel="noopener">快速启动演示</a></p><p><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.8/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.11.3/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">step1=>operation: 创建虚拟机。step2=>operation: 保存虚拟机到pmem。step3=>operation: 退出QEMU、更新kernel、Microcode等升级。step4=>operation: 重新运行QEMU，恢复VM使其继续执行。step1->step2->step3->step4</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script></p>]]></content>
      
      
      <categories>
          
          <category> QEMU </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM QEMU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>利用虚拟机(QEMU)学习X86指令集1--内存存储的重排序以及FENCE指令</title>
      <link href="/2019/07/16/study-x86-fence/"/>
      <url>/2019/07/16/study-x86-fence/</url>
      
        <content type="html"><![CDATA[<h2 id="浅谈“内存读写重排序”"><a href="#浅谈“内存读写重排序”" class="headerlink" title="浅谈“内存读写重排序”"></a>浅谈“内存读写重排序”</h2><p>在我们编写C/C++代码时，以及它在CPU上运行时，按照一些规则，代码中原有的内存读写指令的执行顺序(又叫“程序顺序”, program ordering)会被重新排列。这个现象会在两个地方引入，编译时候由编译器引入；以及运行时由处理器引入。目的都是为了”使代码运行的更快”。尽管本文重在说明运行时CPU对内存读写的重排序作用。但考虑完整性以及防止读者混淆，我们会两种重排序一起介绍。</p><div id="flowchart-0" class="flow-chart"></div><h3 id="X86的内存读写顺序模型"><a href="#X86的内存读写顺序模型" class="headerlink" title="X86的内存读写顺序模型"></a>X86的内存读写顺序模型</h3><p>按照内存访问重排序发生情况的多少，大概划分为下面三种“顺序模型”。</p><h4 id="弱顺序模型"><a href="#弱顺序模型" class="headerlink" title="弱顺序模型"></a>弱顺序模型</h4><p>弱顺序模型中，可能会出现四种内存重排序(Load-Load, Store-Store, Load-Store 和 Store-Load)。任意读(load)操作和写(store)操作都有可能与其他读写操作重排序，只要它能保证原来程序的行为。采用弱顺序模型的处理器可以称为“weakly-order”或者”weak ordering”。<br>对于C/C++的编译器gcc(因为我只用过gcc:p)，都可以呈现弱顺序模型，稍后我们看下例子。</p><h4 id="强顺序模型"><a href="#强顺序模型" class="headerlink" title="强顺序模型"></a>强顺序模型</h4><p>强顺序模型和弱顺序模型的界限可能不一定有确切的标准，但从SDM 8.2章开头可以看到，奔腾4之后的X86处理器大概属于强顺序类型：<br><em>To allow performance optimization of instruction execution, the IA-32 architecture allows departures from strongordering model called processor ordering in Pentium 4, Intel Xeon, and P6 family processors</em><br>继续读SDM8.2 可以发现如下约定：</p><ol><li>Reads are not reordered with other reads. (任何‘读-读’之间不可重排序)<br>这就意味着前述弱顺序模型中的重排序中的”load-load”禁止。</li><li>Writes are not reordered with older reads. (‘写’不可向前重排到‘读’之前)<br>这就意味着弱顺序模型中的”load-store”被禁止。</li><li>Writes to memory are not reordered with other writes, with the following exceptions:… (‘写’与‘写’之间不可以重排序，但除了如下例外。<em>例外的部分我们暂时忽略</em>)<br>这就意味着弱顺序模型中的大部分”store-store”是被禁止的，例外情况文末会提到。</li><li>Reads may be reordered with older writes to different locations but not with older writes to the same location. (‘读’可以向前重排序到不同内存位置的‘写’之前)<br>这就明确的说明4种弱顺序模型中的store-load是<strong>被允许的!</strong>。这也是我们后面实例的重要依据。</li></ol><h4 id="顺序一致"><a href="#顺序一致" class="headerlink" title="顺序一致"></a>顺序一致</h4><p>所有运行时内存访问的顺序跟程序顺序一模一样。现如今都是多核系统，可能很难找到可以成为顺序一致(Sequential consistency)的CPU了。如果真要追溯可能是386时代。</p><p><img src="/2019/07/16/study-x86-fence/weak-strong-table.png" alt=""></p><h2 id="编译时内存顺序重排序"><a href="#编译时内存顺序重排序" class="headerlink" title="编译时内存顺序重排序"></a>编译时内存顺序重排序</h2><p>我们先通过下面这个最简单的实例，体验编译器如何进行内存访问的重排序的，直接看代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int a, b;</span><br><span class="line">void test() &#123;</span><br><span class="line">    a = b;</span><br><span class="line">    b = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>写了一个.c 文件，里面仅仅包含了上面这几行，然后我们用gcc把它翻译成汇编语言：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$gcc -S -O0 test.c -o test1.s</span><br><span class="line"></span><br><span class="line">movl    b(%rip), %eax</span><br><span class="line">movl    %eax, a(%rip)</span><br><span class="line">movl    $1, b(%rip)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$gcc -S -O2 test.c -o test2.s</span><br><span class="line"></span><br><span class="line">movl    b(%rip), %eax</span><br><span class="line">movl    $1, b(%rip)&lt;--- 被提前了!!</span><br><span class="line">movl    %eax, a(%rip)</span><br></pre></td></tr></table></figure><p>通过这个例子可以明显的感受到gcc的弱顺序模型：-O0的时候，顺序跟我们预期的程序顺序是一致的；但当使用-O2优化时，test函数的最后一句的变量b赋值明显已经被<strong>向前重排</strong>到了变量a的存储之前！<br>但我们需要知道的是，这样的重排序，对于单线程的硬件来说，重排序并不会影响程序最后的执行结果。但是对于多线程来说，如果有另外的线程实时的读取变量a的值的话，很可能会得到错误的结果。</p><h3 id="如何阻止编译器的重排序？"><a href="#如何阻止编译器的重排序？" class="headerlink" title="如何阻止编译器的重排序？"></a>如何阻止编译器的重排序？</h3><p>前辈们习惯的用法是这样的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">int a, b;</span><br><span class="line">void test() &#123;</span><br><span class="line">    a = b;</span><br><span class="line">    asm volatile(&quot;&quot; ::: &quot;memory&quot;);</span><br><span class="line">    b = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>加了嵌入式汇编<code>asm volatile(&quot;&quot; ::: &quot;memory&quot;);</code>后的test.c再无论怎么优化，都会得到跟-O0一样的汇编结果。</p><h2 id="CPU运行时重排序"><a href="#CPU运行时重排序" class="headerlink" title="CPU运行时重排序"></a>CPU运行时重排序</h2><p>前面的一篇文章大概翻译了下SDM的8.2章节<a href="/2019/05/12/sdm-8-2-memory-ordering/" title="SMD Chapter 8.2 内存存取顺序">SMD Chapter 8.2 内存存取顺序</a>，我们按照SDM8.2.3.4的描述，重现一个store-read操作的重排序，并且观察MFENCE是如何工作的，以保证执行顺序的正确。</p><h3 id="回顾SDM8-2-3-4的内容"><a href="#回顾SDM8-2-3-4的内容" class="headerlink" title="回顾SDM8.2.3.4的内容"></a>回顾SDM8.2.3.4的内容</h3><p>intel-64存取顺序重排允许<strong>加载操作</strong>重排序到<strong>不同地址</strong>的存储之前，但<strong>不</strong>允许重排序到<strong>同一个</strong>地址的存储之前。</p><table><thead><tr><th>处理器0</th><th>处理器1</th></tr></thead><tbody><tr><td>mov [x],1</td><td>mov [y],1</td></tr><tr><td>mov r1 [y]</td><td>mov r2,[x]</td></tr><tr><td>初始值 x=y=0</td></tr><tr><td>r1 = 0 并且 r2 = 0 允许</td></tr></tbody></table><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>下面我们就来实现上面这段逻辑：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">#define USE_CPU_FENCE  0</span><br><span class="line"></span><br><span class="line">atomic_t begin_sem1;</span><br><span class="line">atomic_t begin_sem2;</span><br><span class="line">atomic_t end_sem;</span><br><span class="line"></span><br><span class="line">int X, Y;</span><br><span class="line">int r1, r2;</span><br><span class="line"></span><br><span class="line">int main(int ac, char **av) &#123;</span><br><span class="line"></span><br><span class="line">int detected = 0;</span><br><span class="line">atomic_set(&amp;begin_sem1, 0);</span><br><span class="line">atomic_set(&amp;begin_sem2, 0);</span><br><span class="line">atomic_set(&amp;end_sem, 0);</span><br><span class="line"></span><br><span class="line">id = 0;</span><br><span class="line"></span><br><span class="line">for (int i = 1; ; ++i) &#123;</span><br><span class="line">X = Y = 0;</span><br><span class="line">r1 = r2 = 1;</span><br><span class="line">atomic_inc(&amp;begin_sem1);</span><br><span class="line">atomic_inc(&amp;begin_sem2);</span><br><span class="line"></span><br><span class="line">while(atomic_read(&amp;end_sem) != 2) NOP();</span><br><span class="line"></span><br><span class="line">atomic_set(&amp;end_sem, 0);</span><br><span class="line"></span><br><span class="line">if (r1 == 0 &amp;&amp; r2 == 0) &#123;</span><br><span class="line">detected++;</span><br><span class="line">printf(&quot;%d reorders detected after %d iterations\n&quot;, detected, i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if( i % 10000 == 0) printf(&quot;BSP: times %d\n&quot;, i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">while(1) &#123; NOP(); &#125;</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void test1() &#123;</span><br><span class="line">while(atomic_read(&amp;begin_sem1) != 1) NOP();</span><br><span class="line">atomic_dec(&amp;begin_sem1);</span><br><span class="line"></span><br><span class="line">asm volatile(</span><br><span class="line">&quot;xor %0, %0\n\t                 &quot;</span><br><span class="line">&quot;movl $1, %1\n\t                &quot;</span><br><span class="line">#if USE_CPU_FENCE</span><br><span class="line">&quot;mfence\n\t                     &quot;</span><br><span class="line">#endif</span><br><span class="line">&quot;movl %2, %0\n\t                &quot;</span><br><span class="line">: &quot;=r&quot;(r1), &quot;=m&quot; (X)</span><br><span class="line">: &quot;m&quot;(Y)</span><br><span class="line">: &quot;memory&quot;);</span><br><span class="line"></span><br><span class="line">atomic_inc(&amp;end_sem);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void test2() &#123;</span><br><span class="line">while(atomic_read(&amp;begin_sem2) != 1) NOP();</span><br><span class="line">atomic_dec(&amp;begin_sem2);</span><br><span class="line"></span><br><span class="line">asm volatile(</span><br><span class="line">&quot;xor %0, %0\n\t                 &quot;</span><br><span class="line">&quot;movl $1, %1\n\t                &quot;</span><br><span class="line">#if USE_CPU_FENCE</span><br><span class="line">&quot;mfence\n\t                     &quot;</span><br><span class="line">#endif</span><br><span class="line">&quot;movl %2, %0\n\t                &quot;</span><br><span class="line">: &quot;=r&quot;(r2), &quot;=m&quot; (Y)</span><br><span class="line">: &quot;m&quot;(X)</span><br><span class="line">: &quot;memory&quot;);</span><br><span class="line"></span><br><span class="line">atomic_inc(&amp;end_sem);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完整的可编译的code可以到github上clone:<br><code>git clone -b memory_ordering https://github.com/ysun/acrn-unit-test.git</code><br>在<code>guest</code>文件夹里执行<code>make unit file=memory_order</code>就可以执行了。</p><h3 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h3><p>读代码难免有点枯燥，我们把流程图画一下就一目了然了：</p><p><img src="/2019/07/16/study-x86-fence/memory_order.png" alt=""></p><ol><li><p>上面这个例子中一共涉及到了三个逻辑CPU(core)。BSP(processor1)就是上电后第一个执行指令的逻辑CPU，负责另外两个AP(processor2和processor3)的同步工作。两个AP负责分别运行两段测试代码<code>test1</code>和<code>test2</code>。</p></li><li><p>程序一开始，两个AP(processor2和processor3)忙等待BSP发来的同步信号(begin_sem1和begin_sem2)。BSP在进行了必要的初始化操作之后，使用原子操作(atomic_inc)分别将上述两个信号 +1。两个AP等到各自的信号之后，立即清除该信号，然后准备测试。</p></li><li><p>所以，我们可以认为processor2和processor3几乎是同步运行的。也就是test1和test2代码块可以认为是同时运行。此时processor1在忙等待两个AP的测试完成end_sem == 2。</p></li><li><p>test1和test2的两段汇编很简单，严格按照前面的表各种所述。如果没有重排序的发生，那么两个寄存器变量中r1和r2中的值都应该是1。但如果我们发现某次test1和test2测试结束后，r1和r2的值同时为0的时候，那么就说明发生了重排序，test1和test2中的两个store操作，也就是<code>movl %2, %0</code>这句重排到了<code>movl $1, %1</code>这句之前，而且是两个processor同时发生这样的重排序。</p></li><li><p>processor1在end_sem == 2的时候，意味着两个AP都已完成，此时processor1检测是否r1 == r2 == 0。</p></li><li><p>通过改变宏定义USE_CPU_FENCE  的值来重现重排序，以及引入MFENCE来防止重排序。</p></li></ol><h3 id="执行结果"><a href="#执行结果" class="headerlink" title="执行结果"></a>执行结果</h3><p>下面两个图就是义USE_CPU_FENCE=0和USE_CPU_FENCE=1两次不同的运行结果。<br><img src="/2019/07/16/study-x86-fence/fence_no.png" alt=""><br><img src="/2019/07/16/study-x86-fence/fence_added.png" alt=""><br>从打印的日志可以容易的看出图一发生了重排序，图二中大概200w次测试没有发生重排序。需要指出的是这里200w次循环执行时间不超过1秒钟，非常快。</p><h2 id="LFENCE-和-SFENCE"><a href="#LFENCE-和-SFENCE" class="headerlink" title="LFENCE 和 SFENCE"></a>LFENCE 和 SFENCE</h2><p>既然说到FNECE了，咱就得讲完另外两种LFENE和SFENCE。SDM里面讲LFENCE是保证load-load操作不被重排序，SFENCE是保证store-store不被重排序，就是前面在说SDM8.2里面列举了禁止的弱顺序模型中的store-store我们省略掉的部分。<br><em>Writes to memory are not reordered with other writes, with the following exceptions:<br>— streaming stores (writes) executed with the non-temporal move instructions (MOVNTI, MOVNTQ,<br>MOVNTDQ, MOVNTPS, and MOVNTPD); and<br>— string operations (see Section 8.2.4.1)</em></p><p>这里我利用RDTSC指令实现了LFENCE组织CPU指令的重排序，这里不列举了，大概意思是，在一个逻辑CPU上，利用两次rdtsc指令之间插入LFENCE来观察循环的周期的长短来判断LFENCE的作用。只放个链接在这里吧<a href="https://github.com/ysun/acrn-unit-test/blob/memory_ordering_LFENCE/guest/x86/memory_order.c" target="_blank" rel="noopener">memory_ordering_lfence.c</a></p><p>但对于SFENCE，我按照SDM 8.2.2所述内容并没有重现MOVNTI指令的store-store重排序，所以没能确认SFENCE的作用。<br>我的MOVNTI和SFENCE的测试代码在这里<a href="https://github.com/ysun/acrn-unit-test/blob/memory_ordering_SFENCE/guest/x86/memory_order.c" target="_blank" rel="noopener">memory_ordering_sfence.c</a>，<strong>幻想着某位大牛可以回复我一下！！！</strong></p><p>参考文档：<br><a href="https://preshing.com/20120930/weak-vs-strong-memory-models/" target="_blank" rel="noopener">https://preshing.com/20120930/weak-vs-strong-memory-models/</a><br><a href="https://preshing.com/20120515/memory-reordering-caught-in-the-act/" target="_blank" rel="noopener">https://preshing.com/20120515/memory-reordering-caught-in-the-act/</a><br><a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/" target="_blank" rel="noopener">http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/</a></p><p><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.8/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.11.3/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">c_code=>operation: C 语言asm_code=>operation: 汇编语言cpu_instruction=>operation: CPU执行序列compiler_reorder=>inputoutput: 编译器重排序cpu_reorder=>inputoutput: 处理器重排序c_code(right)->compiler_reorder(right)->asm_code(right)->cpu_reorder(right)->cpu_instruction</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script></p>]]></content>
      
      
      <categories>
          
          <category> X86 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> x86 KVM QEMU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>利用虚拟机(QEMU)学习X86指令集0</title>
      <link href="/2019/07/12/study-x86-using-qemu/"/>
      <url>/2019/07/12/study-x86-using-qemu/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>接下来的几个日志，我会写几篇关于如何学习X86指令集，也是帮助自己梳理和记忆知识点。<br>下面是我大概总结了一下，一个操作系统需要掌握的知识点，仅供参考欢迎斧正！</p><h2 id="学习内容"><a href="#学习内容" class="headerlink" title="学习内容"></a>学习内容</h2><div id="flowchart-0" class="flow-chart"></div><p>上图用户层应用程序以及硬件部分暂不是本文考虑范围，中间的三个软件部分“Linux内核/模块”、“IA32e指令”以及“BIOS/UEFI部分指令”都可以通过本文的方法学习。需要说明的是，虽然这里划分了三个部分，并不是操作系统上的划分，只是一个建议的学习的阶段划分。</p><h3 id="BIOS-UEFI-部分设计的指令"><a href="#BIOS-UEFI-部分设计的指令" class="headerlink" title="BIOS/UEFI 部分设计的指令"></a>BIOS/UEFI 部分设计的指令</h3><p>是指硬件上电后CPU执行的最早期的指令。通常包括BIOS、boot loader等。<br>这部分可以通过<a href="https://github.com/cirosantilli/x86-bare-metal-examples" target="_blank" rel="noopener">x86-bare-metal-examples</a>来学习</p><h3 id="IA32e指令"><a href="#IA32e指令" class="headerlink" title="IA32e指令"></a>IA32e指令</h3><p>是指操作系统已经经过一些初始化操作，例如开启页表、开启32bit或者32e模式、段寄存器初始化、开启中断（APIC/X2APIC)、开启SMP支持等。<br>在这样的环境中，我们可以更专注于X86指令集的研究。上述初始化过程可以等日后展开讲述。</p><h3 id="Linux内核-模块"><a href="#Linux内核-模块" class="headerlink" title="Linux内核/模块"></a>Linux内核/模块</h3><p>基本上Linux 内核开发涵盖之前两个方面，只是上来就学习Linux内核有点复杂，代码量太大。并且，本系教程的重点在于学习X86指令，并不在Linux中复杂的功能实现。</p><h2 id="如何利用QEMU学习"><a href="#如何利用QEMU学习" class="headerlink" title="如何利用QEMU学习"></a>如何利用QEMU学习</h2><p>首先确保系统里安装了qemu，步骤略。大概有两种形式使用QEMU</p><h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>随便举个例子，来自kvm-unit-test:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">gcc -m64 -g -Wall -fno-pic -no-pie -std=gnu99 -ffreestanding \</span><br><span class="line">-I /home/works/kvm-unit-tests/lib -I /home/works/kvm-unit-tests/lib/x86 -I ./lib \</span><br><span class="line">-c -o x86/tsc.o x86/tsc.c</span><br><span class="line"></span><br><span class="line">gcc -I /home/works/kvm-unit-tests/lib -I /home/works/kvm-unit-tests/lib/x86 \</span><br><span class="line">-I lib -T /home/works/kvm-unit-tests/x86/flat.lds  -fno-pic -no-pie -nostdlib \</span><br><span class="line">x86/tsc.c x86/cstart64.o lib/libcflat.a /usr/lib/gcc/x86_64-linux-gnu/5/libgcc.a \</span><br><span class="line">-o x86/tsc.elf </span><br><span class="line"></span><br><span class="line">objcopy -O elf32-i386 x86/tsc.elf x86/tsc.flat  ##&amp;&amp; ./x86-run x86/tsc.flat</span><br></pre></td></tr></table></figure></p><p>编译一个test case，代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">        u64 t1, t2;</span><br><span class="line">        asm volatile (&quot;rdtsc&quot; : &quot;=a&quot;(a), &quot;=d&quot;(d));</span><br><span class="line">        t1 = a | ((long long)d &lt;&lt; 32);</span><br><span class="line"></span><br><span class="line">        asm volatile (&quot;rdtsc&quot; : &quot;=a&quot;(a), &quot;=d&quot;(d));</span><br><span class="line">        t2 = a | ((long long)d &lt;&lt; 32);</span><br><span class="line"></span><br><span class="line">        printf(&quot;rdtsc latency %u\n&quot;, (unsigned)(t2 - t1));</span><br><span class="line"></span><br><span class="line">        return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这样得到一个测试两次rdtsc指令执行的时间差的测试<code>tsc.flat</code>。当然上面辣么麻烦的编译啊、链接啊都是为了得到最终的测试的binary，或者叫可执行文件？！我们后面有很多种方法以及机会得到这样的测试代码，如果读者一时没有成功，不要终止于此，不要气馁。</p><h3 id="在虚拟机中作为内核直接运行-kernel"><a href="#在虚拟机中作为内核直接运行-kernel" class="headerlink" title="在虚拟机中作为内核直接运行(-kernel)"></a>在虚拟机中作为内核直接运行(-kernel)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x86_64 -vnc none -serial stdio -machine accel=kvm -kernel x86/tsc.flat</span><br></pre></td></tr></table></figure><p>这样运行的虚拟机，看上去并不真的像是一个“虚拟机”，因为没有窗口，仅仅是console端文字输出。但这样足够我们验证和尝试CPU 指令，而且非常的轻量。个人比较喜欢这样的运行方式。</p><h3 id="制作一个镜像文件，并且使用QEMU启动"><a href="#制作一个镜像文件，并且使用QEMU启动" class="headerlink" title="制作一个镜像文件，并且使用QEMU启动"></a>制作一个镜像文件，并且使用QEMU启动</h3><p>我们可以手动制作一个镜像，步骤如下。但最后一步安装grub的时候，需要的条件有点苛刻，需要本地装有较新版本的grub-x86_64-efi。如果本地没有环境的同学，可以直接跳过制作镜像，直接下载文末的制作好的镜像文件raw.img。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">$  dd if=/dev/zero of=raw.img bs=512 count=1048576</span><br><span class="line">1048576+0 records in</span><br><span class="line">1048576+0 records out</span><br><span class="line">536870912 bytes (537 MB, 512 MiB) copied, 1.22641 s, 438 MB/s</span><br><span class="line"></span><br><span class="line">$ losetup /dev/loop0 raw.img</span><br><span class="line">$ fdisk /dev/loop0</span><br><span class="line">Welcome to fdisk (util-linux 2.27.1).</span><br><span class="line">Changes will remain in memory only, until you decide to write them.</span><br><span class="line">Be careful before using the write command.</span><br><span class="line">Device does not contain a recognized partition table.</span><br><span class="line">Created a new DOS disklabel with disk identifier 0xe68d8ac0.</span><br><span class="line"></span><br><span class="line">Command (m for help): g</span><br><span class="line">Created a new GPT disklabel (GUID: 93A91033-E421-48DD-88E9-662C17E83136).</span><br><span class="line"></span><br><span class="line">Command (m for help): n</span><br><span class="line">Partition number (1-128, default 1):</span><br><span class="line">First sector (2048-999966, default 2048):</span><br><span class="line">Last sector, +sectors or +size&#123;K,M,G,T,P&#125; (2048-999966, default 999966):</span><br><span class="line">Created a new partition 1 of type &apos;Linux filesystem&apos; and of size 487.3 MiB.</span><br><span class="line"></span><br><span class="line">Command (m for help): t</span><br><span class="line">Selected partition 1</span><br><span class="line">Hex code (type L to list all codes): 1</span><br><span class="line">Changed type of partition &apos;Linux filesystem&apos; to &apos;EFI System&apos;.</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">Command (m for help): w</span><br><span class="line">  </span><br><span class="line">#then to ensure the disk status</span><br><span class="line">$ sudo fdisk -l /dev/loop0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#注意：</span><br><span class="line">#1.the disk type must be gpt</span><br><span class="line">#2.disk identifier should have sha id</span><br><span class="line">#3.the type must be EFI System</span><br><span class="line">Disklabel type: gpt</span><br><span class="line">Disk identifier: 93A91033-E421-48DD-88E9-662C17E83136</span><br><span class="line">Device       Start    End Sectors   Size Type</span><br><span class="line">/dev/loop0p1  2048 999966  997919 487.3M EFI System</span><br><span class="line"> </span><br><span class="line">$ partprobe /dev/loop0</span><br><span class="line">$ lsblk</span><br><span class="line">loop0                   7:0    0 488.3M  0 loop</span><br><span class="line">└─loop0p1             259:4    0 487.3M  0 loop</span><br><span class="line"> </span><br><span class="line">$ sudo mkfs.vfat -F 32 /dev/loop0p1</span><br><span class="line">mkfs.fat 3.0.28 (2015-05-16)</span><br><span class="line">$ mkdir /virtfs</span><br><span class="line">$ mount -o rw,umask=000 /dev/loop0p1 /virtfs</span><br><span class="line">$ grub-install --removable --root-directory=/virtfs --target=x86_64-efi  /dev/loop0p1</span><br><span class="line">Installing for x86_64-efi platform.</span><br><span class="line">Installation finished. No error reported.</span><br><span class="line"> </span><br><span class="line">$ cp /boot/grub/grub.cfg /virtfs/boot/grub/grub.cfg</span><br></pre></td></tr></table></figure><p>同样，这里附上UEFI/OVMF的build 方法，但同样可以直接下载文末的binary，毕竟这不是本文的主要内容。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$ git clone git://github.com/tianocore/edk2.git</span><br><span class="line">$ cd edk2</span><br><span class="line"># Because the latest version is missing a file, switch to an older version</span><br><span class="line">$ git checkout 984ba6a467</span><br><span class="line">$ cd edk2</span><br><span class="line">$ make -C BaseTools</span><br><span class="line">$ . edksetup.sh</span><br><span class="line"> </span><br><span class="line">  </span><br><span class="line">  $ vi Conf/target.txt</span><br><span class="line">  #Find</span><br><span class="line">  # ACTIVE_PLATFORM       = Nt32Pkg/Nt32Pkg.dsc</span><br><span class="line">  # and replace it with</span><br><span class="line">  # ACTIVE_PLATFORM       = OvmfPkg/OvmfPkgX64.dsc</span><br><span class="line">  # Find</span><br><span class="line">  #  TOOL_CHAIN_TAG        = MYTOOLS</span><br><span class="line">  # and replace it with your version on GCC here for example GCC 4.6 will be used.</span><br><span class="line">  # TOOL_CHAIN_TAG        = GCC5  //this is your gcc version</span><br><span class="line">  # Find</span><br><span class="line">  # TARGET_ARCH           = IA32</span><br><span class="line">  # and replace it with &apos;X64&apos; for 64bit or &apos;IA32 X64&apos; to build both architectures.</span><br><span class="line">  # TARGET_ARCH           = X64</span><br><span class="line">  #mode detail:https://wiki.ubuntu.com/UEFI/EDK2</span><br><span class="line">  $ build</span><br><span class="line">  $ find -name &quot;OVMF.fd&quot;</span><br><span class="line">  #./Build/OvmfX64/DEBUG_GCC5/FV/OVMF.fd</span><br><span class="line">  $ vim ~/.bashrc</span><br><span class="line">  # add this to bashrc &quot;export OVMF_PATH=/home/huihuang/git/edk2/Build/OvmfX64/DEBUG_GCC5/FV/OVMF.fd&quot;</span><br><span class="line">  $ source ~/.bashrc</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">        mkdir -p virt_fs</span><br><span class="line">        sudo losetup /dev/loop7 raw.img</span><br><span class="line">        partprobe /dev/loop7</span><br><span class="line">        sudo cp x86/tsc.elf virt_fs/tsx.elf</span><br><span class="line">#        sudo umount $(virt_fs_path)</span><br></pre></td></tr></table></figure><p>上面这个脚本是将之前生成的tsx.flat文件copy到预先准备好的镜像里面。同时，需要确保镜像中的grub.cfg文件中有正确的entry：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">menuentry &apos;acrn_unit_test&apos; &#123;</span><br><span class="line">                recordfail</span><br><span class="line">                load_video</span><br><span class="line">                insmod gzio</span><br><span class="line">                if [ x$grub_platform = xxen ]; then insmod xzio; insmod lzopio; fi</span><br><span class="line">                insmod part_gpt</span><br><span class="line">                insmod ext2</span><br><span class="line">                set root=&apos;hd0,gpt0&apos;</span><br><span class="line">                search --no-floppy --fs-uuid --set=root --hint-bios=hd0,gpt0 --hint-efi=hd0,gpt0 --hint-baremetal=ahci0,gpt4  A807-B387</span><br><span class="line">                multiboot /tsx.elf</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>要启动这个镜像需要使用OVMF（EDK2项目中的软件模拟的UEFI）。下面是QEMU的启动参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">       DISPLAY=:0 qemu-system-x86_64 --bios OVMF_CODE.fd \</span><br><span class="line">-drive file=raw.img,index=0,media=disk,format=raw \</span><br><span class="line">-serial mon:stdio -m 1024M -smp cpus=4 \</span><br><span class="line">-cpu  Nehalem,+sse,+avx,+xsave,+sse2,+sse3,+mpx,+fpu,level=13 #-vnc :0</span><br></pre></td></tr></table></figure><p>这里所需的所有文件都放在文末以备下载。<br>这样启动的虚拟机，就有种仪式感了，QEMU会创建一个窗口，同时因为有UEFI/OVMF，所以可以看到一个虚拟的BIOS画面，然后还有GRUB的选择菜单，选择刚刚创建的tsx.elf的入口。</p><p>OVMF 点击下载：<a href="OVMF_CODE.fd">OVMF</a><br>raw.img 点击下载： <a href="raw.img">raw.img</a></p><h3 id="调试虚拟机代码"><a href="#调试虚拟机代码" class="headerlink" title="调试虚拟机代码"></a>调试虚拟机代码</h3><p>请参考 <a href="/2018/12/24/qemu-debug/" title="Debug QEMU with GDB">Debug QEMU with GDB</a></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>自此如何利用虚拟机学习底层编程的准备工作都已经搞定，我们会在后面的文章里陆续介绍X86的指令。可能不一定系统，甚至可以说的是零碎。因为Intel SDM实在是太长了，能吃透个一章半节的就挺开心的了。仅仅是为想学相关技术的同学们一点点思路，有不对的地方请留言指正！</p><p><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.8/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.11.3/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">blk_userspace=>parallel: 用户态应用程序blk_kernel=>parallel: Linux内核/模块 blk_64bit=>parallel: IA32e指令|invalidblk_bios=>parallel: BIOS/UEFI 部分设计的指令|approvedblk_hardware=>parallel: 系统硬件blk_kernel_study=>parallel: linux-kernel-module-cheat:>https://github.com/cirosantilli/linux-kernel-module-cheatblk_64bit_study=>parallel: KVM Unit Test|future:>http://www.linux-kvm.org/page/KVM-unit-testsblk_bios_study=>parallel: x86-bare-metal-examples:>https://github.com/cirosantilli/x86-bare-metal-examplesblk_userspace(path1, bottom)->blk_kernel(path1, bottom)->blk_64bit(path1,bottom)->blk_bios(path1,bottom)->blk_hardwareblk_64bit(path2,right)->blk_64bit_studyblk_bios(path2,right)->blk_bios_studyblk_kernel(path2, right)->blk_kernel_study</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script></p>]]></content>
      
      
      <categories>
          
          <category> X86 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> X86 KVM QEMU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>C/C++ 中嵌入汇编总结</title>
      <link href="/2019/05/22/inline-assembly/"/>
      <url>/2019/05/22/inline-assembly/</url>
      
        <content type="html"><![CDATA[<h2 id="GCC汇编语法梗概"><a href="#GCC汇编语法梗概" class="headerlink" title="GCC汇编语法梗概"></a>GCC汇编语法梗概</h2><h3 id="AT-amp-T-与-Intel-汇编区别"><a href="#AT-amp-T-与-Intel-汇编区别" class="headerlink" title="AT&amp;T 与 Intel 汇编区别"></a>AT&amp;T 与 Intel 汇编区别</h3><p>Linux GCC(GNU, C Compiler)使用AT&amp;T汇编语法。下面列一下AT&amp;T 和Intel汇编语法中的不同：</p><h4 id="源-目的-顺序"><a href="#源-目的-顺序" class="headerlink" title="源-目的 顺序"></a>源-目的 顺序</h4><p>AT&amp;T中源和目的操作数的顺序相反。Intel语法中第一个操作数是目的，第二个是源。而AT&amp;T语法中，第一个是源第二个操作数是目的。<br>“Op-code src, dst” —— AT&amp;T 语法<br>“Op-code dst, src” —— Intel语法</p><h4 id="寄存器命名"><a href="#寄存器命名" class="headerlink" title="寄存器命名"></a>寄存器命名</h4><p>AT&amp;T语法中，寄存器需要有‘%’前缀，例如eax需要写作%eax。这里只是强调Intel汇编语法中不使用各种前缀，具体寄存器命名后面会继续涉及。</p><h4 id="立即数"><a href="#立即数" class="headerlink" title="立即数"></a>立即数</h4><p>AT&amp;T中立即数需要有‘$’前缀。如果是静态“C”变量，同样需要’$’前缀。<br>Intel语法中，16进制需要’h’前缀，而AT&amp;T则需要‘0x’前缀。所以，对于16进制的立即数写作 ‘$0x1234’</p><h4 id="操作数大小"><a href="#操作数大小" class="headerlink" title="操作数大小"></a>操作数大小</h4><p>在AT&amp;T语法中，内存操作数的大小取决于Op-code的<em>后缀</em>字母’b’’w’以及’l’，分别指代’字节(8bit) 字(16bit) 和长字(32bit)内存指针。而Intel语法使用前置限定符’byte ptr’ ‘word ptr’ 以及’dword prt’。<br>所以下面两句等效：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Intel &quot;mov al, byte ptr foo&quot;</span><br><span class="line">At&amp;T  &quot;movb foo, %al&quot;</span><br></pre></td></tr></table></figure></p><h4 id="内存地址的访问"><a href="#内存地址的访问" class="headerlink" title="内存地址的访问"></a>内存地址的访问</h4><p>在AT&amp;T中基址寄存器使用’()’，Intel中使用’[]’。 下面两句等效：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Intel &quot;section: [base + index*scale + disp]&quot;</span><br><span class="line">AT&amp;T  &quot;section: disp(base, index, scale)&quot;</span><br></pre></td></tr></table></figure></p><h3 id="GNU-AT-amp-T汇编"><a href="#GNU-AT-amp-T汇编" class="headerlink" title="GNU AT&amp;T汇编"></a>GNU AT&amp;T汇编</h3><h4 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h4><p>现代X86处理器（例如386及其以后）有8个32位通用寄存器（general purpose registers,GPR）如图:<br><img src="/2019/05/22/inline-assembly/x86-registers.png" alt="x86-registers.png"><br>寄存器名字是继承过来的。例如EAX成为<strong>累加器</strong>，因为之前被大量的算法这样操作，ECX被称为计数器，因为它通常用来作为循环的索引。然而，在现代指令集中，大多数寄存器已经失去了它之前特殊的用途。但有两个例外的——堆指针（ESP）和基址指针（EBP）。<br>对于EAX EBX ECX以及EDX，可以分段使用。例如，EAX的低2字节可以看做是16位寄存器，称作AX；低1字节可以看做8位寄存器，称作AL，而AX的高字节也可以看作是8位寄存器，成为AH。这些寄存器名字都指向相同的物理寄存器。当2字节数值存入DX中的时候，它会影响DH，DL以及EDX。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">movb $2, (%ebx)/* Move 2 into the single byte at the address stored in EBX. */</span><br><span class="line">movw $2, (%ebx)/* Move the 16-bit integer representation of 2 into the 2 bytes starting at the address in EBX. */</span><br><span class="line">movl $2, (%ebx) /* Move the 32-bit integer representation of 2 into the 4 bytes starting at the address in EBX. */</span><br></pre></td></tr></table></figure></p><h4 id="内存操作符"><a href="#内存操作符" class="headerlink" title="内存操作符"></a>内存操作符</h4><p>X86指令中，我们可以生命静态数据区域（类似全局变量）。使用<code>.data</code>指令来声明，紧跟在<code>.data</code>指令之后，使用指令<code>.byte</code>, <code>.short</code> 以及<code>.long</code>来声明1,2或者4字节数据位置，然后使用标签来引用之前创建的数据区。标签可以看做是内存区域的名字，可以在之后的汇编或者连接器中使用标签，这就跟用名字声明变量非常的相似，但稍微有些不同。比如，一个连续的内存数据位置的声明他们在内存中的位置是连续的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">.data</span><br><span class="line">var:</span><br><span class="line">.byte 64/* Declare a byte, referred to as location var, containing the value 64. */</span><br><span class="line">.byte 10/* Declare a byte with no label, containing the value 10. Its location is var + 1. */</span><br><span class="line">x:</span><br><span class="line">.short 42/* Declare a 2-byte value initialized to 42, referred to as location x. */</span><br><span class="line">y:</span><br><span class="line">.long 30000    /* Declare a 4-byte value, referred to as location y, initialized to 30000. */</span><br></pre></td></tr></table></figure></p><p>并不像高级语言那样，数组可以有各种容量，并且可以使用索引访问。X86汇编中的数组仅仅是简单的一些内存中接续的存储单元。数组可以通过列出数值累声明（例如第一个例子）。对于一些特别的数组，可以使用字符串；再如果一个很大的内存需要填充0，那么可使用<code>.zero</code>指令。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">s:</span><br><span class="line">.long 1, 2, 3/* Declare three 4-byte values, initialized to 1, 2, and 3. </span><br><span class="line">The value at location s + 8 will be 3. */</span><br><span class="line">barr:</span><br><span class="line">.zero 10/* Declare 10 bytes starting at location barr, initialized to 0. */</span><br><span class="line">str:</span><br><span class="line">.string &quot;hello&quot;   /* Declare 6 bytes starting at the address str initialized to </span><br><span class="line">the ASCII character values for hello followed by a nul (0) byte. */</span><br></pre></td></tr></table></figure></p><h4 id="内存寻址"><a href="#内存寻址" class="headerlink" title="内存寻址"></a>内存寻址</h4><p>现代X86处理器最高可寻址2^32字节的内存地址（内存地址有32位宽）。上面的例子中，我们使用标签指向内存区域，这些标签实际上被编译器用实际32位地址取代。为了更进一步支持<strong>标签指向内存地址</strong>（例如常量），X86提供了一个灵活的计算和引用内存地址的方法：两个32位寄存器以及一个32位有符号常量相加，并且其中一个寄存器可以被2,4,8相乘。<br>有一点需要注意，当disp/scale中使用常数的时候，这里不再需要”$”前缀。</p><table><thead><tr><th>Intel 代码</th><th>AT&amp;T 代码</th></tr></thead><tbody><tr><td>mov eax, 1</td><td>movl $1, %eax</td></tr><tr><td>mov ebx, 0ffh</td><td>movl $0xff, %ebx</td></tr><tr><td>int 80h</td><td>int $0x80</td></tr><tr><td>mov ebx, eax</td><td>mov %eax, %ebx</td></tr><tr><td>mov eax, [ecx]</td><td>movl (%ecx), %eax</td></tr><tr><td>mov eax, [ebx + 3]</td><td>movl 3(%ebx), %eax</td></tr><tr><td>mov eax, [ebx + 20h]</td><td>movl 0x20(%ebx), %eax</td></tr><tr><td>mov eax, [ebx + ecx]</td><td>movl (%ebx,%ecx), %eax</td></tr><tr><td>mov eax, [ebx + ecx*2h]</td><td>movl (%ebx,%ecx,0x2), %eax</td></tr><tr><td>mov eax, [ebx + ecx*4h-20h]</td><td>movl -0x20(%ebx,%ecx,0x4), %eax</td></tr></tbody></table><h2 id="基本内联"><a href="#基本内联" class="headerlink" title="基本内联"></a>基本内联</h2><p>基本内联汇编的格式比较简单：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">asm(&quot;assembly code&quot;);</span><br></pre></td></tr></table></figure></p><p>例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">asm(&quot;movl %ecx, %eax&quot;);//把ecx中的内容移动到eax中</span><br><span class="line">__asm__(&quot;movb %bh, (%eax)&quot;) //把寄存器bh中的内容移动到eax指向的内存地址</span><br></pre></td></tr></table></figure></p><p>这里有几点注意事项：</p><ol><li>千万不要忘记src, dst两个操作数之间的逗号’,’</li><li>这里<code>asm()</code> 和 <code>__asm()__</code> 都是有效的。</li><li>如果有多行汇编，需要在每行末尾添加 <code>\n\t</code>，除最后一行汇编的末尾。例如：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__asm__ (&quot;movl %eax, %ebx\n\t&quot;</span><br><span class="line">         &quot;movl $56, %esi\n\t&quot;</span><br><span class="line">         &quot;movl %ecx, $label(%edx,%ebx,$4)\n\t&quot;</span><br><span class="line">         &quot;movb %ah, (%ebx)&quot;);</span><br></pre></td></tr></table></figure><p>如果在代码中，更改过一些寄存器并从asm返回后，则会发生一些难以预料的事情。这是因为GCC不知道寄存器内容的变化，所致，特别是当编译器进行一些优化时。这就需要一些扩展功能的地方。下面来看下<strong>扩展的asm</strong>语法。</p><h2 id="扩展的ASM"><a href="#扩展的ASM" class="headerlink" title="扩展的ASM"></a>扩展的ASM</h2><p>在基本内联汇编中，我们只有指令。但在扩展汇编中，我们可以指定操作数。并且允许指定输入寄存器，输出寄存器以及改动的寄存器列表。但不强制使用寄存器。格式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">asm ( assembler template </span><br><span class="line">    : output operands                  /* optional */</span><br><span class="line">    : input operands                   /* optional */</span><br><span class="line">    : list of clobbered registers      /* optional */</span><br><span class="line">    );</span><br></pre></td></tr></table></figure></p><p>如果没有输出操作符，但有输入操作，也必须保留两个冒号，例如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">asm (&quot;cld\n\t&quot;//多行指令</span><br><span class="line">     &quot;rep\n\t&quot;</span><br><span class="line">     &quot;stosl&quot;</span><br><span class="line">     : /* 没有输出寄存器 */</span><br><span class="line">     : &quot;c&quot; (count), &quot;a&quot; (fill_value), &quot;D&quot; (dest)</span><br><span class="line">     : &quot;%ecx&quot;, &quot;%edi&quot; </span><br><span class="line">     );</span><br></pre></td></tr></table></figure></p><p>上段代码意思是，把fill_value变量中的值往edi指向的内存地址写入count次。也就是说，eax和edi中的内容不再有效。再来看下面的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">int a=10, b;</span><br><span class="line">asm (&quot;movl %1, %%eax;\n\t&quot; </span><br><span class="line">     &quot;movl %%eax, %0;&quot;</span><br><span class="line">     :&quot;=r&quot;(b)        /* output */</span><br><span class="line">     :&quot;r&quot;(a)         /* input */</span><br><span class="line">     :&quot;%eax&quot;         /* clobbered register */</span><br><span class="line">     );</span><br></pre></td></tr></table></figure></p><p>这段代码意思是，把变量a的值赋值给b。</p><ul><li>‘b’是输出操作符，%0引用它，并且’a’是输入操作符，1%引用它。</li><li>‘r’是操作符的限定符。这里’r’告诉GCC可以使用任意一个寄存器来存储操作符。’=’是输出操作符的限定符，并且是只写的。</li><li>在寄存器之前有两个’%’号。用来帮助GCC区别操作符还是寄存器。操作符只有一个’%’前缀。<br>换句话说，<strong>在扩展ASM语法中，如果在汇编中直接使用寄存器名字而不是通过%0 %1这样引用，则寄存器前需要两个%限定</strong>。</li><li>改动的寄存器%eax列在第三个冒号在后，告诉GCC %eax的值在汇编中有改动，所以GCC不会再用这个寄存器存储其他的值。<br>当asm结束时，’b’会反应更新过的数据，因为他被指定为输出操作符。换句话说，在汇编中改变’b’的值，会被反映到汇编之外。</li><li>但如果一个寄存器已经出现在输出操作符列表中，那么无需再将它添加到clobber list里，如果添加了编译的时候会报错。例如下面这段汇编是错误的：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">       int a=10, b;</span><br><span class="line">asm (&quot;movl %1, %%eax;   \n\t&quot;</span><br><span class="line">    &quot;movl %%eax, %0;&quot;</span><br><span class="line">    :&quot;=b&quot;(b)        /* 明确指出使用寄存器ebx */</span><br><span class="line">    :&quot;r&quot;(a)         /* input  */</span><br><span class="line">    :&quot;%eax&quot;, &quot;%ebx&quot;         /* 编译出错！！ */</span><br><span class="line">    );</span><br></pre></td></tr></table></figure></li></ul><h3 id="编译器模板"><a href="#编译器模板" class="headerlink" title="编译器模板"></a>编译器模板</h3><h4 id="操作数"><a href="#操作数" class="headerlink" title="操作数"></a>操作数</h4><p>每个 操作数都必须包含在“”之内。对于输出操作数，双引号（“”）中会多一个限定符，用来决定限定符地址的模式。<br>如果有多个操作数，他们使用逗号（，）隔开。<br>每个操作数都可以通过数字来引用，按照顺序一次命名。输入和输出操作数依次命名，第一个输出的操作数记作0，后面依次增加。<br>输出操作数必须是长类型，输入操作数没有这个限制。扩展汇编最常用来调用机器指令本身，跟编译器无关。如果输出表达式不是一个直接地址，例如一个位阈，限定符必须是寄存器。此事，GCC会使用寄存器作为内联汇编的输出，并且把寄存器的值存储到输出里。<br>综上，原始输出操作数必须是“只写”的；GCC假定在指令结束之前，数值都在这些操作数中，并且不需要生成。扩展汇编也支持读写操作数。<br>来看几个例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">asm (&quot;leal (%1, %1, 4), %0&quot;</span><br><span class="line">     : &quot;=r&quot; (five_times_x)</span><br><span class="line">     : &quot;r&quot; (x) </span><br><span class="line">     );</span><br></pre></td></tr></table></figure></p><p>这个例子中，输入是’x’，并且没有指定寄存器。GCC会自己选择一个。再同样给输出选择一个寄存器。如果我们想要输入输出使用同一个寄存器，可以告诉GCC我们希望那种读写的操作数，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">asm (&quot;leal (%0, %0, 4), %0&quot;</span><br><span class="line">     : &quot;=r&quot; (five_times_x)</span><br><span class="line">     : &quot;0&quot; (x) </span><br><span class="line">     );</span><br></pre></td></tr></table></figure></p><p>此时，输入输出操作数会是同一个寄存器。但我们并不知道是具体那一个。如果想明确指定某一个寄存器，也有方法，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">asm (&quot;leal (%%ecx,%%ecx,4), %%ecx&quot;</span><br><span class="line">     : &quot;=c&quot; (x)</span><br><span class="line">     : &quot;c&quot; (x) </span><br><span class="line">     );</span><br></pre></td></tr></table></figure></p><p>以上三个例子，并没有指定任何改动寄存器列表，为什么？前两个例子，GCC决定使用哪个寄存器，它会知道寄存器发生的变化。在最后一个例子中，我们也没有指定变化寄存器，因为GCC知道值最终保存到x中，在汇编之外，它知道ecx的值了，所以没有必要列出变化寄存器列表(clobber list)，如果列上<code>%ecx</code>编译就会错误。</p><h4 id="变化寄存器列表-clobber"><a href="#变化寄存器列表-clobber" class="headerlink" title="变化寄存器列表(clobber)"></a>变化寄存器列表(clobber)</h4><p>有些指令会改变硬件寄存器，因此必须明确指出这些改动过的寄存器，将其列在第三个’:’之后。这是为了告诉GCC汇编使用并修改了那些寄存器。所以，GCC会知道之前被加载到这些寄存器的值已经无效了。同时没有必要列出放在输入和输出操作数中的寄存器，以内GCC知道内联已经使用了他们。需要明确指出的是那些没有明确指出的隐式使用的寄存器，那些没有列在输入和输出操作数中的寄存器。<br>如果指令修改了内存，需要在clobber list中添加”memory”。这样通知GCC内存缓存应该失效了。同时必须添加’volatile’关键字，如果内存修改并没有列在输入和输出操作数中时。<br>我们多次可以读写更改的寄存器，参考下面的例子，意思是调用子程序_foo，并且通过eax 和 ecx传递两个参数给他。<br><strong>注：这里的寄存器名字前是否加%，<code>eax</code>和<code>%eax</code>都是正确的！</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">asm (&quot;movl %0,%%eax; \n\t&quot;</span><br><span class="line">     &quot;movl %1,%%ecx;\n\t&quot;</span><br><span class="line">     &quot;call _foo&quot;</span><br><span class="line">     : /* no outputs */</span><br><span class="line">     : &quot;g&quot; (from), &quot;g&quot; (to)</span><br><span class="line">     : &quot;eax&quot;, &quot;ecx&quot;</span><br><span class="line">     );</span><br></pre></td></tr></table></figure></p><h4 id="Volatile-关键字"><a href="#Volatile-关键字" class="headerlink" title="Volatile 关键字"></a>Volatile 关键字</h4><p>如果熟悉内核源码，我们会经常看到volatile或者<strong>volatile</strong>关键字在 asm或者<strong>asm</strong>之后。<br>如果内联汇编需要在它原来所在的位置处被执行，例如不被移到循环的外面或者不被优化掉，在asm 和 （）之间放一个volatile，像这样：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">asm volatile ( ... : ... : ... : ...);</span><br></pre></td></tr></table></figure></p><p>如果我们添加的汇编语言仅仅是为了计算并且没有任何边际效应，最好不要使用volatile关键字，因为volatile会妨碍代码优化。</p><h4 id="关于限定符"><a href="#关于限定符" class="headerlink" title="关于限定符"></a>关于限定符</h4><p>前面的例子中我们已经使用了很多限定符，但还没有具体讲限定符的作用。限定符可以规定操作数是否在寄存器中，什么样的寄存器；以及操作数是指向内存以及内存地址类型；操作数是否是立即数，和数字的范围。来看下常用的限定符。</p><h5 id="寄存器操作数限定符-‘r’"><a href="#寄存器操作数限定符-‘r’" class="headerlink" title="寄存器操作数限定符 ‘r’"></a>寄存器操作数限定符 ‘r’</h5><p>当使用这个限定符时，操作数被存储在通用寄存器中（General Purpose Registers, GPR)。举例说明：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">asm (&quot;movl %%eax, %0\n&quot; :&quot;=r&quot;(myval));</span><br></pre></td></tr></table></figure></p><p>变量myval被存储到及粗糙那其中，寄存器eax中的值被copy到那个寄存器中，并且myval的值会被从寄存器更新到内存中。因为限定符’r’，gcc会把变量保存到任何一个通用寄存器中。如果需要明确指定某一个寄存器，需要使用相对应的限定符，如下表：</p><table><thead><tr><th>r</th><th>GPRs</th></tr></thead><tbody><tr><td>a</td><td>%eax, %ax, %al</td></tr><tr><td>b</td><td>%ebx, %bx, %bl</td></tr><tr><td>c</td><td>%ecx, %cx, %cl</td></tr><tr><td>d</td><td>%edx, %dx, %dl</td></tr><tr><td>S</td><td>%esi, %si</td></tr><tr><td>D</td><td>%edi, %di</td></tr></tbody></table><h5 id="内存操作数限定符-‘m’"><a href="#内存操作数限定符-‘m’" class="headerlink" title="内存操作数限定符 ‘m’"></a>内存操作数限定符 ‘m’</h5><p>当操作数在内存中，任何关于操作数的操作都直接访问内存地址。相反，寄存器操作数是先把数据存储到寄存器中，在写回到内存地址中。但寄存器限定符只有当指令明确需要或者明显加速处理，才会存储到寄存器中。当一个C变量需要在内联汇编更新的时候，内存限定符会更方便，并且，我们并不是真的需要用寄存器来存储值。例如存储IDTR的值到loc中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">asm(&quot;sidt %0\n&quot; : :&quot;m&quot;(loc));</span><br></pre></td></tr></table></figure></p><h5 id="匹配限定符-Digit"><a href="#匹配限定符-Digit" class="headerlink" title="匹配限定符(Digit)"></a>匹配限定符(Digit)</h5><p>很多情况下，一个变量就可以做输入也可以做输出操作数，例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">asm (&quot;incl %0&quot; :&quot;=a&quot;(var):&quot;0&quot;(var));</span><br></pre></td></tr></table></figure></p><p>来看一个简单的例子，寄存器eax及用作输入同时用作输出操作数。变量var作为输入，传值给eax，并且在完成自增后，又更新到eax中。“0”这里指代同一个限定符，第0个，也就是输出变量。也就是输出变量var只会被存到eax中。通常下列情况可以这样使用：</p><ul><li>当变量作为输入，并且协会到同一个变量中。</li><li>没必要把输入和输出分开的时候。<br>匹配限定符最重要的作用是高效的使用寄存器。</li></ul><p>其他限定符：<br>“g” : Any register, memory or immediate integer operand is allowed, except for registers that are not general registers.<br>“m” : A memory operand is allowed, with any kind of address that the machine supports in general.<br>“o” : A memory operand is allowed, but only if the address is offsettable. ie, adding a small offset to the address gives a valid address.<br>“V” : A memory operand that is not offsettable. In other words, anything that would fit the <code>m’ constraint but not the</code>o’constraint.<br>“i” : An immediate integer operand (one with constant value) is allowed. This includes symbolic constants whose values will be known only at assembly time.<br>“n” : An immediate integer operand with a known numeric value is allowed. Many systems cannot support assembly-time constants for operands less than a word wide. Constraints for these operands should use ’n’ rather than ’i’.</p><p>下面是X86特有的限定符：<br>“r” : Register operand constraint, look table given above.<br>“q” : Registers a, b, c or d.<br>“I” : Constant in range 0 to 31 (for 32-bit shifts).<br>“J” : Constant in range 0 to 63 (for 64-bit shifts).<br>“K” : 0xff.<br>“L” : 0xffff.<br>“M” : 0, 1, 2, or 3 (shifts for lea instruction).<br>“N” : Constant in range 0 to 255 (for out instruction).<br>“f” : Floating point register<br>“t” : First (top of stack) floating point register<br>“u” : Second floating point register<br>“A” : Specifies the ‘a’ or ‘d’ registers. This is primarily useful for 64-bit integer values intended to be returned with the ‘d’ register holding the most significant bits and the ‘a’ register holding the least significant bits.</p><h4 id="限定修饰符"><a href="#限定修饰符" class="headerlink" title="限定修饰符"></a>限定修饰符</h4><ol><li>‘=’ 意思是操作数是“只写”的，之前的值会被输出值覆盖掉。</li><li>‘&amp;’ 意思是输入操作数在本条指令完成之前，被修改。但这个操作数可能没有列在输入操作数列表或者是内存的一部分。如果输入仅仅用于早起结果的输入时，输入操作数可以被看做earlyclobber操作数</li><li>‘+’ 意思是操作数是“可读可写”的。</li></ol><p>参考：<a href="https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html" target="_blank" rel="noopener">https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html</a><br>      <a href="https://www.ibm.com/developerworks/cn/linux/sdk/assemble/inline/" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/linux/sdk/assemble/inline/</a><br>      <a href="http://flint.cs.yale.edu/cs421/papers/x86-asm/asm.html" target="_blank" rel="noopener">http://flint.cs.yale.edu/cs421/papers/x86-asm/asm.html</a></p><hr><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>First we start with a simple example. We’ll write a program to add two numbers.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> int main(void)</span><br><span class="line">&#123;</span><br><span class="line">        int foo = 10, bar = 15;</span><br><span class="line">        __asm__ __volatile__(&quot;addl  %%ebx,%%eax&quot;</span><br><span class="line">                             :&quot;=a&quot;(foo)</span><br><span class="line">                             :&quot;a&quot;(foo), &quot;b&quot;(bar)</span><br><span class="line">                             );</span><br><span class="line">        printf(&quot;foo+bar=%d\n&quot;, foo);</span><br><span class="line">        return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Here we insist GCC to store foo in %eax, bar in %ebx and we also want the result in %eax. The ’=’ sign shows that it is an output register. Now we can add an integer to a variable in some other way.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__asm__ __volatile__(</span><br><span class="line">                    &quot;   lock       ;\n&quot;</span><br><span class="line">                    &quot;   addl %1,%0 ;\n&quot;</span><br><span class="line">                    : &quot;=m&quot;  (my_var)</span><br><span class="line">                    : &quot;ir&quot;  (my_int), &quot;m&quot; (my_var)</span><br><span class="line">                    :                                 /* no clobber-list */</span><br><span class="line">                    );</span><br></pre></td></tr></table></figure><p>This is an atomic addition. We can remove the instruction ’lock’ to remove the atomicity. In the output field, “=m” says that my_var is an output and it is in memory. Similarly, “ir” says that, my_int is an integer and should reside in some register (recall the table we saw above). No registers are in the clobber list.</p><p>Now we’ll perform some action on some registers/variables and compare the value.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__asm__ __volatile__(  &quot;decl %0; sete %1&quot;</span><br><span class="line">                    : &quot;=m&quot; (my_var), &quot;=q&quot; (cond)</span><br><span class="line">                    : &quot;m&quot; (my_var) </span><br><span class="line">                    : &quot;memory&quot;</span><br><span class="line">                    );</span><br></pre></td></tr></table></figure><p>Here, the value of my_var is decremented by one and if the resulting value is 0 then, the variable cond is set. We can add atomicity by adding an instruction “lock;\n\t” as the first instruction in assembler template.</p><p>In a similar way we can use “incl %0” instead of “decl %0”, so as to increment my_var.</p><p>Points to note here are that (i) my_var is a variable residing in memory. (ii) cond is in any of the registers eax, ebx, ecx and edx. The constraint “=q” guarantees it. (iii) And we can see that memory is there in the clobber list. ie, the code is changing the contents of memory.</p><p>How to set/clear a bit in a register? As next recipe, we are going to see it.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__asm__ __volatile__(   &quot;btsl %1,%0&quot;</span><br><span class="line">                     : &quot;=m&quot; (ADDR)</span><br><span class="line">                     : &quot;Ir&quot; (pos)</span><br><span class="line">                     : &quot;cc&quot;</span><br><span class="line">                     );</span><br></pre></td></tr></table></figure><p>Here, the bit at the position ’pos’ of variable at ADDR ( a memory variable ) is set to 1 We can use ’btrl’ for ’btsl’ to clear the bit. The constraint “Ir” of pos says that, pos is in a register, and it’s value ranges from 0-31 (x86 dependant constraint). ie, we can set/clear any bit from 0th to 31st of the variable at ADDR. As the condition codes will be changed, we are adding “cc” to clobberlist.</p><p>Now we look at some more complicated but useful function. String copy.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> static inline char * strcpy(char * dest,const char *src)</span><br><span class="line">&#123;</span><br><span class="line">int d0, d1, d2;</span><br><span class="line">__asm__ __volatile__(  &quot;1:\tlodsb\n\t&quot;</span><br><span class="line">                       &quot;stosb\n\t&quot;</span><br><span class="line">                       &quot;testb %%al,%%al\n\t&quot;</span><br><span class="line">                       &quot;jne 1b&quot;</span><br><span class="line">                     : &quot;=&amp;S&quot; (d0), &quot;=&amp;D&quot; (d1), &quot;=&amp;a&quot; (d2)</span><br><span class="line">                     : &quot;0&quot; (src),&quot;1&quot; (dest) </span><br><span class="line">                     : &quot;memory&quot;);</span><br><span class="line">return dest;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>The source address is stored in esi, destination in edi, and then starts the copy, when we reach at 0, copying is complete. Constraints “&amp;S”, “&amp;D”, “&amp;a” say that the registers esi, edi and eax are early clobber registers, ie, their contents will change before the completion of the function. Here also it’s clear that why memory is in clobberlist.</p><p>We can see a similar function which moves a block of double words. Notice that the function is declared as a macro.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> #define mov_blk(src, dest, numwords) \</span><br><span class="line">__asm__ __volatile__ (                                          \</span><br><span class="line">                       &quot;cld\n\t&quot;                                \</span><br><span class="line">                       &quot;rep\n\t&quot;                                \</span><br><span class="line">                       &quot;movsl&quot;                                  \</span><br><span class="line">                       :                                        \</span><br><span class="line">                       : &quot;S&quot; (src), &quot;D&quot; (dest), &quot;c&quot; (numwords)  \</span><br><span class="line">                       : &quot;%ecx&quot;, &quot;%esi&quot;, &quot;%edi&quot;                 \</span><br><span class="line">                       )</span><br></pre></td></tr></table></figure></p><p>Here we have no outputs, so the changes that happen to the contents of the registers ecx, esi and edi are side effects of the block movement. So we have to add them to the clobber list.</p><p>In Linux, system calls are implemented using GCC inline assembly. Let us look how a system call is implemented. All the system calls are written as macros (linux/unistd.h). For example, a system call with three arguments is defined as a macro as shown below.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> #define _syscall3(type,name,type1,arg1,type2,arg2,type3,arg3) \</span><br><span class="line">type name(type1 arg1,type2 arg2,type3 arg3) \</span><br><span class="line">&#123; \</span><br><span class="line">long __res; \</span><br><span class="line">__asm__ volatile (  &quot;int $0x80&quot; \</span><br><span class="line">                  : &quot;=a&quot; (__res) \</span><br><span class="line">                  : &quot;0&quot; (__NR_##name),&quot;b&quot; ((long)(arg1)),&quot;c&quot; ((long)(arg2)), \</span><br><span class="line">                    &quot;d&quot; ((long)(arg3))); \</span><br><span class="line">__syscall_return(type,__res); \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Whenever a system call with three arguments is made, the macro shown above is used to make the call. The syscall number is placed in eax, then each parameters in ebx, ecx, edx. And finally “int 0x80” is the instruction which makes the system call work. The return value can be collected from eax.</p><p>Every system calls are implemented in a similar way. Exit is a single parameter syscall and let’s see how it’s code will look like. It is as shown below.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> &#123;</span><br><span class="line">        asm(&quot;movl $1,%%eax;         /* SYS_exit is 1 */</span><br><span class="line">             xorl %%ebx,%%ebx;      /* Argument is in ebx, it is 0 */</span><br><span class="line">             int  $0x80&quot;            /* Enter kernel mode */</span><br><span class="line">             );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>The number of exit is “1” and here, it’s parameter is 0. So we arrange eax to contain 1 and ebx to contain 0 and by int $0x80, the exit(0) is executed. This is how exit works. </p><p>参考：<a href="https://www.ibiblio.org/gferg/ldp/GCC-Inline-Assembly-HOWTO.html" target="_blank" rel="noopener">https://www.ibiblio.org/gferg/ldp/GCC-Inline-Assembly-HOWTO.html</a></p>]]></content>
      
      
      <categories>
          
          <category> ASM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ASM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SMD Chapter 8.2 内存存取顺序</title>
      <link href="/2019/05/12/sdm-8-2-memory-ordering/"/>
      <url>/2019/05/12/sdm-8-2-memory-ordering/</url>
      
        <content type="html"><![CDATA[<p>‘内存存取顺序(Memory ordering)’一词说的是处理器通过系统总线进行读取（加载）以及写回（存储）到系统内存里面。Intel 64以及32位系统根据架构的实现，支持多种存储顺序模型。例如，intel 386处理器强制使用“程序顺序”（强顺序），就是说读写系统总线的顺序按照全部环境中CPU指令流产生的顺序。<br>后来为了指令执行的效率，IA32架构允许脱离“强顺序”，在奔腾4、Xeon以及P6系列处理器中，称作“处理器顺序”。处理器顺序不同的方式，称作“内存存取顺序模型”，他们都允许增强执行，例如 允许读操作在可以缓存的写操作之前。所有这些不同模型的目的就是增强指令执行速度，同时保持存储内容的一致性，即使在多核系统中亦然。<br>8.2.1和8.2.2章节描述在intel486、奔腾、Core2 Due、Atom、Core Due、奔腾4、Xeon以及P6系列处理器中内存存取模型的实现。8.2.3章节会给出具体的存储模型的例子。8.2.4章节是关于字节操作的特殊处理。8.2.5章节讨论一些特殊指令的使用会影响存储模型的行为。</p><h2 id="8-2-1-奔腾以及486处理器上的存储模型"><a href="#8-2-1-奔腾以及486处理器上的存储模型" class="headerlink" title="8.2.1 奔腾以及486处理器上的存储模型"></a>8.2.1 奔腾以及486处理器上的存储模型</h2><p>奔腾和486处理器遵循“处理器顺序”的内存存取模型，但在大多数情况下他们是按照“强顺序”模型来运行的。加载和存储是按照系统总线顺序，但除了以下情况：加载允许放在缓存的写之前，当所有的写操作都被缓存，但是不可以跟加载操作是同一个地址。<br>对于I/O操作，无论是加载还是存储都是程序顺序。</p><h2 id="8-2-2-P6系列以及最新系列CPU的存储顺序"><a href="#8-2-2-P6系列以及最新系列CPU的存储顺序" class="headerlink" title="8.2.2 P6系列以及最新系列CPU的存储顺序"></a>8.2.2 P6系列以及最新系列CPU的存储顺序</h2><p>Intel Core2 Due、Atom、Core Duo、奔腾4以及P6系列处理器上使用的处理器顺序模型可以被称为“带写缓存转发的存储顺序（write ordered with store-buffer forwarding）”（很拗口，可能读到后面才能理解上啥意思），我们本节来看这种模型。<br>在单处理器系统中存储区域被定义为“可缓存的回写”。这种存取模型遵循下面的法则。注意，单核或者多核处理器存储模型中涉及到的名词“处理器”都是指逻辑处理器。比如，一个物理处理器支持多核或者支持intel 超线程技术（HT），那么它都被看做是“多核处理器”</p><ul><li>加载操作之间不可以重排序。</li><li>存储不可以跟加载操作重排序。</li><li>存储操作间除下列例外情况之外，不可以重排。<ul><li>流存储通过非时态（non-temporal)的move 指令，MOVINTI，MOVNTQ，MOVNTDQ， MOVNTPS以及MOVNTPD。</li><li>字符串操作（详见8.2.4.1）</li></ul></li><li>不允许CLFLUSH指令的存储操作的重排序；当使用CLFLUSHOPT指令时，存储操作可以被重排序，并且刷新缓存而不是直接存储。CLFLUSH指令的执行不可以被重新排序。当刷新不同缓存线的时候，CLFLUSHOPT指令的执行可以被重新排序。</li><li>加载操作可以与不同地址的存储操作重排序，不可以与相同地址的存储重新排序。</li><li>在I/O操作、锁指令或者串行指令时加载和存储都不可以重排序。</li><li>加载不可以早于LFENCE和MFENCE指令。</li><li>存储和CLFUSH、CLFLUSHOPT不能早于LFENCE、SFENCE以及MFENCE指令。</li><li>LFENCE指令不可以早于加载。</li><li>SFENCE指令不可以早于存储或者CLFLUSH、CLFLUSHOPT指令。</li><li>MFENCE指令不能早于加载、存储或者CLFLUSH和CLFLUSHOPT指令。</li></ul><p>对于多核处理器，还要遵守下面规则：</p><ul><li>多核处理器中的每一个核都与单核处理器遵守同样的准则。</li><li>各个核中的存储顺序是跟所有处理器中存储顺序是一致的。</li><li>单个处理器上的存储操作与其他处理器上的存储操作顺序无关。</li><li>内存存取顺序遵从因果关系（memory ordering respects transitive visibility）。</li><li>在同一个处理器上的任何两个存储操作都可以看做是有确定顺序的，但整个存储操作看来却不一定。</li><li>锁指令具有绝对的执行顺序。</li></ul><p>看一个例子，图8-1.有三个处理器，并且每个处理器中有三个存储操作，分别是A，B，C。单独来说，处理器是按照程序顺序来进行存储操作，但由于总线仲裁以及内存访问机制，三个处理器对同一个内存的访问，即使是执行同一段代码，可能每次都不太一样。<br>本章处理器顺序模型是奔腾和486所使用的，在奔腾4、Xeon以及P6系列处理器中，仅仅加强了如下内容：</p><ul><li>增加了推理加载，但依然遵守上午策略。</li><li>存储缓存转发，当一个读取操作在存储操作之后。</li><li>长字符串的乱序存储以及move操作（详见8.2.4）<br><img src="/2019/05/12/sdm-8-2-memory-ordering/figure8-1.png" alt=""></li></ul><h2 id="8-2-3-举例说明存储顺序策略"><a href="#8-2-3-举例说明存储顺序策略" class="headerlink" title="8.2.3 举例说明存储顺序策略"></a>8.2.3 举例说明存储顺序策略</h2><p>本章举例说明8.2.2中的内存存取顺序策略。目的是给软件开发人员深入理解内存存取顺序是如何影响不同指令序列的结果的。<br>这些例子仅限于有回写缓存能力的内存区域。读者需要理解他们仅仅是软件可见的行为。即便某个例子说明不可以重排的两次方访问，逻辑处理器也可能会重排。此时软件是无法察觉这样的重排操作发生。</p><h3 id="8-2-3-1-假设、术语以及注意事项"><a href="#8-2-3-1-假设、术语以及注意事项" class="headerlink" title="8.2.3.1 假设、术语以及注意事项"></a>8.2.3.1 假设、术语以及注意事项</h3><p>如前文所述，本章所述的内容仅限于回写缓存（WB）的存储区域。此时仅提交原始的加载和存储操作，同时为“读-改-写”指令加锁。同时并不提交任何如下指令：字符串的乱序存储、用non-temporal hint访问存储、处理器加载页表以及更新段、页结构。<br>在本节例子中，Intel64存储顺序模型保证下列内存访问指令视为一次单独的访问操作:</p><ul><li>加载或存储一个字节的指令</li><li>加载或存储一个word（2字节），并且他们的地址是2字节对齐的。</li><li>加载或存储一个doubleword(4字节），并且他们的的地址是4字节对齐的</li><li>加载或存储一个quadword（8字节），并且他们的地址8字节对齐的。<br>任何带锁的指令（例如XCHG或者其他读后写的指令都会有一个LOCK前缀指令），看上去是作为一次单独的、不会被中断的指令序列。<br>其他指令也可能是有多次内存存取访问组合来实现的。从内存存取顺序的观点来看，并不能保证其操作的顺序，也不能保内存存取操作的顺序跟程序加载的顺序一致。<br>8.2.3.2至8.2.3.7使用MOV指令来举例。通过内存存取操作来说明存储器策略以及其他各种存取指令的基础。8.2.3.8和8.2.3.9使用XCHG指令举例，用来说明那些带锁的以及读后写的指令。<br>本章节中“处理器”是指逻辑处理器。例子是用intel-64汇编语言，并且使用如下写法：</li><li>使用’r’开头的参数，例如r1 r2看作是寄存器，只有处理器可见。</li><li>存储器地址记作x,y,z</li><li>存储记为 mov [_x],val, 意思是把val存到寄存器的_x地址中</li><li>加载记作 mov r,[_x], 意思是把内存地址_x中的值加载到寄存器r中</li></ul><p>正如前文所述，例子只是设计软件可见的行为。当文中说“把两个存储操作重排”意思是“两个存储操作从软件的角度看上去被重新排列执行顺序了”。</p><h3 id="8-2-3-2-相似的加载或者存储都不可以重排序"><a href="#8-2-3-2-相似的加载或者存储都不可以重排序" class="headerlink" title="8.2.3.2 相似的加载或者存储都不可以重排序"></a>8.2.3.2 相似的加载或者存储都不可以重排序</h3><p>Intel-64 内存存取顺序模型不允许同样类型的加载或者存储指令重新排列。也就是说，在程序中加载或者存储都是按照程序顺序，用下面的里说明：</p><table><thead><tr><th>Processor0</th><th>Processor1</th></tr></thead><tbody><tr><td>mov [_x],1</td><td>mov r1,[_y]</td></tr><tr><td>mov [_y],1</td><td>mov r2,[_x]</td></tr><tr><td>初始值 x=y=0</td></tr><tr><td>r1 = 1 并且 r2 = 0 是不允许的</td></tr></tbody></table><p>只有当处理器0的两个存储操作重排序，或者处理器1的两个加载操作重排的时候，返回值是非法的。</p><p>如果r1 = 1，那么对y的存储操作早于y的加载。因为Intel-64内存存取顺序模型不允许存储操作重排序，所以存储X的操作也应早于y，同事由于存储顺序模型不允许加载重排序，所以x的存储也早于x的加载，所以 r2 = 1.</p><h3 id="8-2-3-3-存储不能重排到加载之前"><a href="#8-2-3-3-存储不能重排到加载之前" class="headerlink" title="8.2.3.3 存储不能重排到加载之前"></a>8.2.3.3 存储不能重排到加载之前</h3><p>Intel-64 存储顺序模型确保处理器的存储操作不会在同一个处理器家在之前。</p><table><thead><tr><th>处理器0</th><th>处理器1</th></tr></thead><tbody><tr><td>mov r1,[x]</td><td>mov r2,[y]</td></tr><tr><td>mov [y],1</td><td>mov [x],1</td></tr><tr><td>初始值 x=y=0</td></tr><tr><td>r1 = 1 并且 r2 = 1 非法</td></tr></tbody></table><p>假设 r1 = 1</p><ul><li>因为r1 = 1， 处理器1的x存储早于处理器0的x的加载</li><li>因为intel-64 存取顺序模型避免存储操作被重排序到同一个处理器的加载操作之前，处理器1的y的加载早于对x的存储。</li><li>同理，处理器0的x的加载早于y的存储</li><li>因此，处理器1中y的加载在处理器0y存储之前，所以r2 = 0.</li></ul><h3 id="8-2-3-4-加载可以被重排序到不同地址的存储之前"><a href="#8-2-3-4-加载可以被重排序到不同地址的存储之前" class="headerlink" title="8.2.3.4 加载可以被重排序到不同地址的存储之前"></a>8.2.3.4 加载可以被重排序到不同地址的存储之前</h3><p>intel-64存取顺序重排允许加载操作重排序到不同地址的存储之前，但不允许重排序到同一个地址的存储之前。</p><table><thead><tr><th>处理器0</th><th>处理器1</th></tr></thead><tbody><tr><td>mov [x],1</td><td>mov [y],1</td></tr><tr><td>mov r1 [y]</td><td>mov r2,[x]</td></tr><tr><td>初始值 x=y=0</td></tr><tr><td>r1 = 0 并且 r2 = 0 允许</td></tr></tbody></table><p>在每个处理器中，对于不同的地址的加载和存储操作是允许重排序的。任何交替执行方式也因此被允许。其中一种交替执行的方式，是两个加载在两个存储之前。这样的结果就是r1和r2都返回0</p><table><thead><tr><th>处理器0</th></tr></thead><tbody><tr><td>mov [x], 1</td></tr><tr><td>mov r1,[x]</td></tr><tr><td>初始值 x = 0</td></tr><tr><td>r1 = 0 非法</td></tr></tbody></table><p>Intel64 存取顺序模型不允许加载重排序到同一个地址的存储之前，因此r1 = 1必须被加载。</p><h3 id="8-2-3-5-允许处理器内转发"><a href="#8-2-3-5-允许处理器内转发" class="headerlink" title="8.2.3.5 允许处理器内转发"></a>8.2.3.5 允许处理器内转发</h3><p>存取顺序模型允许两个处理器并行的存储，但从各自处理器看来存储的顺序是不一样的。每一个处理器可能都认为自己的存储操作早于另一个处理器的存储操作。举例说明：</p><table><thead><tr><th>处理器0</th><th>处理器1</th></tr></thead><tbody><tr><td>mov [x], 1</td><td>mov [y],1</td></tr><tr><td>mov r1,[x]</td><td>mov r3,[y]</td></tr><tr><td>mov r2,[y]</td><td>mov r4,[x]</td></tr></tbody></table><p>存储顺序模型不会在执行顺序上增加限制。这个情况允许处理器0认为它的存储操作早于处理器1，同事处理器1认为它的存储操作早于处理器0.这使得r2=0并且r4=0成为可能。<br>事实上，这个例子可以看做是存储缓存区转发。当处理器临时含有存储缓存的时候，它可以传递给处理器自己的加载操作，但它不能被其他的处理器看到并加载。</p><h3 id="8-2-3-6-内存存取顺序可见"><a href="#8-2-3-6-内存存取顺序可见" class="headerlink" title="8.2.3.6 内存存取顺序可见"></a>8.2.3.6 内存存取顺序可见</h3><p>存取顺序模型确保存储的可见性。一个处理器上的存储操作需要被所有的处理器可见，并且按照一定的合理的顺序。举例说明：</p><table><thead><tr><th>处理器0</th><th>处理器1</th><th>处理器2</th></tr></thead><tbody><tr><td>mov [x],1</td><td>mov r1,[x]</td><td></td></tr><tr><td></td><td>mov [y],1</td><td>mov r2,[y]</td></tr><tr><td></td><td></td><td>mov r3,[x]</td></tr><tr><td>初始值 x=y=0</td></tr><tr><td>r1 = 1并且r2 =1并且 r3=0 非法</td></tr></tbody></table><p>假设 r1=1 并且 r2 = 1.</p><ul><li>因为r1=1，处理器0的存储早于处理器1的加载</li><li>因为存取顺序模型避免存储被重排序到加载之前，处理器1中的加载早于存储。因此处理器0的存储的存储势必早于处理器1的存储。</li><li>因为处理器0的存储早于处理器1的存储，存储顺序模型确保处理器0的存储在所有处理器看来早于处理器1.</li><li>因为r2 = 1, 处理器1的存储早于处理器2的加载操作。</li><li>因为Intel-64存储模型避免加载操作重排序，处理器2的加载顺序执行。</li><li>综上分析，处理器0的存储在处理器2的加载之前，这就意味着r3 = 1.</li></ul><h3 id="8-2-3-7-存储顺序一致"><a href="#8-2-3-7-存储顺序一致" class="headerlink" title="8.2.3.7 存储顺序一致"></a>8.2.3.7 存储顺序一致</h3><p>正如8.2.3.5中提到，存取顺序模型允许两个处理器看到不同的处理顺序。然而，任意两个存储操作必须在所有处理器看来有一致的执行顺序。举例说明：</p><table><thead><tr><th>处理器0</th><th>处理器1</th><th>处理器2</th><th>处理器3</th></tr></thead><tbody><tr><td>mov [x],1</td><td>mov [y],1</td><td>mov r1,[x]</td><td>mov r3,[y]</td></tr><tr><td></td><td></td><td>mov r2,[y]</td><td>mov r4,[x]</td></tr><tr><td>初始值 x=y=0</td></tr><tr><td>r1=1并且r2=0并且r3=1并且r4=0 非法</td></tr></tbody></table><p>根据8.2.3.2中讨论的原则</p><ul><li>处理器2中的两个加载不可以被重排序</li><li>处理器3中的两个加载不可以被重排序</li><li>如果 r1=1 并且 r2=0，根据处理器2的加载，处理器0的存储在处理器1的存储之前。</li><li>同理，r3=1并且r4=0，意味着，根据处理器1的加载，处理器1的存储在处理器0的存储之前。<br>因此，内存存取顺序模型确保两个存储在所有处理器看来具有同样的顺序，所以这组返回值非法。</li></ul><h3 id="8-2-3-8-带锁的指令具有绝对顺序"><a href="#8-2-3-8-带锁的指令具有绝对顺序" class="headerlink" title="8.2.3.8 带锁的指令具有绝对顺序"></a>8.2.3.8 带锁的指令具有绝对顺序</h3><p>存取顺序模型确保所有的处理器处理对待锁指令的时候保持一致，包括大于8字节的或者没有自然对齐的指令。举例说明：</p><table><thead><tr><th>处理器0</th><th>处理器1</th><th>处理器2</th><th>处理器3</th></tr></thead><tbody><tr><td>xchg [x],r1</td><td>xchg [y],r2</td><td></td><td></td></tr><tr><td></td><td></td><td>mov r3,[x]</td><td>mov r5,[y]</td></tr><tr><td></td><td></td><td>mov r4,[y]</td><td>mov r6,[x]</td></tr><tr><td>初始值 r1=r2=1, x=y=0</td></tr><tr><td>r3=1 并且 r4=0 并且r5=1 并且r6=0 非法</td></tr></tbody></table><p>处理器2 和处理器3必须确保两个xchg指令的执行顺序。这里假定处理器1的xchg指令早于处理器3中y的加载指令发生。</p><ul><li>如果r5=1, 处理器1的xchg执行早于处理器3的加载，先发生。</li><li>因为intel64 内存顺序模型避免加载重排序，处理器3中按顺序加载。所以处理器1的xchg早于处理器3中x的加载，先发生。</li><li>根据假设，处理器0中的xchg早于处理器1xchg，并且是在处理器3的加载之前，所以r6=1</li></ul><h3 id="8-2-3-9-加载和存储不允许跟锁指令重排序"><a href="#8-2-3-9-加载和存储不允许跟锁指令重排序" class="headerlink" title="8.2.3.9 加载和存储不允许跟锁指令重排序"></a>8.2.3.9 加载和存储不允许跟锁指令重排序</h3><p>存取顺序模型避免加载和存储操作跟其前后的锁指令重排序。举例说明：<br>第一个例子说明，加载操作不可以跟之前的锁指令重排序</p><table><thead><tr><th>处理器0</th><th>处理器1</th></tr></thead><tbody><tr><td>xchg [x],r1</td><td>xchg [y],r3</td></tr><tr><td>mov r2,[y]</td><td>mov r4,[x]</td></tr><tr><td>初始值 x=y=0, r1=r3=1</td></tr><tr><td>r2=0 并且 r4=0 非法</td></tr></tbody></table><p>根据8.2.3.8的解释，锁指令有绝对的执行顺序，这里假设处理器0上的schg0先发生。<br>因为intel64 内存存取顺序模型避免处理器1的加载跟锁指令重排序，处理器0上的xchg在处理器1的加载之前，这意味着，r4=1.<br>相似的，如果处理器1的xchg先发生, 也可得非法返回值。</p><p>第二个例子说明存储操作不能跟之前的锁指令重排序。</p><table><thead><tr><th>处理器0</th><th>处理器1</th></tr></thead><tbody><tr><td>xchg [x],r1</td><td>mov r2,[y]</td></tr><tr><td>mov [y],1</td><td>mov r3,[x]</td></tr><tr><td>初始值 x=y=0, r1=1</td></tr><tr><td>r2=1 并且r3=0 非法</td></tr></tbody></table><p>假设r2=1</p><ul><li>因为r2=1， 处理器0的y存储早于处理器1的y的加载。</li><li>因为内存存取顺序模型避免存储跟前面的锁指令重排序，处理器0上的xchg早于y的加载发生。</li><li>因为内存存取顺序模型避免加载重排序，处理器1上按顺序加载，并且处理器1上的对x的xchg操作早于处理器1的x的加载，因为r3=1</li></ul><h2 id="8-2-4-快速字符串操作和乱序存储"><a href="#8-2-4-快速字符串操作和乱序存储" class="headerlink" title="8.2.4 快速字符串操作和乱序存储"></a>8.2.4 快速字符串操作和乱序存储</h2><p>SDM 第一卷7.3.9.3 章节中描述描述了优化重复执行fast-string操作。该章节中阐述，存储产生fast-string操作，可能会乱序执行。软件则需要串行化存储顺序，所以不可以使用字符操作来存储整个的数据结构。数据和信号量应该分隔开。有顺序依赖的代码在进行字符串操作之后，需要写到一个单独的信号量中，以保证所有处理看到正确的数据顺序。加载和存储操作的原子化，仅能保证本地字符串数据元素，并且他们还得在用一个缓存中。<br>8.2.4.1 和4.2.4.2提供的进一步的说明和例子。</p><h3 id="8-2-4-1-字符串的内存存取模型"><a href="#8-2-4-1-字符串的内存存取模型" class="headerlink" title="8.2.4.1 字符串的内存存取模型"></a>8.2.4.1 字符串的内存存取模型</h3><p>本章讲述字符串操作的内存存取模型。存取规则如下：</p><ol><li>单个字符串的存储可能是乱序执行。</li><li>一个独立的字符串的存储，例如保存一个连续的字符串，并不希望乱序。所有的存储操作都必须在完成上一次存储之后，进行新的存储操作。</li><li>字符串操作不可以跟其他存储操作重排序。</li></ol><p>快速字符串操作（例如，使用MOVS/STOS指令，并且使用REP前缀）可能会被中断或者异常而打断。中断是准确的，但可能会延迟，比如中断可能在每个几次循环或者在每操隔几次操作之后，在缓存的边界触发。不同的实现方式可能配置不同，或者甚至选择不延迟中断handle，所以软件不要依赖延迟。如果运行到中断或者陷入的处理函数，源/目的寄存器指向下一个等待处理的字符串元素。当EIP存储在指向指令的栈中,并且ECX寄存器还持有上一条指令成功时的值。中断或者陷阱处理函数应该引起字符串指令被恢复到它之前中断的地方。<br>字符串操作内存存取顺序规则（上面的2,3点）可以举例说明。如果一个快速字符串操作在第k次遍历时被中断，那么中断处理函数中的存储操作变为可见的（*）。<br>只有当快速字符串操作开启时，存储单个字符串的操作可能乱序执行。（上面的1）</p><h3 id="8-2-4-2-举例说明字符串操作中的内存存取策略"><a href="#8-2-4-2-举例说明字符串操作中的内存存取策略" class="headerlink" title="8.2.4.2 举例说明字符串操作中的内存存取策略"></a>8.2.4.2 举例说明字符串操作中的内存存取策略</h3><p>To-do</p><h2 id="8-2-5-加强型和减弱型内存存取模型"><a href="#8-2-5-加强型和减弱型内存存取模型" class="headerlink" title="8.2.5 加强型和减弱型内存存取模型"></a>8.2.5 加强型和减弱型内存存取模型</h2><p>Intel64和32体系结构提供了多种加强型或者减弱型的内存存取模型，以应对不同的程序条件。这些机制包括：</p><ul><li>I/O指令、锁指令，锁前缀以及串行化指令强制较强的存取顺序</li><li>SFENCE指令（IA32体系结构的奔腾3系列处理器）和LFENCE以及MFENCE指令（奔腾4处理器引入）提供内存存取顺序以及对某些特定指令的串行化的能力。</li><li>内存类型鸡寄存器（Memory type range registers，MTRR）可以在特定的物理内存区域中被用于增强或者减弱型的内存存取顺序。 MTRR只在奔腾4，Xeon 以及P6系列处理器中。</li><li>页属性表（page attribute table,PAT) 可以被用于页表或者页表组的增强型以及减弱型的内存存取顺序。PAT只在奔腾4，Xeon 以及P6系列处理器中。<br>这些机制可以如下使用：<br>映射到设备或者其他IO设备的内存地址通常顺序敏感。I/O指令（IN和OUt指令）强制使用写顺序。在执行一个I/O指令之前，处理器会等待所有的之前指令完成，并且所有的缓存写回内存中。但除了页表的获取和遍历指令。<br>多核处理器系统的同步机制可以依赖强内存存取顺序模型。这里应用程序可以使用锁指令，例如XCHG指令以及所前缀，来确保读-改-写才做。锁指令通常操作起来像I/O操作，他们同样等待之前的指令结束并且把所有的缓存写回内存中。<br>程序的同步也可以使用串行化指令（8.3章节）。这些指令通常在紧急的步骤中，或者边界任务，以确保所有之前的指令都完成，然后再跳转到新的代码段或者上下文切换。类似I/O或者锁指令，处理器会在之前的指令完成之前一直等待，并且把所有的缓存写回到内存中，然后再执行串行的指令。<br>SFENCE、LFENCE以及MFENCE指令提供了高效的方法来确保通常情况下产生的弱顺序以及数据的处理过程中的加载和存储顺序。这些指令的方法如下：</li><li>SFENCE：串行化所有的发生在SFENCE指令之前的程序指令流中的存储操作，但不影响加载操作。</li><li>LFENSE： 串行所有发生在在LFENCE指令之前的程序指令流中的加载操作，但不影响存储操作。</li><li>MFENCE： 串行化所有发生在MFENCE指令之前的存储和加载操作。</li></ul><p>注意，相比CPUID指令，SFENCE、LFENCE以及MFENCE指令提供了更搞笑的方法控制内存存取顺序。<br>MTRR在P6系列处理器中杯引入，来定义指定物理内存区域的缓存特性。下面的两个例子说明内存类型的设置可以使用增强或者减弱的内存存取顺序。</p><ul><li>非缓存（uncached）内存类型，强制内存访问中使用强顺序模型。这里所有读写非缓存内存区域，不可能使用乱序或者预测的方法。这种类型的内存可以被用于I/O设备映射。</li><li>回写（write back,WB)内存类型是弱存取顺序。这时，加载可以使用预测的方法，并且存储可以被缓存或者合并。这种类型的内存，缓存锁作为原子操作，不可以被中断，可以用来指令同步，同时降低的程序运行的速度，例如XCHG指令，它会在整个读-改-写的操作中锁住总线。使用写回内存类型，如果缓存命中，那么XCGH指令只是锁缓存，而并不需要锁总线</li></ul><p>PAT是在奔腾3处理器中被引入的，来增强缓存特性，可以用在页表或者页表组中。PAT机制通常用在页表层的增强特性，与MTRR相关。<br>Intel推荐软件运行在Intel Core 2 Duo, Intel Atom, Intel Core Duo, Pentium 4, Intel Xeon, and P6 family等系列处理器中，假定处理器顺序或者更弱的内存存取顺序模型。上述处理器没有实现强内存存取模型，除非使用非缓存内存。尽管其中一些处理器支持处理器顺序，但intel不保证未来的处理器会支持这种模型。为了让软件可以一直到未来的处理器，推荐操作系统提供紧急区域以及资源控制构造和基于I/O的API ，锁以及串行化指令，用来多处理器间同步访问共享的内存区域。并且，软件不应该依赖处理器顺序，当硬件系统不支持该种内存存取顺序模型。</p>]]></content>
      
      
      <categories>
          
          <category> SDM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SDM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>EFI Shell中使用tfpt.efi 自动化Kernel测试方案</title>
      <link href="/2019/05/07/efi-shell-tftp/"/>
      <url>/2019/05/07/efi-shell-tftp/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>对于Linux Kernel 或者OS相关的自动化测试，如何自动更新被测的Kernel以及OS image有时候是比较困难的事情。<br>Linux社区的”老神仙”Fengguang同学牵头开发了0-day自动化测试系统，系统期初的核心功能是利用kexec加载待测的kernel image二次启动。大概流程是:</p><div id="flowchart-0" class="flow-chart"></div><p>这个方法对于绝大多数kernel或者module测试中是工作的，也是非常灵活的。但有几个特例：</p><ol><li>由于Kexec的限制，上述方法对Xen支持的不好。</li><li>对于被测对象是hypervisor的情况，因为没有host OS的支持，无法加载ramfs</li></ol><p>这里大概验证了一个补充的方法，可以覆盖对于hypervisor等运行在Linux Kernel下层的组建进行自动化测试。</p><h2 id="EFI-以及EDKII"><a href="#EFI-以及EDKII" class="headerlink" title="EFI 以及EDKII"></a>EFI 以及EDKII</h2><p>我不是EFI或者EDKII的专家，这里就简单描述使用方法。另外之所以需要编译EDKII，是因为一般平台自带的EFI shell网络支持都不是很好。</p><h3 id="下载EDKII-source-code："><a href="#下载EDKII-source-code：" class="headerlink" title="下载EDKII source code："></a>下载EDKII source code：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/tianocore/edk2.git</span><br><span class="line">cd edk2</span><br><span class="line">git submodule update --init --recursive</span><br></pre></td></tr></table></figure><h3 id="编译edk2的编译工具"><a href="#编译edk2的编译工具" class="headerlink" title="编译edk2的编译工具"></a>编译edk2的编译工具</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">. edksetup.sh BaseTools</span><br><span class="line">cd BaseTools/</span><br><span class="line">make</span><br></pre></td></tr></table></figure><h3 id="编译EFI-Shell包"><a href="#编译EFI-Shell包" class="headerlink" title="编译EFI Shell包"></a>编译EFI Shell包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">build -p ShellPkg/ShellPkg.dsc  -t GCC5 -a IA32 -a X64</span><br></pre></td></tr></table></figure><p>然后就可以在目录<code>Build/Shell/RELEASE_GCC5/X64/</code> 中找到<code>shell.efi</code>和<code>tftp.efi</code>。可以将这两个文件copy到efi分区中，就可以使用了。</p><h3 id="加载shell-efi"><a href="#加载shell-efi" class="headerlink" title="加载shell.efi"></a>加载shell.efi</h3><p><code>shell.efi</code>也只是个EFI 的application，可以使用Linux下的工具<code>efibootmgr</code>让BIOS自动加载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">efibootmgr -c -l &quot;\EFI\shell.efi&quot; -d /dev/nvme0n1 -p 1  -L &quot;MY EFI SHELL&quot;</span><br></pre></td></tr></table></figure></p><p>大概意思是创建(<code>-c</code>)一个entry，加载(<code>-l</code>)EFI文件<code>\EFI\shell.efi</code>，磁盘(<code>-d</code>)<code>/dev/nvme0n1</code>的第1个分区(<code>-p 1</code>)，标签命名为(<code>-L &quot;MY EFI SHELL&quot;</code>)</p><p>另外还有两个常用命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">efibootmgr -v</span><br><span class="line">efibootmgr -o 0001,0002,0005,0003,0004,0000</span><br></pre></td></tr></table></figure></p><p><code>-v</code> 列出当前的启动顺序，一般新加入的都是第一个启动<br><code>-o</code> 后面列出来重新排列的启动顺序，需要需要从上一条命令中查到。</p><h3 id="确认网络工作"><a href="#确认网络工作" class="headerlink" title="确认网络工作"></a>确认网络工作</h3><p>执行命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig -l</span><br></pre></td></tr></table></figure></p><p>可以列出来所有的网络接口。默认会自动dhcp，如果没有可以使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig -i etho dhcp</span><br></pre></td></tr></table></figure></p><p>来手动获取IP地址。</p><p>tips: 如果在BIOS里面设置关闭PXE网络启动的话，网络驱动就不会加载了，所以，建议在BIOS里面enable PXE boot，尽管我们并不使用它。</p><h2 id="TFTP"><a href="#TFTP" class="headerlink" title="TFTP"></a>TFTP</h2><p>接下来简单说下TFTP的使用方法</p><h3 id="搭建TFTP-server"><a href="#搭建TFTP-server" class="headerlink" title="搭建TFTP server"></a>搭建TFTP server</h3><p>以Ubuntu为例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">安装：</span><br><span class="line">apt-get install tftp-hpa tftpd-hpa</span><br><span class="line"></span><br><span class="line">创建目录：</span><br><span class="line">mkdir /tftpboot # 这是建立tftp传输目录。</span><br><span class="line">sudo chmod 0777 /tftpboot</span><br><span class="line">sudo touch test.txt # test.txt文件最好输入内容以便区分</span><br><span class="line"></span><br><span class="line">配置：</span><br><span class="line">vim /etc/default/tftpd-hpa3</span><br><span class="line">TFTP_USERNAME=&quot;tftp&quot;</span><br><span class="line">TFTP_DIRECTORY=&quot;/tftpboot&quot; # 这里是你的tftpd-hpa的服务目录,这个想建立在哪里都行</span><br><span class="line">TFTP_ADDRESS=&quot;0.0.0.0:69&quot;</span><br><span class="line">TFTP_OPTIONS=&quot;-l -c -s&quot; # 这里是选项,-c是可以上传文件的参数，-s是指定tftpd-hpa服务目录，上面已经指定</span><br><span class="line"></span><br><span class="line">重启服务</span><br><span class="line">sudo service tftpd-hpa restart # 启动服务，这里要注意，采用的独立服务形式。</span><br><span class="line"></span><br><span class="line">测试</span><br><span class="line">$ tftp 127.0.0.1</span><br><span class="line">tftp&gt;get test.txt</span><br><span class="line">tftp&gt;put test1.txt</span><br></pre></td></tr></table></figure></p><h3 id="EFI-Shell-中使用tftp-efi"><a href="#EFI-Shell-中使用tftp-efi" class="headerlink" title="EFI Shell 中使用tftp.efi"></a>EFI Shell 中使用tftp.efi</h3><p>在EFI shell中进入tftp.efi所在目录然后执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tftp.efi &lt;tftp server IP&gt; &lt;文件名字&gt;</span><br></pre></td></tr></table></figure></p><p>就可以下载文件了。</p><h2 id="自动化kernel-测试方案："><a href="#自动化kernel-测试方案：" class="headerlink" title="自动化kernel 测试方案："></a>自动化kernel 测试方案：</h2><p>在EFI Shell的根目录中，比如fs0: 中添加一个文件 startup.nsh 内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">if not exist fs0:\EFI\tftp.efi then</span><br><span class="line">        echo &quot;No tftp.efi&quot;</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">fs0:</span><br><span class="line">cd \EFI</span><br><span class="line"></span><br><span class="line">tftp.efi 10.239.159.139 kernel_images/bzImage_current bzImage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">:boot_os</span><br><span class="line">        cd \EFI\ubuntu</span><br><span class="line">        grubx64.efi</span><br></pre></td></tr></table></figure></p><p>这样Ubuntu grub加载的时候，就可以使用刚刚下载来的kernel了，因为grub和efi都可以使用FAT分区格式。</p><p>当系统死掉了，并且需要更新kernel的时候，只需要覆盖tftp server上的bzimage_current或者改变其软连接的指向，然后重启系统，就可以一次性更新kernel。</p><h2 id="Todo"><a href="#Todo" class="headerlink" title="Todo"></a>Todo</h2><p>目前EFI shell能做的事情相比Linux shell还相差甚远，没有太多现成的application可以直接使用。<br>tftp.efi也能是download，并不能upload，这使得EFI直接并不能对server进行通知，需要借助OS。<br>后面，可以增加application，实现类似Linux工具curl，或者patch tfpt让它可以上传文件，这样就可以双向通信了。</p><h2 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h2><p>EDKII是不是有点bug似乎，附上我build的efi shell 以及tftp，有需要的小伙伴可以直接点击下载<br>64bit: <a href="efi_x64/Shell.efi">shell.efi</a>  <a href="efi_x64/tftp.efi">tftp.efi</a><br>32bit: <a href="efi_ia32/Shell.efi">shell.efi</a>  <a href="efi_ia32/tftp.efi">tftp.efi</a></p><p><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.8/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.11.3/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: 系统启动op1=>operation: 启动small size的kernel + ramfsop2=>operation: 初始化网络并获取IP地址op3=>operation: 从服务器上获取可用的kernel image列表op4=>operation: 根据列表的配置获取待测的kernel imageop5=>operation: 在ramfs初始化的最后阶段使用Kexec加载待测的kernel image启动本地文件系统e=>end: 系统启动结束st->op1->op2->op3->op4->op5->e</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script></p>]]></content>
      
      
      <categories>
          
          <category> efi </category>
          
      </categories>
      
      
        <tags>
            
            <tag> efi </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KVM(Kernel-based Virtual Machine)源码分析</title>
      <link href="/2019/02/20/kvm-src-analysis/"/>
      <url>/2019/02/20/kvm-src-analysis/</url>
      
        <content type="html"><![CDATA[<p>(编者按：写完才发现，这篇分析写的又臭又长…… 原谅语言凝练不足和code阅读还没有炉火纯青，我会慢慢提炼，有兴趣的同学可以评论区吐槽:)</p><p>在看code之前，先把KVM-QEMU的source code的大框架拎出来，给读者直观一点的感受，本文最后还有一个稍微详细的call graph。中间这些文字是帮助读者以及我自己阅读和理解code的，大多数是kernel source code，因为Qemu相关的在之前的日志中已经涉及到了。<br><img src="/2019/02/20/kvm-src-analysis/kvm-qemu-brief.svg" alt=""></p><h2 id="VMCS"><a href="#VMCS" class="headerlink" title="VMCS"></a>VMCS</h2><p>对于Intel的虚拟化技术(VT)而言，它的软件部分基本体现在VMCS结构中(Virtual Machine Control Block)。主要通过VMCS结构来控制VCPU的运转。</p><ul><li>VMCS是个不超过4K的内存块。</li><li>VMCS通过下列的指令控制:<ul><li>VMCLEAR: 清空VMCS结构</li><li>VMREAD: 读取VMCS数据</li><li>VMWRITE: 数据写入VMCS</li></ul></li><li>通过VMPTR指针指向VMCS结构，该指针包含VMCS的物理地址。</li></ul><h3 id="VMCS包含的信息可以分为六个部分"><a href="#VMCS包含的信息可以分为六个部分" class="headerlink" title="VMCS包含的信息可以分为六个部分:"></a>VMCS包含的信息可以分为六个部分:</h3><ul><li>Guest state area：虚拟机状态域，保存非根模式的vcpu运行状态。当VM-Exit发生，vcpu的运行状态要写入这个区域，当VM-Entry发生时，cpu会把这个区域保存的信息加载到自身，从而进入非根模式。这个过程是硬件自动完成的,软件只需要修改这个区域的信息就可以控制cpu的运转。</li><li>Host state area：宿主机状态域，保存根模式下cpu的运行状态。在vm-exit时需要将状态加载到CPU。大概包含如下寄存器：<ul><li>CR0, CR3, CR4, RSP, RIP (都是64bit的，不支持32位)</li><li>段选择器CS, SS, DS, ES, FS, GS, TR，不包含LDTR。</li><li>基址部分FS, GS, TR, GDTR 和IDTR</li><li>一些MSR: IA32_SYSENTER_CS, IA32_SYSENTER_ESP,IA32_SYSENTER_EIP, IA32_PERF_GLOBAL_CTRL, IA32_PAT, IA32_EFER。</li></ul></li><li>VM-Execution control filelds：包括page fault控制，I/O位图地址，CR3目标控制，异常位图，pin-based运行控制(异步事件)，processor-based运行控制(同步事件)。这个域可以设置哪些指令触发VM-Exit。触发VM-Exit的指令分为无条件指令和有条件指令，这里设置的是有条件指令。（SDM 24.6）</li><li>VM-entry contorl filelds：包括‘vm-entry控制’，‘vm-entry MSR控制’和‘VM-Entry事件注入’。（SDM 24.8）</li><li>VM-exit control filelds：包括’VM-Exit控制’，’VM-Exit MSR控制’。(SDM 24.7)</li><li>VM退出信息：这个域保存VM-Exit退出时的信息，并且描述原因。(SDM 24.9)</li></ul><p>有了VMCS结构后，对虚拟机的控制就是读写VMCS结构。后面对VCPU设置中断，检查状态实际上都是在读写VMCS结构。在vmx.c文件给出了intel定义的VMCS结构的内容。 <code>struct __packed vmcs12</code></p><h2 id="CPU-虚拟化"><a href="#CPU-虚拟化" class="headerlink" title="CPU 虚拟化"></a>CPU 虚拟化</h2><h3 id="创建VM"><a href="#创建VM" class="headerlink" title="创建VM"></a>创建VM</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">virt/kvm/kvm_main.c: (有所省略)</span><br><span class="line">static int kvm_dev_ioctl_create_vm(void)</span><br><span class="line">&#123;</span><br><span class="line">int fd;</span><br><span class="line">struct kvm *kvm;</span><br><span class="line"></span><br><span class="line"> kvm = kvm_create_vm(type);</span><br><span class="line"> if (IS_ERR(kvm))</span><br><span class="line">         return PTR_ERR(kvm);</span><br><span class="line"></span><br><span class="line"> r = kvm_coalesced_mmio_init(kvm);</span><br><span class="line"></span><br><span class="line"> r = get_unused_fd_flags(O_CLOEXEC);</span><br><span class="line"></span><br><span class="line">         /*生成kvm-vm控制文件*/</span><br><span class="line"> file = anon_inode_getfile(&quot;kvm-vm&quot;, &amp;kvm_vm_fops, kvm, O_RDWR);</span><br><span class="line"></span><br><span class="line">return fd;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用了函数kvm_create_vm，然后是创建一个文件，这个文件的作用是提供对vm的io_ctl控制。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">virt/kvm/kvm_main.c:(简略)</span><br><span class="line">static struct kvm *kvm_create_vm(void)</span><br><span class="line">&#123;</span><br><span class="line">int r, i;</span><br><span class="line">----&gt;struct kvm *kvm = kvm_arch_create_vm();</span><br><span class="line"></span><br><span class="line">        /*设置kvm的mm结构为当前进程的mm,然后引用计数为1*/</span><br><span class="line">----&gt;kvm-&gt;mm = current-&gt;mm;</span><br><span class="line">----&gt;kvm_eventfd_init(kvm);</span><br><span class="line">mutex_init(&amp;kvm-&gt;lock);</span><br><span class="line">mutex_init(&amp;kvm-&gt;irq_lock);</span><br><span class="line">mutex_init(&amp;kvm-&gt;slots_lock);</span><br><span class="line">refcount_set(&amp;kvm-&gt;users_count, 1);</span><br><span class="line">INIT_LIST_HEAD(&amp;kvm-&gt;devices);</span><br><span class="line">INIT_HLIST_HEAD(&amp;kvm-&gt;irq_ack_notifier_list);</span><br><span class="line"></span><br><span class="line">r = kvm_arch_init_vm(kvm, type);</span><br><span class="line"></span><br><span class="line">r = hardware_enable_all()</span><br><span class="line"></span><br><span class="line">for (i = 0; i &lt; KVM_NR_BUSES; i++) &#123;</span><br><span class="line">rcu_assign_pointer(kvm-&gt;buses[i],</span><br><span class="line">----&gt;kzalloc(sizeof(struct kvm_io_bus), GFP_KERNEL));</span><br><span class="line">&#125;</span><br><span class="line">kvm_init_mmu_notifier(kvm); </span><br><span class="line"></span><br><span class="line">        /*把kvm链表加入总链表*/</span><br><span class="line">list_add(&amp;kvm-&gt;vm_list, &amp;vm_list);</span><br><span class="line"></span><br><span class="line">return kvm;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，这个函数首先是申请一个kvm结构。然后执行初始化工作。<br>初始化第一步是把kvm的mm结构设置为当前进程的mm。我们知道，mm结构反应了整个进程的内存使用情况，也包括进程使用的页目录信息。<br>然后是初始化io bus和eventfd。这两者和设备io有关。<br>最后把kvm加入到一个全局链表头。通过这个链表头，可以遍历所有的vm虚拟机。</p><h3 id="创建VCPU"><a href="#创建VCPU" class="headerlink" title="创建VCPU"></a>创建VCPU</h3><p>创建VM之后，就是创建VCPU。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">virt/kvm/kvm_main.c:</span><br><span class="line">static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)</span><br><span class="line">&#123;</span><br><span class="line">int r;</span><br><span class="line">struct kvm_vcpu *vcpu, *v;</span><br><span class="line">       /*调用相关cpu的vcpu_create 通过arch/x86/x86.c 进入vmx.c*/</span><br><span class="line">----&gt;vcpu = kvm_arch_vcpu_create(kvm, id);</span><br><span class="line"></span><br><span class="line">       /*调用相关cpu的vcpu_setup*/</span><br><span class="line">r = kvm_arch_vcpu_setup(vcpu);</span><br><span class="line"></span><br><span class="line">       /*判断是否达到最大cpu个数*/</span><br><span class="line">mutex_lock(&amp;kvm-&gt;lock);</span><br><span class="line">if (atomic_read(&amp;kvm-&gt;online_vcpus) == KVM_MAX_VCPUS) &#123;</span><br><span class="line">r = -EINVAL;</span><br><span class="line">goto vcpu_destroy;</span><br><span class="line">&#125;</span><br><span class="line">----&gt;kvm-&gt;created_vcpus++;    </span><br><span class="line">mutex_unlock(&amp;kvm-&gt;lock);</span><br><span class="line"></span><br><span class="line">       /*生成kvm-vcpu控制文件*/</span><br><span class="line">/* Now it&apos;s all set up, let userspace reach it */</span><br><span class="line">----&gt;kvm_get_kvm(kvm);</span><br><span class="line">r = create_vcpu_fd(vcpu);</span><br><span class="line"></span><br><span class="line">        kvm_get_kvm(kvm);</span><br><span class="line">        r = create_vcpu_fd(vcpu);</span><br><span class="line">        if (r &lt; 0) &#123;</span><br><span class="line">                kvm_put_kvm(kvm);</span><br><span class="line">                goto unlock_vcpu_destroy;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        kvm-&gt;vcpus[atomic_read(&amp;kvm-&gt;online_vcpus)] = vcpu;</span><br><span class="line"></span><br><span class="line">        /*</span><br><span class="line">         * Pairs with smp_rmb() in kvm_get_vcpu.  Write kvm-&gt;vcpus</span><br><span class="line">         * before kvm-&gt;online_vcpu&apos;s incremented value.</span><br><span class="line">         */</span><br><span class="line">        smp_wmb();</span><br><span class="line">        atomic_inc(&amp;kvm-&gt;online_vcpus);</span><br><span class="line"></span><br><span class="line">        mutex_unlock(&amp;kvm-&gt;lock);</span><br><span class="line">        kvm_arch_vcpu_postcreate(vcpu);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码可见，分别调用相关cpu提供的vcpu_create和vcpu_setup来完成vcpu创建。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/vmx.c:</span><br><span class="line">static struct kvm_vcpu *vmx_create_vcpu(struct kvm *kvm, unsigned int id)</span><br><span class="line">&#123;</span><br><span class="line">int err;</span><br><span class="line">       /*申请一个vmx结构*/</span><br><span class="line">struct vcpu_vmx *vmx = kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL);</span><br><span class="line">int cpu;</span><br><span class="line"></span><br><span class="line">err = kvm_vcpu_init(&amp;vmx-&gt;vcpu, kvm, id);</span><br><span class="line">      /*申请guest的msrs,host的msrs*/ </span><br><span class="line">vmx-&gt;guest_msrs = kmalloc(PAGE_SIZE, GFP_KERNEL);</span><br><span class="line">vmx-&gt;host_msrs = kmalloc(PAGE_SIZE, GFP_KERNEL);</span><br><span class="line"></span><br><span class="line">       /*申请一个vmcs结构*/</span><br><span class="line">err = alloc_loaded_vmcs(&amp;vmx-&gt;vmcs01);</span><br><span class="line"></span><br><span class="line">cpu = get_cpu();</span><br><span class="line">vmx_vcpu_load(&amp;vmx-&gt;vcpu, cpu);</span><br><span class="line">       /*设置vcpu为实模式，设置各种寄存器*/</span><br><span class="line">err = vmx_vcpu_setup(vmx);</span><br><span class="line">vmx_vcpu_put(&amp;vmx-&gt;vcpu);</span><br><span class="line">put_cpu();</span><br><span class="line"></span><br><span class="line">/*为中断分配slot，当虚拟机访问中断的时候，会map到vmcs中的相应地址中*/</span><br><span class="line">if (cpu_need_virtualize_apic_accesses(&amp;vmx-&gt;vcpu)) &#123;</span><br><span class="line">        err = alloc_apic_access_page(kvm);</span><br><span class="line">        if (err)</span><br><span class="line">                goto free_vmcs;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (enable_ept &amp;&amp; !enable_unrestricted_guest) &#123;</span><br><span class="line">        err = init_rmode_identity_map(kvm);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (nested)</span><br><span class="line">        nested_vmx_setup_ctls_msrs(&amp;vmx-&gt;nested.msrs,</span><br><span class="line">                                   kvm_vcpu_apicv_active(&amp;vmx-&gt;vcpu));</span><br><span class="line"></span><br><span class="line">vmx-&gt;msr_ia32_feature_control_valid_bits = FEATURE_CONTROL_LOCKED;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先申请一个vcpu_vmx结构，然后初始化vcpu_vmx。<br>MSR寄存器是cpu模式寄存器，所以要分别为guest 和host申请页面，这个页面要保存MSR寄存器的信息。然后申请一个vmcs结构。然后调用vmx_vcpu_setup设置vcpu工作在实模式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/vmx.c:</span><br><span class="line">static int vmx_vcpu_setup(struct vcpu_vmx *vmx)</span><br><span class="line">&#123;     </span><br><span class="line">/* Control */</span><br><span class="line">vmcs_write32(PIN_BASED_VM_EXEC_CONTROL, vmx_pin_based_exec_ctrl(vmx))</span><br><span class="line"></span><br><span class="line">vmx-&gt;hv_deadline_tsc = -1;</span><br><span class="line"></span><br><span class="line">vmcs_write32(CPU_BASED_VM_EXEC_CONTROL, vmx_exec_control(vmx));</span><br><span class="line"></span><br><span class="line">if (cpu_has_secondary_exec_ctrls()) &#123;</span><br><span class="line">        vmx_compute_secondary_exec_control(vmx);</span><br><span class="line">        vmcs_write32(SECONDARY_VM_EXEC_CONTROL,</span><br><span class="line">                     vmx-&gt;secondary_exec_control);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> if (kvm_vcpu_apicv_active(&amp;vmx-&gt;vcpu)) &#123;</span><br><span class="line">         vmcs_write64(EOI_EXIT_BITMAP0, 0);</span><br><span class="line">         vmcs_write64(EOI_EXIT_BITMAP1, 0);</span><br><span class="line">         vmcs_write64(EOI_EXIT_BITMAP2, 0);</span><br><span class="line">         vmcs_write64(EOI_EXIT_BITMAP3, 0);</span><br><span class="line"></span><br><span class="line">         vmcs_write16(GUEST_INTR_STATUS, 0);</span><br><span class="line"></span><br><span class="line">         vmcs_write16(POSTED_INTR_NV, POSTED_INTR_VECTOR);</span><br><span class="line">         vmcs_write64(POSTED_INTR_DESC_ADDR, __pa((&amp;vmx-&gt;pi_desc)));</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> if (!kvm_pause_in_guest(vmx-&gt;vcpu.kvm)) &#123;</span><br><span class="line">         vmcs_write32(PLE_GAP, ple_gap);</span><br><span class="line">         vmx-&gt;ple_window = ple_window;</span><br><span class="line">         vmx-&gt;ple_window_dirty = true;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> vmcs_write32(PAGE_FAULT_ERROR_CODE_MASK, 0);</span><br><span class="line"> vmcs_write32(PAGE_FAULT_ERROR_CODE_MATCH, 0);</span><br><span class="line"> vmcs_write32(CR3_TARGET_COUNT, 0);           /* 22.2.1 */</span><br><span class="line"></span><br><span class="line"> vmcs_write16(HOST_FS_SELECTOR, 0);            /* 22.2.4 */</span><br><span class="line"> vmcs_write16(HOST_GS_SELECTOR, 0);            /* 22.2.4 */</span><br><span class="line"> vmx_set_constant_host_state(vmx);</span><br><span class="line"> vmcs_writel(HOST_FS_BASE, 0); /* 22.2.4 */</span><br><span class="line"> vmcs_writel(HOST_GS_BASE, 0); /* 22.2.4 */</span><br><span class="line"> </span><br><span class="line">if (cpu_has_vmx_vmfunc())</span><br><span class="line">        vmcs_write64(VM_FUNCTION_CONTROL, 0);</span><br><span class="line"></span><br><span class="line">vmcs_write32(VM_EXIT_MSR_STORE_COUNT, 0);</span><br><span class="line">vmcs_write32(VM_EXIT_MSR_LOAD_COUNT, 0);</span><br><span class="line">vmcs_write64(VM_EXIT_MSR_LOAD_ADDR, __pa(vmx-&gt;msr_autoload.host.val));</span><br><span class="line">        vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, 0);</span><br><span class="line">        vmcs_write64(VM_ENTRY_MSR_LOAD_ADDR, __pa(vmx-&gt;msr_autoload.guest.val));</span><br><span class="line"></span><br><span class="line">        if (vmcs_config.vmentry_ctrl &amp; VM_ENTRY_LOAD_IA32_PAT)</span><br><span class="line">                vmcs_write64(GUEST_IA32_PAT, vmx-&gt;vcpu.arch.pat);</span><br><span class="line"></span><br><span class="line">        for (i = 0; i &lt; ARRAY_SIZE(vmx_msr_index); ++i) &#123;</span><br><span class="line">                u32 index = vmx_msr_index[i];</span><br><span class="line">                u32 data_low, data_high;</span><br><span class="line">                int j = vmx-&gt;nmsrs;</span><br><span class="line"></span><br><span class="line">                if (rdmsr_safe(index, &amp;data_low, &amp;data_high) &lt; 0)</span><br><span class="line">                        continue;</span><br><span class="line">                if (wrmsr_safe(index, data_low, data_high) &lt; 0)</span><br><span class="line">                        continue;</span><br><span class="line">                vmx-&gt;guest_msrs[j].index = i;</span><br><span class="line">                vmx-&gt;guest_msrs[j].data = 0;</span><br><span class="line">                vmx-&gt;guest_msrs[j].mask = -1ull;</span><br><span class="line">                ++vmx-&gt;nmsrs;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">         vmx-&gt;arch_capabilities = kvm_get_arch_capabilities();</span><br><span class="line"></span><br><span class="line">         vm_exit_controls_init(vmx, vmcs_config.vmexit_ctrl);</span><br><span class="line"></span><br><span class="line">         /* 22.2.1, 20.8.1 */</span><br><span class="line">         vm_entry_controls_init(vmx, vmcs_config.vmentry_ctrl);</span><br><span class="line"></span><br><span class="line">         vmx-&gt;vcpu.arch.cr0_guest_owned_bits = X86_CR0_TS;</span><br><span class="line">         vmcs_writel(CR0_GUEST_HOST_MASK, ~X86_CR0_TS);</span><br><span class="line"></span><br><span class="line">         set_cr4_guest_host_mask(vmx);</span><br><span class="line"></span><br><span class="line">         if (vmx_xsaves_supported())</span><br><span class="line">                 vmcs_write64(XSS_EXIT_BITMAP, VMX_XSS_EXIT_BITMAP);</span><br><span class="line"></span><br><span class="line">if (enable_pml) &#123;</span><br><span class="line">        vmcs_write64(PML_ADDRESS, page_to_phys(vmx-&gt;pml_pg));</span><br><span class="line">         vmcs_write16(GUEST_PML_INDEX, PML_ENTITY_NUM - 1);</span><br><span class="line"> &#125;</span><br><span class="line"> if (cpu_has_vmx_encls_vmexit())</span><br><span class="line">        vmcs_write64(ENCLS_EXITING_BITMAP, -1ull);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数到这里之所以列这么而详细，其实因为也不是很确定需要保留那几个，那就索性加深下印象吧，记住Kernel对虚拟机VT-X是如何操作的——读写VMCS结构体。一堆的寄存器和控制信息，具体的都在SDM Vol3 第24章里面描述的。只重点聊下其中的几个地方：<br>设置CPU_BASED控制器（VMCS的一部分）；GUEST中断状态寄存器；CR3,CR0 以及各种段选寄存器CS, DS, ES；之后，要保存host的MSR寄存器的值到前面分配的guest_msrs页面; Guest PML地址等等……</p><h3 id="VCPU运行"><a href="#VCPU运行" class="headerlink" title="VCPU运行"></a>VCPU运行</h3><p>推动vcpu运行，启动虚拟机开始运行，主要在vcpu_run函数执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/x86.c:</span><br><span class="line">static int vcpu_run(struct kvm_vcpu *vcpu)</span><br><span class="line">&#123;</span><br><span class="line">        int r;</span><br><span class="line">        struct kvm *kvm = vcpu-&gt;kvm;</span><br><span class="line">        for (;;) &#123;</span><br><span class="line">/*vcpu进入guest模式*/ </span><br><span class="line">                if (kvm_vcpu_running(vcpu)) &#123;</span><br><span class="line">----&gt;                   r = vcpu_enter_guest(vcpu);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                        r = vcpu_block(kvm, vcpu);</span><br><span class="line">                &#125;</span><br><span class="line">                kvm_clear_request(KVM_REQ_PENDING_TIMER, vcpu);</span><br><span class="line"></span><br><span class="line">/*检查是否有阻塞的时钟timer*/</span><br><span class="line">                if (kvm_cpu_has_pending_timer(vcpu))</span><br><span class="line">                        kvm_inject_pending_timer_irqs(vcpu);</span><br><span class="line"></span><br><span class="line">/*检查是否有用户空间的中断注入*/ </span><br><span class="line">                if (dm_request_for_irq_injection(vcpu) &amp;&amp;</span><br><span class="line">                        kvm_vcpu_ready_for_interrupt_injection(vcpu)) &#123;</span><br><span class="line">                        r = 0;</span><br><span class="line">                        vcpu-&gt;run-&gt;exit_reason = KVM_EXIT_IRQ_WINDOW_OPEN;</span><br><span class="line">                        ++vcpu-&gt;stat.request_irq_exits;</span><br><span class="line">                        break;</span><br><span class="line">                &#125;</span><br><span class="line">                kvm_check_async_pf_completion(vcpu);</span><br><span class="line"></span><br><span class="line">/*是否有阻塞的signal*/</span><br><span class="line">                if (signal_pending(current)) &#123;</span><br><span class="line">                        r = -EINTR;</span><br><span class="line">                        vcpu-&gt;run-&gt;exit_reason = KVM_EXIT_INTR;</span><br><span class="line">                        ++vcpu-&gt;stat.signal_exits;</span><br><span class="line">                        break;</span><br><span class="line">                &#125;</span><br><span class="line">/*执行一个调度*/</span><br><span class="line">                 if (need_resched()) &#123;</span><br><span class="line">                         cond_resched();</span><br><span class="line">                 &#125;</span><br><span class="line">         &#125;</span><br></pre></td></tr></table></figure><p>这里理解的关键是vcpu_enter_guest进入了Guest，然后一直是vcpu在运行，当退出这个函数的时候，虚拟机已经执行了VM-Exit指令，也就是说，已经退出了虚拟机，进入根模式了。<br>退出之后，要检查退出的原因。如果有时钟中断发生，则插入一个时钟中断，如果是用户空间的中断发生，则退出原因要填写为KVM_EXIT_INTR。<br>注意一点的是，对于导致退出的事件，vcpu_enter_guest函数里面已经处理了一部分，处理的是虚拟机本身运行导致退出的事件。虚拟机一旦退出后，执行vmx_handle_exit。比如虚拟机内部写磁盘io导致退出，就在vcpu_enter_guest里面处理（只是设置了退出的原因为io，并没有真正执行io）。KVM是如何知道退出的原因的？这个就是vmcs结构的作用了，vmcs结构里面有VM-Exit的信息。<br>退出VM之后，如果内核没有完成处理，那么要退出内核到QEMU进程。然后是QEMU进程要处理.后面io处理时，我们再看下QEMU的处理过程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/x86.carch/x86/kvm/x86.c:</span><br><span class="line">static int vcpu_enter_guest(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run)</span><br><span class="line">&#123;</span><br><span class="line"> r = kvm_mmu_reload(vcpu);</span><br><span class="line"></span><br><span class="line"> preempt_disable();</span><br><span class="line"></span><br><span class="line"> kvm_x86_ops-&gt;prepare_guest_switch(vcpu);</span><br><span class="line"></span><br><span class="line"> /*</span><br><span class="line">  * Disable IRQs before setting IN_GUEST_MODE.  Posted interrupt</span><br><span class="line">  * IPI are then delayed after guest entry, which ensures that they</span><br><span class="line">  * result in virtual interrupt delivery.</span><br><span class="line">  */</span><br><span class="line"> local_irq_disable();</span><br><span class="line"> vcpu-&gt;mode = IN_GUEST_MODE;</span><br><span class="line"></span><br><span class="line"> /*</span><br><span class="line">  * This handles the case where a posted interrupt was</span><br><span class="line">  * notified with kvm_vcpu_kick.</span><br><span class="line">  */</span><br><span class="line"> if (kvm_lapic_enabled(vcpu) &amp;&amp; vcpu-&gt;arch.apicv_active)</span><br><span class="line">         kvm_x86_ops-&gt;sync_pir_to_irr(vcpu);</span><br><span class="line"></span><br><span class="line"> kvm_load_guest_xcr0(vcpu);</span><br><span class="line"></span><br><span class="line"> trace_kvm_entry(vcpu-&gt;vcpu_id);</span><br><span class="line"> if (lapic_timer_advance_ns)</span><br><span class="line">         wait_lapic_expire(vcpu);</span><br><span class="line"> guest_enter_irqoff();</span><br><span class="line"></span><br><span class="line"> /* KVM故事的核心*/</span><br><span class="line">----&gt; kvm_x86_ops-&gt;run(vcpu);</span><br><span class="line"></span><br><span class="line"> vcpu-&gt;arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());</span><br><span class="line"></span><br><span class="line"> vcpu-&gt;mode = OUTSIDE_GUEST_MODE;</span><br><span class="line"> smp_wmb();</span><br><span class="line"></span><br><span class="line"> kvm_put_guest_xcr0(vcpu);</span><br><span class="line"></span><br><span class="line"> kvm_before_interrupt(vcpu);</span><br><span class="line"> kvm_x86_ops-&gt;handle_external_intr(vcpu);</span><br><span class="line"> kvm_after_interrupt(vcpu);</span><br><span class="line"></span><br><span class="line"> ++vcpu-&gt;stat.exits;</span><br><span class="line"></span><br><span class="line"> guest_exit_irqoff();</span><br><span class="line"></span><br><span class="line"> local_irq_enable();</span><br><span class="line"> preempt_enable();</span><br><span class="line"></span><br><span class="line"> /*</span><br><span class="line">  * Profile KVM exit RIPs:</span><br><span class="line">  */</span><br><span class="line"> if (unlikely(prof_on == KVM_PROFILING)) &#123;</span><br><span class="line">         unsigned long rip = kvm_rip_read(vcpu);</span><br><span class="line">         profile_hit(KVM_PROFILING, (void *)rip);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);</span><br><span class="line"></span><br><span class="line"> kvm_lapic_sync_from_vapic(vcpu);</span><br><span class="line"></span><br><span class="line"> vcpu-&gt;arch.gpa_available = false;</span><br><span class="line"> /* KVM故事兜底的包袱*/</span><br><span class="line">----&gt; r = kvm_x86_ops-&gt;handle_exit(vcpu);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先要装载mmu，然后注入事件，像中断，异常什么的。然后调用cpu架构相关的run函数(vmx_vcpu_run)，这个函数里面调用__vmx_vcpu_run这是一个用汇编实现的函数在vmx/vmenter.S里面，用来进入虚拟机以及指定从虚拟机退出的执行地址。最后调用cpu的handle_exit，用来从vmcs读取退出的信息。<br>下面展开函数vmx_vcpu_run，这个函数实在是……需要对照SDM一行一行的看，已无力分析，那就看原文中的注释简单的了解个大概就好了，他日如果有机会做这部分code，定努力哈哈哈~~<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/vmx.c:</span><br><span class="line">static void __noclone vmx_vcpu_run(struct kvm_vcpu *vcpu)</span><br><span class="line">&#123;</span><br><span class="line">        struct vcpu_vmx *vmx = to_vmx(vcpu);</span><br><span class="line">        unsigned long cr3, cr4, evmcs_rsp;</span><br><span class="line"></span><br><span class="line">        /* Record the guest&apos;s net vcpu time for enforced NMI injections. */</span><br><span class="line">        if (unlikely(!enable_vnmi &amp;&amp;</span><br><span class="line">                     vmx-&gt;loaded_vmcs-&gt;soft_vnmi_blocked))</span><br><span class="line">                vmx-&gt;loaded_vmcs-&gt;entry_time = ktime_get();</span><br><span class="line"></span><br><span class="line">        /* Don&apos;t enter VMX if guest state is invalid, let the exit handler</span><br><span class="line">           start emulation until we arrive back to a valid state */</span><br><span class="line">        if (vmx-&gt;emulation_required)</span><br><span class="line">                return;</span><br><span class="line"></span><br><span class="line">        if (vmx-&gt;ple_window_dirty) &#123;</span><br><span class="line">                vmx-&gt;ple_window_dirty = false;</span><br><span class="line">                vmcs_write32(PLE_WINDOW, vmx-&gt;ple_window);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (vmx-&gt;nested.need_vmcs12_sync) &#123;</span><br><span class="line">                /*</span><br><span class="line">                 * hv_evmcs may end up being not mapped after migration (when</span><br><span class="line">                 * L2 was running), map it here to make sure vmcs12 changes are</span><br><span class="line">                 * properly reflected.</span><br><span class="line">                 */</span><br><span class="line">                if (vmx-&gt;nested.enlightened_vmcs_enabled &amp;&amp;</span><br><span class="line">                    !vmx-&gt;nested.hv_evmcs)</span><br><span class="line">                        nested_vmx_handle_enlightened_vmptrld(vcpu, false);</span><br><span class="line"></span><br><span class="line">                if (vmx-&gt;nested.hv_evmcs) &#123;</span><br><span class="line">                        copy_vmcs12_to_enlightened(vmx);</span><br><span class="line">                        /* All fields are clean */</span><br><span class="line">                        vmx-&gt;nested.hv_evmcs-&gt;hv_clean_fields |=</span><br><span class="line">                                HV_VMX_ENLIGHTENED_CLEAN_FIELD_ALL;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                        copy_vmcs12_to_shadow(vmx);</span><br><span class="line">                &#125;</span><br><span class="line">                 vmx-&gt;nested.need_vmcs12_sync = false;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         if (test_bit(VCPU_REGS_RSP, (unsigned long *)&amp;vcpu-&gt;arch.regs_dirty))</span><br><span class="line">                 vmcs_writel(GUEST_RSP, vcpu-&gt;arch.regs[VCPU_REGS_RSP]);</span><br><span class="line">         if (test_bit(VCPU_REGS_RIP, (unsigned long *)&amp;vcpu-&gt;arch.regs_dirty))</span><br><span class="line">                 vmcs_writel(GUEST_RIP, vcpu-&gt;arch.regs[VCPU_REGS_RIP]);</span><br><span class="line"></span><br><span class="line">         cr3 = __get_current_cr3_fast();</span><br><span class="line">         if (unlikely(cr3 != vmx-&gt;loaded_vmcs-&gt;host_state.cr3)) &#123;</span><br><span class="line">                 vmcs_writel(HOST_CR3, cr3);</span><br><span class="line">                 vmx-&gt;loaded_vmcs-&gt;host_state.cr3 = cr3;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         cr4 = cr4_read_shadow();</span><br><span class="line">         if (unlikely(cr4 != vmx-&gt;loaded_vmcs-&gt;host_state.cr4)) &#123;</span><br><span class="line">                 vmcs_writel(HOST_CR4, cr4);</span><br><span class="line">                 vmx-&gt;loaded_vmcs-&gt;host_state.cr4 = cr4;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         atomic_switch_perf_msrs(vmx);</span><br><span class="line"></span><br><span class="line">         vmx_update_hv_timer(vcpu);</span><br><span class="line">         /*</span><br><span class="line">          * If this vCPU has touched SPEC_CTRL, restore the guest&apos;s value if</span><br><span class="line">          * it&apos;s non-zero. Since vmentry is serialising on affected CPUs, there</span><br><span class="line">          * is no need to worry about the conditional branch over the wrmsr</span><br><span class="line">          * being speculatively taken.</span><br><span class="line">          */</span><br><span class="line">         x86_spec_ctrl_set_guest(vmx-&gt;spec_ctrl, 0);</span><br><span class="line"></span><br><span class="line">         vmx-&gt;__launched = vmx-&gt;loaded_vmcs-&gt;launched;</span><br><span class="line"></span><br><span class="line">         evmcs_rsp = static_branch_unlikely(&amp;enable_evmcs) ?</span><br><span class="line">                 (unsigned long)&amp;current_evmcs-&gt;host_rsp : 0;</span><br><span class="line"></span><br><span class="line"> //大概kernel 4.19之后的版本，这个部分汇编被已到了__vmx_vcpu_run </span><br><span class="line">         asm(</span><br><span class="line">                 /* Store host registers */</span><br><span class="line">                 &quot;push %%&quot; _ASM_DX &quot;; push %%&quot; _ASM_BP &quot;;&quot;</span><br><span class="line">......</span><br><span class="line">                 /* Avoid VMWRITE when Enlightened VMCS is in use */</span><br><span class="line">                 &quot;test %%&quot; _ASM_SI &quot;, %%&quot; _ASM_SI &quot; \n\t&quot;</span><br><span class="line">......</span><br><span class="line">                 /* Reload cr2 if changed */</span><br><span class="line">                 &quot;mov %c[cr2](%0), %%&quot; _ASM_AX &quot; \n\t&quot;</span><br><span class="line">......</span><br><span class="line">                 /* Check if vmlaunch of vmresume is needed */</span><br><span class="line">                 &quot;cmpl $0, %c[launched](%0) \n\t&quot;</span><br><span class="line">                 /* Load guest registers.  Don&apos;t clobber flags. */</span><br><span class="line">                 &quot;mov %c[rax](%0), %%&quot; _ASM_AX &quot; \n\t&quot;</span><br><span class="line">......</span><br><span class="line">                 /* Enter guest mode */</span><br><span class="line">                 &quot;jne 1f \n\t&quot;</span><br><span class="line">                 __ex(&quot;vmlaunch&quot;) &quot;\n\t&quot;</span><br><span class="line">                 &quot;jmp 2f \n\t&quot;</span><br><span class="line">                 &quot;1: &quot; __ex(&quot;vmresume&quot;) &quot;\n\t&quot;</span><br><span class="line">                 &quot;2: &quot;</span><br><span class="line">                 /* Save guest registers, load host registers, keep flags */</span><br><span class="line">                 &quot;mov %0, %c[wordsize](%%&quot; _ASM_SP &quot;) \n\t&quot;</span><br><span class="line">                 &quot;pop %0 \n\t&quot;</span><br><span class="line">......</span><br><span class="line">                 /*</span><br><span class="line">                 * Clear host registers marked as clobbered to prevent</span><br><span class="line">                 * speculative use.</span><br><span class="line">                 */</span><br><span class="line">                 [rdx]&quot;i&quot;(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_RDX])),</span><br><span class="line">               );</span><br><span class="line">         /*</span><br><span class="line">          * We do not use IBRS in the kernel. If this vCPU has used the</span><br><span class="line">          * SPEC_CTRL MSR it may have left it on; save the value and</span><br><span class="line">          * turn it off.</span><br><span class="line">          */</span><br><span class="line">         if (unlikely(!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL)))</span><br><span class="line">                 vmx-&gt;spec_ctrl = native_read_msr(MSR_IA32_SPEC_CTRL);</span><br><span class="line"></span><br><span class="line">         x86_spec_ctrl_restore_host(vmx-&gt;spec_ctrl, 0);</span><br><span class="line"></span><br><span class="line">         /* Eliminate branch target predictions from guest mode */</span><br><span class="line">         vmexit_fill_RSB();</span><br><span class="line"></span><br><span class="line">         /* All fields are clean at this point */</span><br><span class="line">         if (static_branch_unlikely(&amp;enable_evmcs))</span><br><span class="line">                 current_evmcs-&gt;hv_clean_fields |=</span><br><span class="line">                         HV_VMX_ENLIGHTENED_CLEAN_FIELD_ALL;</span><br><span class="line"></span><br><span class="line">         /* MSR_IA32_DEBUGCTLMSR is zeroed on vmexit. Restore it if needed */</span><br><span class="line">         if (vmx-&gt;host_debugctlmsr)</span><br><span class="line">                 update_debugctlmsr(vmx-&gt;host_debugctlmsr);</span><br><span class="line"></span><br><span class="line">         /*</span><br><span class="line">          * The sysexit path does not restore ds/es, so we must set them to</span><br><span class="line">          * a reasonable value ourselves.</span><br><span class="line">          */</span><br><span class="line">         loadsegment(ds, __USER_DS);</span><br><span class="line">         loadsegment(es, __USER_DS);</span><br><span class="line"></span><br><span class="line">         vcpu-&gt;arch.regs_avail = ~((1 &lt;&lt; VCPU_REGS_RIP) | (1 &lt;&lt; VCPU_REGS_RSP)</span><br><span class="line">                                   | (1 &lt;&lt; VCPU_EXREG_RFLAGS)</span><br><span class="line">                                   | (1 &lt;&lt; VCPU_EXREG_PDPTR)</span><br><span class="line">                                   | (1 &lt;&lt; VCPU_EXREG_SEGMENTS)</span><br><span class="line">                                   | (1 &lt;&lt; VCPU_EXREG_CR3));</span><br><span class="line">         vcpu-&gt;arch.regs_dirty = 0;</span><br><span class="line"></span><br><span class="line">         vmx-&gt;exit_reason = vmx-&gt;fail ? 0xdead : vmcs_read32(VM_EXIT_REASON);</span><br><span class="line">         if (vmx-&gt;fail || (vmx-&gt;exit_reason &amp; VMX_EXIT_REASONS_FAILED_VMENTRY))</span><br><span class="line">                 return;</span><br><span class="line"></span><br><span class="line">         vmx-&gt;loaded_vmcs-&gt;launched = 1;</span><br><span class="line">         vmx-&gt;idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);</span><br><span class="line"></span><br><span class="line">         vmx_complete_atomic_exit(vmx);</span><br><span class="line">         vmx_recover_nmi_blocking(vmx);</span><br><span class="line">         vmx_complete_interrupts(vmx);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p><p>‘中断’从来都是很意外的出现，我们分析也不例外没有过度令补丁的——我们简单看下中断的注入函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/vmx.c:</span><br><span class="line">static void vmx_inject_irq(struct kvm_vcpu *vcpu)</span><br><span class="line">&#123;</span><br><span class="line"> ++vcpu-&gt;stat.irq_injections;</span><br><span class="line"> if (vmx-&gt;rmode.vm86_active) &#123;</span><br><span class="line">         int inc_eip = 0;</span><br><span class="line">         if (vcpu-&gt;arch.interrupt.soft)</span><br><span class="line">                 inc_eip = vcpu-&gt;arch.event_exit_inst_len;</span><br><span class="line">         if (kvm_inject_realmode_interrupt(vcpu, irq, inc_eip) != EMULATE_</span><br><span class="line"></span><br><span class="line">                 kvm_make_request(KVM_REQ_TRIPLE_FAULT, vcpu);</span><br><span class="line">         return;</span><br><span class="line"> &#125;</span><br><span class="line"> intr = irq | INTR_INFO_VALID_MASK;</span><br><span class="line"> if (vcpu-&gt;arch.interrupt.soft) &#123;</span><br><span class="line">         intr |= INTR_TYPE_SOFT_INTR;</span><br><span class="line">         vmcs_write32(VM_ENTRY_INSTRUCTION_LEN,</span><br><span class="line">                      vmx-&gt;vcpu.arch.event_exit_inst_len);</span><br><span class="line"> &#125; else</span><br><span class="line">         intr |= INTR_TYPE_EXT_INTR;</span><br><span class="line"> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);</span><br><span class="line"></span><br><span class="line"> vmx_clear_hlt(vcpu);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，实际上注入中断就是写vmcs里面的VM_ENTRY_INTR_INFO_FIELD这个域。然后在vcpu的run函数里面设置cpu进入非根模式，vcpu会自动检查vmcs结构，然后注入中断，这是硬件自动完成的工作。而处理中断，这就是另外一个故事了，不知道后面有没有篇幅和时间继续看下吧。:p</p><h3 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h3><p>KVM只是个内核模块，虚拟机实际上是运行在QEMU的进程上下文中。所以VCPU的调度实际上直接使用了LINUX自身的调度机制。也就是linux自身的进程调度机制。<br>QEMU可以设置每个VCPU都运作在一个线程中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">static void qemu_kvm_start_vcpu(CPUState *cpu)</span><br><span class="line">&#123;</span><br><span class="line">    char thread_name[VCPU_THREAD_NAME_SIZE];</span><br><span class="line"></span><br><span class="line">    cpu-&gt;thread = g_malloc0(sizeof(QemuThread));</span><br><span class="line">    cpu-&gt;halt_cond = g_malloc0(sizeof(QemuCond));</span><br><span class="line">    qemu_cond_init(cpu-&gt;halt_cond);</span><br><span class="line">    snprintf(thread_name, VCPU_THREAD_NAME_SIZE, &quot;CPU %d/KVM&quot;,</span><br><span class="line">             cpu-&gt;cpu_index);</span><br><span class="line">    qemu_thread_create(cpu-&gt;thread, thread_name, qemu_kvm_cpu_thread_fn,</span><br><span class="line">                       cpu, QEMU_THREAD_JOINABLE);</span><br><span class="line">    while (!cpu-&gt;created) &#123;</span><br><span class="line">        qemu_cond_wait(&amp;qemu_cpu_cond, &amp;qemu_global_mutex);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从Qemu的代码，看到Qemu启动了一个kvm_cpu_thread线程。其主线程函数qemu_kvm_cpu_thread_fn内循环调用kvm_cpu_exec函数，前面已经有一篇文章<a href="https://www.owalle.com/2018/12/10/kvm-boot/">KVM 虚拟化原理2— QEMU启动过程</a>大概了解了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">int kvm_cpu_exec(CPUState *env)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    do &#123;</span><br><span class="line">        MemTxAttrs attrs;</span><br><span class="line"></span><br><span class="line">        if (cpu-&gt;kvm_vcpu_dirty) &#123;</span><br><span class="line">            kvm_arch_put_registers(cpu, KVM_PUT_RUNTIME_STATE);</span><br><span class="line">            cpu-&gt;kvm_vcpu_dirty = false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        kvm_arch_pre_run(cpu, run);</span><br><span class="line">        if (cpu-&gt;exit_request) &#123;</span><br><span class="line">            qemu_cpu_kick_self();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">----&gt;   run_ret = kvm_vcpu_ioctl(cpu, KVM_RUN, 0);</span><br><span class="line"></span><br><span class="line">        attrs = kvm_arch_post_run(cpu, run);</span><br><span class="line"></span><br><span class="line">----&gt;switch (run-&gt;exit_reason) &#123;</span><br><span class="line"> case KVM_EXIT_IO:</span><br><span class="line">     DPRINTF(&quot;handle_io\n&quot;);</span><br><span class="line">     /* Called outside BQL */</span><br><span class="line">     kvm_handle_io(run-&gt;io.port, attrs,</span><br><span class="line">                   (uint8_t *)run + run-&gt;io.data_offset,</span><br><span class="line">                   run-&gt;io.direction,</span><br><span class="line">                   run-&gt;io.size,</span><br><span class="line">                   run-&gt;io.count);</span><br><span class="line">     ret = 0;</span><br><span class="line">     break;</span><br><span class="line"> case KVM_EXIT_MMIO:</span><br><span class="line">     DPRINTF(&quot;handle_mmio\n&quot;);</span><br><span class="line">     /* Called outside BQL */</span><br><span class="line">     address_space_rw(&amp;address_space_memory,</span><br><span class="line">                      run-&gt;mmio.phys_addr, attrs,</span><br><span class="line">                      run-&gt;mmio.data,</span><br><span class="line">                      run-&gt;mmio.len,</span><br><span class="line">                      run-&gt;mmio.is_write);</span><br><span class="line">     ret = 0;</span><br><span class="line">     break;</span><br><span class="line"> case KVM_EXIT_IRQ_WINDOW_OPEN:</span><br><span class="line">     DPRINTF(&quot;irq_window_open\n&quot;);</span><br><span class="line">     ret = EXCP_INTERRUPT;</span><br><span class="line">     break;</span><br><span class="line"> case KVM_EXIT_SHUTDOWN:</span><br><span class="line">     DPRINTF(&quot;shutdown\n&quot;);</span><br><span class="line">     qemu_system_reset_request();</span><br><span class="line">     ret = EXCP_INTERRUPT;</span><br><span class="line">     break;</span><br><span class="line"> case KVM_EXIT_UNKNOWN:</span><br><span class="line">     fprintf(stderr, &quot;KVM: unknown exit, hardware reason %&quot; PRIx64 &quot;\n&quot;,</span><br><span class="line">             (uint64_t)run-&gt;hw.hardware_exit_reason);</span><br><span class="line">     ret = -1;</span><br><span class="line">     break;</span><br><span class="line"> case KVM_EXIT_INTERNAL_ERROR:</span><br><span class="line">     ret = kvm_handle_internal_error(cpu, run);</span><br><span class="line">     break;</span><br><span class="line"> case KVM_EXIT_SYSTEM_EVENT:</span><br><span class="line">     switch (run-&gt;system_event.type) &#123;</span><br><span class="line">     case KVM_SYSTEM_EVENT_SHUTDOWN:</span><br><span class="line">         qemu_system_shutdown_request();</span><br><span class="line">         ret = EXCP_INTERRUPT;</span><br><span class="line">         break;</span><br><span class="line">&#125; </span><br><span class="line">&#125; while (ret == 0);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数就是调用了前面分析过的KVM_RUN。回顾一下前面的分析，KVM_RUN就进入了虚拟机，如果从虚拟化退出到这里，那么Qemu要处理退出的事件。这些事件，可能是因为io引起的KVM_EXIT_IO，也可能是内部错误引起的KVM_EXIT_INTERNAL_ERROR。如果事件没有被完善处理，那么要停止虚拟机。</p><h3 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h3><p>如何向vcpu注入中断？是通过向真实CPU模拟注入NMI（非可屏蔽中断）中断来实现。<br>KVM要模拟一个中断控制芯片，这个是通过KVM_CREATE_IRQCHIP来实现的。<br>然后，如果Qemu想注入一个中断，就通过KVM_IRQ_LINE实现。这个所谓中断控制芯片只是在内存中存在的结构，kvm通过软件方式模拟了中断的机制。<br>KVM_CREATE_IRQCHIP实际上调用了kvm_pic_init这个函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">qemu-2.5.1/kvm-all.c:</span><br><span class="line">static int kvm_init(MachineState *ms)</span><br><span class="line">&#123;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">    if (machine_kernel_irqchip_allowed(ms)) &#123;</span><br><span class="line">----&gt;        kvm_irqchip_create(ms, s);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    kvm_state = s;</span><br><span class="line"></span><br><span class="line">    s-&gt;memory_listener.listener.eventfd_add = kvm_mem_ioeventfd_add;</span><br><span class="line">    s-&gt;memory_listener.listener.eventfd_del = kvm_mem_ioeventfd_del;</span><br><span class="line">    s-&gt;memory_listener.listener.coalesced_mmio_add = kvm_coalesce_mmio_region;</span><br><span class="line">    s-&gt;memory_listener.listener.coalesced_mmio_del = kvm_uncoalesce_mmio_region;</span><br><span class="line"></span><br><span class="line">    kvm_memory_listener_register(s, &amp;s-&gt;memory_listener,</span><br><span class="line">                                 &amp;address_space_memory, 0);</span><br><span class="line">    memory_listener_register(&amp;kvm_io_listener,</span><br><span class="line">                             &amp;address_space_io);</span><br><span class="line"></span><br><span class="line">    s-&gt;many_ioeventfds = kvm_check_many_ioeventfds();</span><br><span class="line"></span><br><span class="line">    cpu_interrupt_handler = kvm_handle_interrupt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">qemu-2.5.1/kvm-all.c:</span><br><span class="line">static void kvm_irqchip_create(MachineState *machine, KVMState *s)</span><br><span class="line">&#123;</span><br><span class="line">    int ret;</span><br><span class="line"></span><br><span class="line">    /* First probe and see if there&apos;s a arch-specific hook to create the</span><br><span class="line">     * in-kernel irqchip for us */</span><br><span class="line">    ret = kvm_arch_irqchip_create(s);</span><br><span class="line">    if (ret == 0) &#123;</span><br><span class="line">        ret = kvm_vm_ioctl(s, KVM_CREATE_IRQCHIP);</span><br><span class="line">    &#125;</span><br><span class="line">    if (ret &lt; 0) &#123;</span><br><span class="line">        fprintf(stderr, &quot;Create kernel irqchip failed: %s\n&quot;, strerror(-ret));</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    kvm_kernel_irqchip = true;</span><br><span class="line">    /* If we have an in-kernel IRQ chip then we must have asynchronous</span><br><span class="line">     * interrupt delivery (though the reverse is not necessarily true)</span><br><span class="line">     */</span><br><span class="line">    kvm_async_interrupts_allowed = true;</span><br><span class="line">    kvm_halt_in_kernel_allowed = true;</span><br><span class="line"></span><br><span class="line">    kvm_init_irq_routing(s);</span><br><span class="line"></span><br><span class="line">    s-&gt;gsimap = g_hash_table_new(g_direct_hash, g_direct_equal);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>IRQ的初始化就在kvm_init中，通过调用KVM_CREATE_IRQCHIP就搞定。<br>而KVM_IRQ_LINE实际上依旧是通过IOCTL在kernel中完成的。进到Kernel里面：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">kvm-all.c</span><br><span class="line">int kvm_set_irq(KVMState *s, int irq, int level)</span><br><span class="line">&#123;</span><br><span class="line">    struct kvm_irq_level event;</span><br><span class="line">    int ret;</span><br><span class="line"></span><br><span class="line">    assert(kvm_async_interrupts_enabled());</span><br><span class="line"></span><br><span class="line">    event.level = level;</span><br><span class="line">    event.irq = irq;</span><br><span class="line">--&gt; ret = kvm_vm_ioctl(s, s-&gt;irq_set_ioctl, &amp;event);</span><br><span class="line">    if (ret &lt; 0) &#123;</span><br><span class="line">        perror(&quot;kvm_set_irq&quot;);</span><br><span class="line">        abort();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return (s-&gt;irq_set_ioctl == KVM_IRQ_LINE) ? 1 : event.status;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">--------------------------------------------</span><br><span class="line">linux-stable/virt/kvm/irqchip.c:</span><br><span class="line">int kvm_set_irq(struct kvm *kvm, int irq_source_id, int irq, int level)</span><br><span class="line">&#123;</span><br><span class="line">        struct kvm_kernel_irq_routing_entry irq_set[KVM_NR_IRQCHIPS];</span><br><span class="line">        int ret = -1, i, idx;</span><br><span class="line"></span><br><span class="line">        trace_kvm_set_irq(irq, level, irq_source_id);</span><br><span class="line"></span><br><span class="line">        /* Not possible to detect if the guest uses the PIC or the</span><br><span class="line">         * IOAPIC.  So set the bit in both. The guest will ignore</span><br><span class="line">         * writes to the unused one.</span><br><span class="line">         */</span><br><span class="line">        idx = srcu_read_lock(&amp;kvm-&gt;irq_srcu);</span><br><span class="line">        i = kvm_irq_map_gsi(kvm, irq_set, irq);</span><br><span class="line">        srcu_read_unlock(&amp;kvm-&gt;irq_srcu, idx);</span><br><span class="line"></span><br><span class="line">        while (i--) &#123;</span><br><span class="line">                int r;</span><br><span class="line">----&gt;           r = irq_set[i].set(&amp;irq_set[i], kvm, irq_source_id, level,</span><br><span class="line">                                   line_status);</span><br><span class="line">                if (r &lt; 0)</span><br><span class="line">                        continue;</span><br><span class="line"></span><br><span class="line">                ret = r + ((ret &lt; 0) ? 0 : ret);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>从注释中可以看到，因为不能判断Guest使用的是PIC还是APIC，所以为每一个中断路由都设置中断。PIC就是传统的中断控制器8259，x86体系最初使用的中断控制器。后来，又推出了APIC，也就是高级中断控制器。APIC为支持多核架构做了更多的设计。实际上，在kvm模拟中，既有PIC的模拟，也有APIC的模拟。如果使用PIC的话，这里的这个set函数，其实就是kvm_pic_set_irq<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/i8259.c</span><br><span class="line">int kvm_pic_set_irq(struct kvm_pic *s, int irq, int irq_source_id, int level)</span><br><span class="line">&#123;</span><br><span class="line">        int ret, irq_level;</span><br><span class="line"></span><br><span class="line">        BUG_ON(irq &lt; 0 || irq &gt;= PIC_NUM_PINS);</span><br><span class="line"></span><br><span class="line">        pic_lock(s);</span><br><span class="line">        irq_level = __kvm_irq_line_state(&amp;s-&gt;irq_states[irq],</span><br><span class="line">                                         irq_source_id, level);</span><br><span class="line">        ret = pic_set_irq1(&amp;s-&gt;pics[irq &gt;&gt; 3], irq &amp; 7, irq_level);</span><br><span class="line">        pic_update_irq(s);</span><br><span class="line">        trace_kvm_pic_set_irq(irq &gt;&gt; 3, irq &amp; 7, s-&gt;pics[irq &gt;&gt; 3].elcr,</span><br><span class="line">                              s-&gt;pics[irq &gt;&gt; 3].imr, ret == 0);</span><br><span class="line">        pic_unlock(s);</span><br><span class="line"></span><br><span class="line">        return ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>可以看到，前面申请的kvm_pic结构作为参数被引入。然后设置irq到这个结构的pic成员。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/i8259.c !!</span><br><span class="line">static void pic_update_irq(struct kvm_pic *s)</span><br><span class="line">&#123;</span><br><span class="line">int irq2, irq;</span><br><span class="line"></span><br><span class="line">irq2 = pic_get_irq(&amp;s-&gt;pics[1]);</span><br><span class="line">if (irq2 &gt;= 0) &#123;</span><br><span class="line">/*</span><br><span class="line"> * if irq request by slave pic, signal master PIC</span><br><span class="line"> */</span><br><span class="line">pic_set_irq1(&amp;s-&gt;pics[0], 2, 1);</span><br><span class="line">pic_set_irq1(&amp;s-&gt;pics[0], 2, 0);</span><br><span class="line">&#125;</span><br><span class="line">irq = pic_get_irq(&amp;s-&gt;pics[0]);</span><br><span class="line">pic_irq_request(s-&gt;kvm, irq &gt;= 0);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>此时调用irq_request，就是初始化中断芯片时候绑定的函数pic_irq_request。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/i8259.c:</span><br><span class="line">void kvm_pic_update_irq(struct kvm_pic *s)</span><br><span class="line">&#123;</span><br><span class="line">        pic_lock(s);</span><br><span class="line">        pic_update_irq(s);</span><br><span class="line">        pic_unlock(s);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">static void pic_unlock(struct kvm_pic *s)</span><br><span class="line">        __releases(&amp;s-&gt;lock)</span><br><span class="line">&#123;</span><br><span class="line">        bool wakeup = s-&gt;wakeup_needed;</span><br><span class="line">        struct kvm_vcpu *vcpu;</span><br><span class="line">        int i;</span><br><span class="line"></span><br><span class="line">        s-&gt;wakeup_needed = false;</span><br><span class="line"></span><br><span class="line">        spin_unlock(&amp;s-&gt;lock);</span><br><span class="line"></span><br><span class="line">        if (wakeup) &#123;</span><br><span class="line">                kvm_for_each_vcpu(i, vcpu, s-&gt;kvm) &#123;</span><br><span class="line">                        if (kvm_apic_accept_pic_intr(vcpu)) &#123;</span><br><span class="line">                                kvm_make_request(KVM_REQ_EVENT, vcpu);</span><br><span class="line">----&gt;                                kvm_vcpu_kick(vcpu);</span><br><span class="line">                                return;</span><br><span class="line">                        &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>可以看到irq_request之后会调用kvm_vcpu_kick。我们知道，对一个注入的中断来说，需要vcpu立即响应，但是在多核的架构下（smp），目的cpu可能正在运行，所以要提供一种机制停止目的cpu的运行，让它立即处理注入的中断。kvm_vcpu_kick就是给目的cpu发送一个处理器间中断(IPI)，让目的cpu停止运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">arch/alpha/kernel/smp.c:</span><br><span class="line"></span><br><span class="line">void</span><br><span class="line">smp_send_reschedule(int cpu)</span><br><span class="line">&#123;</span><br><span class="line">        send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>等VM-exit退出后，就接上了前文分析过的部分。VCPU再次进入虚拟机的时候，通过inject_pengding_event检查中断。这个检查的过程就发现了通过KVM_IRQ_LINE注入的中断，然后就是写vmcs结构了注入中断，已经分析过了。</p><h2 id="VCPU的内存虚拟化"><a href="#VCPU的内存虚拟化" class="headerlink" title="VCPU的内存虚拟化"></a>VCPU的内存虚拟化</h2><p>在KMV初始化的时候，要检查是否支持vt里面的EPT扩展技术。如果支持，enable_ept这个变量置为1，然后设置tdp_enabled为1。TDP就是两维页表。为表述方便，给出kvm中下列名字的定义：</p><ul><li>GPA：guest机物理地址</li><li>GVA：guest机虚拟地址</li><li>HVA：host机虚拟地址</li><li>HPA：host机物理地址</li></ul><h3 id="虚拟机页表初始化"><a href="#虚拟机页表初始化" class="headerlink" title="虚拟机页表初始化"></a>虚拟机页表初始化</h3><p>在vcpu初始化的时候，要调用kvm_init_mmu来设置不同的内存虚拟化方式。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">void kvm_init_mmu(struct kvm_vcpu *vcpu, bool reset_roots)</span><br><span class="line">&#123;</span><br><span class="line">......</span><br><span class="line">/*嵌套虚拟化，我们暂不考虑吧 */</span><br><span class="line">        if (mmu_is_nested(vcpu))</span><br><span class="line">                init_kvm_nested_mmu(vcpu);</span><br><span class="line">        else if (tdp_enabled)</span><br><span class="line">                init_kvm_tdp_mmu(vcpu);</span><br><span class="line">        else</span><br><span class="line">                init_kvm_softmmu(vcpu);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>设置两种方式，一种是支持EPT的方式，另种是soft mmu，也就是影子页表的方式。在支持EPT的情况下，会调用init_kvm_tdp_mmu函数初始化MMU。在该函数中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/mmu.c:</span><br><span class="line">static void init_kvm_tdp_mmu(struct kvm_vcpu *vcpu)</span><br><span class="line">&#123;</span><br><span class="line">        struct kvm_mmu *context = vcpu-&gt;arch.mmu;</span><br><span class="line">        union kvm_mmu_role new_role =</span><br><span class="line">                kvm_calc_tdp_mmu_root_page_role(vcpu, false);</span><br><span class="line"></span><br><span class="line">        new_role.base.word &amp;= mmu_base_role_mask.word;</span><br><span class="line">        if (new_role.as_u64 == context-&gt;mmu_role.as_u64)</span><br><span class="line">                return;</span><br><span class="line"></span><br><span class="line">        context-&gt;mmu_role.as_u64 = new_role.as_u64;</span><br><span class="line">---&gt;    context-&gt;page_fault = tdp_page_fault;</span><br><span class="line">        context-&gt;sync_page = nonpaging_sync_page;</span><br><span class="line">        context-&gt;invlpg = nonpaging_invlpg;</span><br><span class="line">        context-&gt;update_pte = nonpaging_update_pte;</span><br><span class="line">---&gt;    context-&gt;shadow_root_level = kvm_x86_ops-&gt;get_tdp_level(vcpu);</span><br><span class="line">        context-&gt;direct_map = true;</span><br><span class="line">        context-&gt;set_cr3 = kvm_x86_ops-&gt;set_tdp_cr3;</span><br><span class="line">        context-&gt;get_cr3 = get_cr3;</span><br><span class="line">        context-&gt;get_pdptr = kvm_pdptr_read;</span><br><span class="line">        context-&gt;inject_page_fault = kvm_inject_page_fault;</span><br><span class="line"></span><br><span class="line">        if (!is_paging(vcpu)) &#123;</span><br><span class="line">                context-&gt;nx = false;</span><br><span class="line">                context-&gt;gva_to_gpa = nonpaging_gva_to_gpa;</span><br><span class="line">                context-&gt;root_level = 0;</span><br><span class="line">        &#125; else if (is_long_mode(vcpu)) &#123;</span><br><span class="line">                context-&gt;nx = is_nx(vcpu);</span><br><span class="line">                context-&gt;root_level = is_la57_mode(vcpu) ?</span><br><span class="line">                                PT64_ROOT_5LEVEL : PT64_ROOT_4LEVEL;</span><br><span class="line">                reset_rsvds_bits_mask(vcpu, context);</span><br><span class="line">                context-&gt;gva_to_gpa = paging64_gva_to_gpa;</span><br><span class="line">        &#125; else if (is_pae(vcpu)) &#123;</span><br><span class="line">                context-&gt;nx = is_nx(vcpu);</span><br><span class="line">                context-&gt;root_level = PT32E_ROOT_LEVEL;</span><br><span class="line">                reset_rsvds_bits_mask(vcpu, context);</span><br><span class="line">                context-&gt;gva_to_gpa = paging64_gva_to_gpa;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">                context-&gt;nx = false;</span><br><span class="line">                context-&gt;root_level = PT32_ROOT_LEVEL;</span><br><span class="line">                reset_rsvds_bits_mask(vcpu, context);</span><br><span class="line">                context-&gt;gva_to_gpa = paging32_gva_to_gpa;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></p><p>EPT初始化的内容挺多，还是挑几个喜闻乐见的聊下吧。kvm_x86_ops-&gt;get_tdp_level(vcpu)可以看出来EPT目前用的默认是4级页表，满足条件的会使用5级页表。<br>vcpu-&gt;arch.walk_mmu.pagefault被初始化成tdp_page_fault。下面看下tdp_page_fault。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/mmu.c:</span><br><span class="line">static int tdp_page_fault(struct kvm_vcpu *vcpu, gva_t gpa, u32 error_code,</span><br><span class="line">                          bool prefault)</span><br><span class="line">&#123;</span><br><span class="line">        kvm_pfn_t pfn;</span><br><span class="line">        int r;</span><br><span class="line">        int level;</span><br><span class="line">        bool force_pt_level;</span><br><span class="line">/* 物理地址右移12位得到物理页框号(相对于虚拟机而言)*/</span><br><span class="line">        gfn_t gfn = gpa &gt;&gt; PAGE_SHIFT;</span><br><span class="line">        unsigned long mmu_seq;</span><br><span class="line">        int write = error_code &amp; PFERR_WRITE_MASK;</span><br><span class="line">        bool map_writable;</span><br><span class="line"></span><br><span class="line">        if (page_fault_handle_page_track(vcpu, error_code, gfn))</span><br><span class="line">                return RET_PF_EMULATE;</span><br><span class="line"></span><br><span class="line">/*分配缓存池*/</span><br><span class="line">----&gt;   r = mmu_topup_memory_caches(vcpu);</span><br><span class="line">        if (r)</span><br><span class="line">                return r;</span><br><span class="line"></span><br><span class="line">        force_pt_level = !check_hugepage_cache_consistency(vcpu, gfn,</span><br><span class="line">                                                           PT_DIRECTORY_LEVEL);</span><br><span class="line">----&gt;   level = mapping_level(vcpu, gfn, &amp;force_pt_level);</span><br><span class="line">        if (likely(!force_pt_level)) &#123;</span><br><span class="line">                if (level &gt; PT_DIRECTORY_LEVEL &amp;&amp;</span><br><span class="line">                    !check_hugepage_cache_consistency(vcpu, gfn, level))</span><br><span class="line">                        level = PT_DIRECTORY_LEVEL;</span><br><span class="line">                gfn &amp;= ~(KVM_PAGES_PER_HPAGE(level) - 1);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">----&gt;   if (fast_page_fault(vcpu, gpa, level, error_code))</span><br><span class="line">                return RET_PF_RETRY;</span><br><span class="line"></span><br><span class="line">        mmu_seq = vcpu-&gt;kvm-&gt;mmu_notifier_seq;</span><br><span class="line">        smp_rmb();</span><br><span class="line"></span><br><span class="line">----&gt;   if (try_async_pf(vcpu, prefault, gfn, gpa, &amp;pfn, write, &amp;map_writable))</span><br><span class="line">                return RET_PF_RETRY;</span><br><span class="line"></span><br><span class="line">        if (handle_abnormal_pfn(vcpu, 0, gfn, pfn, ACC_ALL, &amp;r))</span><br><span class="line">                return r;</span><br><span class="line"></span><br><span class="line">        spin_lock(&amp;vcpu-&gt;kvm-&gt;mmu_lock);</span><br><span class="line">         if (mmu_notifier_retry(vcpu-&gt;kvm, mmu_seq))</span><br><span class="line">                 goto out_unlock;</span><br><span class="line">         if (make_mmu_pages_available(vcpu) &lt; 0)</span><br><span class="line">                 goto out_unlock;</span><br><span class="line">         if (likely(!force_pt_level))</span><br><span class="line">                 transparent_hugepage_adjust(vcpu, &amp;gfn, &amp;pfn, &amp;level);</span><br><span class="line">----&gt;    r = __direct_map(vcpu, write, map_writable, level, gfn, pfn, prefault);</span><br><span class="line">         spin_unlock(&amp;vcpu-&gt;kvm-&gt;mmu_lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该函调用mmu_topup_memory_caches函数进行缓存池的分配，解释是为了避免在运行时分配空间失败，这里提前分配足额的空间，便于运行时使用。然后调用mapping_level函数判断当前gfn对应的slot是否可用。为什么要进行这样的判断呢？在if内部可以看到是获取level，如果当前GPN对应的slot可用，我们就可以获取分配slot的pagesize，然后得到最低级的level，比如如果是2M的页，那么level就为2，为4K的页，level就为1.<br>接着调用了fast_page_fault尝试快速处理violation，只有当GFN对应的物理页存在且violation是由读写操作引起的，才可以使用快速处理。</p><p>假设这里不能快速处理，那么到后面就调用try_async_pf函数根据GFN获取对应的PFN，这个过程具体来说需要首先获取GFN对应的slot，转化成HVA，接着就是正常的HOST地址翻译的过程了，如果HVA对应的地址并不在内存中，还需要HOST自己处理缺页中断。</p><p>接着调用transparent_hugepage_adjust对level和gfn、pfn做出调整。紧着着就调用了__direct_map函数，该函数是构建页表的核心函数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/mmu.c:</span><br><span class="line">static int __direct_map(struct kvm_vcpu *vcpu, gpa_t v, int write,</span><br><span class="line">            int map_writable, int level, gfn_t gfn, pfn_t pfn,</span><br><span class="line">            bool prefault)</span><br><span class="line">&#123;</span><br><span class="line">    struct kvm_shadow_walk_iterator iterator;</span><br><span class="line">    struct kvm_mmu_page *sp;</span><br><span class="line">    int emulate = 0;</span><br><span class="line">    gfn_t pseudo_gfn;</span><br><span class="line"></span><br><span class="line">    for_each_shadow_entry(vcpu, (u64)gfn &lt;&lt; PAGE_SHIFT, iterator) &#123;</span><br><span class="line">        /*如果需要映射的level正是iterator.level，那么*/</span><br><span class="line">        if (iterator.level == level) &#123;</span><br><span class="line">            mmu_set_spte(vcpu, iterator.sptep, ACC_ALL,</span><br><span class="line">                     write, &amp;emulate, level, gfn, pfn,</span><br><span class="line">                     prefault, map_writable);</span><br><span class="line">            direct_pte_prefetch(vcpu, iterator.sptep);</span><br><span class="line">            ++vcpu-&gt;stat.pf_fixed;</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line">        /*判断当前entry指向的页表是否存在，不存在的话需要建立*/</span><br><span class="line">        if (!is_shadow_present_pte(*iterator.sptep)) &#123;</span><br><span class="line">            /*iterator.addr是客户物理地址的物理页帧*/</span><br><span class="line">            u64 base_addr = iterator.addr;</span><br><span class="line">            /*确保对应层级的偏移部分为0，如level=1，则baseaddr的低12位就清零*/</span><br><span class="line">            base_addr &amp;= PT64_LVL_ADDR_MASK(iterator.level);//</span><br><span class="line">            /*得到物理页框号*/</span><br><span class="line">            pseudo_gfn = base_addr &gt;&gt; PAGE_SHIFT;</span><br><span class="line">/* 获得一个page */</span><br><span class="line">----&gt;       sp = kvm_mmu_get_page(vcpu, pseudo_gfn, iterator.addr,</span><br><span class="line">                          iterator.level - 1,</span><br><span class="line">                          1, ACC_ALL, iterator.sptep);</span><br><span class="line">             /*设置页表项的sptep指针指向sp*/</span><br><span class="line">            link_shadow_page(iterator.sptep, sp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return emulate;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先进入的便是for_each_shadow_entry，用于根据GFN遍历EPT页表的对应项，这点后面会详细解释。循环中首先判断entry的level和请求的level是否相等，相等说明该entry处引起的violation，即该entry对应的下级页或者页表不在内存中，或者直接为NULL。</p><p>如果level不相等，就进入后面的if判断，这是判断该entry对应的下一级页是否存在，如果不存在需要重新构建，存在就直接向后遍历，即对比二级页表中的entry。整个处理流程就是这样，根据GPA组逐层查找EPT，最终level相等的时候，就根据最后一层的索引定位一个PTE，该PTE应该指向的就是GFN对应的PFN，那么这时候set spite就可以了。最好的情况就是最后一级页表中的entry指向的物理页被换出外磁盘，这样只需要处理一次EPT violation，而如果在初始全部为空的状态下访问，每一级的页表都需要重新构建，则需要处理四次EPTviolation，发生4次VM-exit。</p><p>构建页表的过程即在level相等之前，发现需要的某一级的页表项为NULL，就调用kvm_mmu_get_page获取一个page，然后调用link_shadow_page设置页表项指向page，</p><p>看下kvm_mmu_get_page函数:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/mmu.c:</span><br><span class="line">static struct kvm_mmu_page *kvm_mmu_get_page(struct kvm_vcpu *vcpu,</span><br><span class="line">                         gfn_t gfn,</span><br><span class="line">                         gva_t gaddr,</span><br><span class="line">                         unsigned level,</span><br><span class="line">                         int direct,</span><br><span class="line">                         unsigned access,</span><br><span class="line">                         u64 *parent_pte)</span><br><span class="line">&#123;</span><br><span class="line">    union kvm_mmu_page_role role;</span><br><span class="line">    unsigned quadrant;</span><br><span class="line">    struct kvm_mmu_page *sp;</span><br><span class="line">    bool need_sync = false;</span><br><span class="line">  </span><br><span class="line">    role = vcpu-&gt;arch.mmu.base_role;</span><br><span class="line">    role.level = level;</span><br><span class="line">    role.direct = direct;</span><br><span class="line">    if (role.direct)</span><br><span class="line">        role.cr4_pae = 0;</span><br><span class="line">    role.access = access;</span><br><span class="line">    /*quadrant 对应页表项的索引，来自于GPA*/</span><br><span class="line">    if (!vcpu-&gt;arch.mmu.direct_map</span><br><span class="line">        &amp;&amp; vcpu-&gt;arch.mmu.root_level &lt;= PT32_ROOT_LEVEL) &#123;</span><br><span class="line">        quadrant = gaddr &gt;&gt; (PAGE_SHIFT + (PT64_PT_BITS * level));</span><br><span class="line">        quadrant &amp;= (1 &lt;&lt; ((PT32_PT_BITS - PT64_PT_BITS) * level)) - 1;</span><br><span class="line">        role.quadrant = quadrant;</span><br><span class="line">    &#125;</span><br><span class="line">    /*根据gfn遍历KVM维护的mmu_page_hash哈希链表*/</span><br><span class="line">---&gt; for_each_gfn_sp(vcpu-&gt;kvm, sp, gfn) &#123;</span><br><span class="line">        /**/</span><br><span class="line">        if (is_obsolete_sp(vcpu-&gt;kvm, sp))</span><br><span class="line">            continue;</span><br><span class="line"></span><br><span class="line">        if (!need_sync &amp;&amp; sp-&gt;unsync)</span><br><span class="line">            need_sync = true;</span><br><span class="line"></span><br><span class="line">        if (sp-&gt;role.word != role.word)</span><br><span class="line">            continue;</span><br><span class="line"></span><br><span class="line">        if (sp-&gt;unsync &amp;&amp; kvm_sync_page_transient(vcpu, sp))</span><br><span class="line">            break;</span><br><span class="line">        /*设置sp-&gt;parent_pte=parent_pte*/</span><br><span class="line">        mmu_page_add_parent_pte(vcpu, sp, parent_pte);</span><br><span class="line">        if (sp-&gt;unsync_children) &#123;</span><br><span class="line">            kvm_make_request(KVM_REQ_MMU_SYNC, vcpu);</span><br><span class="line">            kvm_mmu_mark_parents_unsync(sp);</span><br><span class="line">        &#125; else if (sp-&gt;unsync)</span><br><span class="line">            kvm_mmu_mark_parents_unsync(sp);</span><br><span class="line"></span><br><span class="line">        __clear_sp_write_flooding_count(sp);</span><br><span class="line">        trace_kvm_mmu_get_page(sp, false);</span><br><span class="line">        return sp;</span><br><span class="line">    &#125;</span><br><span class="line">    /*如果根据页框号没有遍历到合适的page，就需要重新创建一个页*/</span><br><span class="line">    ++vcpu-&gt;kvm-&gt;stat.mmu_cache_miss;</span><br><span class="line">--&gt; sp = kvm_mmu_alloc_page(vcpu, parent_pte, direct);</span><br><span class="line">    if (!sp)</span><br><span class="line">        return sp;</span><br><span class="line">    /*设置其对应的客户机物理页框号*/</span><br><span class="line">    sp-&gt;gfn = gfn;</span><br><span class="line">    sp-&gt;role = role;</span><br><span class="line">    /*把该也作为一个节点加入到哈希表相应的链表汇总*/</span><br><span class="line">    hlist_add_head(&amp;sp-&gt;hash_link,</span><br><span class="line">        &amp;vcpu-&gt;kvm-&gt;arch.mmu_page_hash[kvm_page_table_hashfn(gfn)]);</span><br><span class="line">    if (!direct) &#123;</span><br><span class="line">        if (rmap_write_protect(vcpu-&gt;kvm, gfn))</span><br><span class="line">            kvm_flush_remote_tlbs(vcpu-&gt;kvm);</span><br><span class="line">        if (level &gt; PT_PAGE_TABLE_LEVEL &amp;&amp; need_sync)</span><br><span class="line">            kvm_sync_pages(vcpu, gfn);</span><br><span class="line"></span><br><span class="line">        account_shadowed(vcpu-&gt;kvm, gfn);</span><br><span class="line">    &#125;</span><br><span class="line">    sp-&gt;mmu_valid_gen = vcpu-&gt;kvm-&gt;arch.mmu_valid_gen;</span><br><span class="line">    /*暂时对所有表项清零*/</span><br><span class="line">    init_shadow_page_table(sp);</span><br><span class="line">    trace_kvm_mmu_get_page(sp, true);</span><br><span class="line">    return sp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>一个kvm_mmu_page对应于一个kvm_mmu_page_role，kvm_mmu_page_role记录对应page的各种属性。下面for_each_gfn_sp是一个遍历链表的宏定义，KVM为了根据GFN查找对应的kvm_mmu_page，用一个HASH数组记录所有的kvm_mmu_page，每一个表项都是一个链表头，即根据GFN获取到的HASH值相同的，位于一个链表中。这也是HASH表处理冲突常见方法。</p><p>如果在对应链表中找到一个合适的页（怎么算是合适暂且不清楚），就直接利用该页，否则需要调用kvm_mmu_alloc_page函数重新申请一个页，主要是申请一个kvm_mmu_page结构和一个存放表项的page，这就用到了之前我们说过的三种缓存，不过这里只用到了两个，分别是mmu_page_header_cache和mmu_page_cache。这样分配好后，把对应的kvm_mmu_page作为一个节点加入到全局的HASH链表中，然后对数组项清零，最后返回sp.</p><p>linux为不同的cpu提供不同的页表层级。64位cpu使用了四级页表PT64_ROOT_4LEVEL，同时设定页表根地址为无效,此时页表尚未分配。<br>何时真正分配vcpu的页表？是在vcpu_enter_guest的开始位置，通过调用kvm_mmu_reload实现。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/mmu.h:</span><br><span class="line">static inline int kvm_mmu_reload(struct kvm_vcpu *vcpu)</span><br><span class="line">&#123;      /*页表根地址不是无效的，则退出，不用分配。*/</span><br><span class="line">if (likely(vcpu-&gt;arch.mmu.root_hpa != INVALID_PAGE))</span><br><span class="line">return 0;</span><br><span class="line">return kvm_mmu_load(vcpu);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>首先检查页表根地址是否无效，如果无效，则调用kvm_mmu_load。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/mmu.c:</span><br><span class="line">int kvm_mmu_load(struct kvm_vcpu *vcpu)</span><br><span class="line">&#123;</span><br><span class="line">int r;</span><br><span class="line">r = mmu_alloc_roots(vcpu);</span><br><span class="line">       /*同步页表*/</span><br><span class="line">mmu_sync_roots(vcpu);</span><br><span class="line"></span><br><span class="line">/* set_cr3() should ensure TLB has been flushed */</span><br><span class="line">kvm_x86_ops-&gt;set_cr3(vcpu, vcpu-&gt;arch.mmu.root_hpa);</span><br><span class="line">kvm_x86_ops-&gt;tlb_flush(vcpu, true);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>mmu_alloc_roots这个函数要申请内存，作为根页表使用，同时root_hpa指向根页表的物理地址。然后可以看到，vcpu中cr3寄存器的地址要指向这个根页表的物理地址。</p><h3 id="虚拟机物理地址"><a href="#虚拟机物理地址" class="headerlink" title="虚拟机物理地址"></a>虚拟机物理地址</h3><p>我们已经分析过，kvm的虚拟机实际上运行在Qemu的进程上下文中。于是，虚拟机的物理内存实际上是Qemu进程的虚拟地址。Kvm要把虚拟机的物理内存分成几个slot。这是因为，对计算机系统来说，物理地址是不连续的，除了bios和显存要编入内存地址，IO设备的内存也可能映射到内存，所以内存实际上是分为一段段的。<br>Qemu通过KVM_SET_USER_MEMORY_REGION来为虚拟机设置内存。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">virt/kvm/kvm_main.c:</span><br><span class="line">int __kvm_set_memory_region(struct kvm *kvm,</span><br><span class="line">    struct kvm_userspace_memory_region *mem,</span><br><span class="line">    int user_alloc)</span><br><span class="line">&#123;</span><br><span class="line">      /*找到现在的memslot*/</span><br><span class="line">slot = id_to_memslot(__kvm_memslots(kvm, as_id), id);</span><br><span class="line">base_gfn = mem-&gt;guest_phys_addr &gt;&gt; PAGE_SHIFT;</span><br><span class="line">npages = mem-&gt;memory_size &gt;&gt; PAGE_SHIFT;</span><br><span class="line"></span><br><span class="line">new = old = *slot;</span><br><span class="line">       /*new是新的slots,old保持老的数值不变*/</span><br><span class="line">new.id = id;</span><br><span class="line">new.base_gfn = base_gfn;</span><br><span class="line">new.npages = npages;</span><br><span class="line">new.flags = mem-&gt;flags;</span><br><span class="line"></span><br><span class="line">       /*用户已经分配了内存，slot的用户空间地址就等于用户分配的地址*/</span><br><span class="line">         if (change == KVM_MR_CREATE) &#123;</span><br><span class="line">----&gt;              new.userspace_addr = mem-&gt;userspace_addr;</span><br><span class="line"></span><br><span class="line">                 if (kvm_arch_create_memslot(kvm, &amp;new, npages))</span><br><span class="line">                         goto out_free;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         /* Allocate page dirty bitmap if needed */</span><br><span class="line">         if ((new.flags &amp; KVM_MEM_LOG_DIRTY_PAGES) &amp;&amp; !new.dirty_bitmap) &#123;</span><br><span class="line">                 if (kvm_create_dirty_bitmap(&amp;new) &lt; 0)</span><br><span class="line">                         goto out_free;</span><br><span class="line">         &#125;</span><br><span class="line">----&gt;    slots = kvzalloc(sizeof(struct kvm_memslots), GFP_KERNEL);</span><br><span class="line">         memcpy(slots, __kvm_memslots(kvm, as_id), sizeof(struct kvm_memslots));</span><br><span class="line"></span><br><span class="line">/*内存地址页的检查和内存overlap的检查*/</span><br><span class="line">         if ((change == KVM_MR_DELETE) || (change == KVM_MR_MOVE)) &#123;</span><br><span class="line">                 slot = id_to_memslot(slots, id);</span><br><span class="line">                 slot-&gt;flags |= KVM_MEMSLOT_INVALID;</span><br><span class="line"></span><br><span class="line">                 old_memslots = install_new_memslots(kvm, as_id, slots);</span><br><span class="line"></span><br><span class="line">                 /* From this point no new shadow pages pointing to a deleted,</span><br><span class="line">                  * or moved, memslot will be created.</span><br><span class="line">                  *</span><br><span class="line">                  * validation of sp-&gt;gfn happens in:</span><br><span class="line">                  *      - gfn_to_hva (kvm_read_guest, gfn_to_pfn)</span><br><span class="line">                  *      - kvm_is_visible_gfn (mmu_check_roots)</span><br><span class="line">                  */</span><br><span class="line">                 kvm_arch_flush_shadow_memslot(kvm, slot);</span><br><span class="line"></span><br><span class="line">                 /*</span><br><span class="line">                  * We can re-use the old_memslots from above, the only difference</span><br><span class="line">                  * from the currently installed memslots is the invalid flag.  This</span><br><span class="line">                  * will get overwritten by update_memslots anyway.</span><br><span class="line">                  */</span><br><span class="line">                 slots = old_memslots;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         r = kvm_arch_prepare_memory_region(kvm, &amp;new, mem, change);</span><br><span class="line">         if (r)</span><br><span class="line">                 goto out_slots;</span><br><span class="line"></span><br><span class="line">         /* actual memory is freed via old in kvm_free_memslot below */</span><br><span class="line">         if (change == KVM_MR_DELETE) &#123;</span><br><span class="line">                 new.dirty_bitmap = NULL;</span><br><span class="line">                 memset(&amp;new.arch, 0, sizeof(new.arch));</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         update_memslots(slots, &amp;new, change);</span><br><span class="line">         old_memslots = install_new_memslots(kvm, as_id, slots);</span><br><span class="line"></span><br><span class="line">         kvm_arch_commit_memory_region(kvm, mem, &amp;old, &amp;new, change);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就是创建一个新的memslot，代替原来的memslot。一个内存slot，最重要部分是指定了vm的物理地址，使用函数gfn_to_hva可以把gfn转换为hva。可见，一个memslot就是建立了GPA到HVA的映射关系。</p><h3 id="内存虚拟化过程"><a href="#内存虚拟化过程" class="headerlink" title="内存虚拟化过程"></a>内存虚拟化过程</h3><p>这里，有必要描述一下内存虚拟化的过程：<br>VM要访问GVA地址x，那么首先查询VM的页表得到PTE（页表项），通过PTE将GVA x映射到物理地址GPA y. GPA y此时不存在，发生页缺失。KVM接管。从memslot，可以知道GPA对应的其实是HVA x’，然后从HVA x’，可以查找得到HPA y’，然后将HPA y’这个映射写入到页表。<br>VM再次存取GVA x，这是从页表项已经可以查到HPA y’了，内存可正常访问。</p><p>首先，从page_fault处理开始。从前文的分析，知道VM里面的异常产生VM-Exit，然后由各自cpu提供的处理函数处理。对intel的vt技术，就是handle_exception这个函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/vmx.c:</span><br><span class="line">static int handle_exception(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run)</span><br><span class="line">&#123;</span><br><span class="line">u32 intr_info, ex_no, error_code; </span><br><span class="line"></span><br><span class="line">       /*读vmcs，获得VM-exit的信息*/</span><br><span class="line">intr_info = vmx-&gt;exit_intr_info;</span><br><span class="line"></span><br><span class="line">       /*发现是page_fault引起*/</span><br><span class="line">         if (is_page_fault(intr_info)) &#123;</span><br><span class="line">                 cr2 = vmcs_readl(EXIT_QUALIFICATION);</span><br><span class="line">                 /* EPT won&apos;t cause page fault directly */</span><br><span class="line">                 /*如果支持EPT，不会因为page_fault退出，所以是bug*/</span><br><span class="line">                 WARN_ON_ONCE(!vcpu-&gt;arch.apf.host_apf_reason &amp;&amp; enable_ept);</span><br><span class="line">                 return kvm_handle_page_fault(vcpu, error_code, cr2, NULL, 0);</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         ex_no = intr_info &amp; INTR_INFO_VECTOR_MASK;</span><br><span class="line"></span><br><span class="line">         if (vmx-&gt;rmode.vm86_active &amp;&amp; rmode_exception(vcpu, ex_no))</span><br><span class="line">                 return handle_rmode_exception(vcpu, ex_no, error_code);</span><br><span class="line"></span><br><span class="line">         switch (ex_no) &#123;</span><br><span class="line">         case AC_VECTOR:</span><br><span class="line">                 kvm_queue_exception_e(vcpu, AC_VECTOR, error_code);</span><br><span class="line">                 return 1;</span><br><span class="line">         case DB_VECTOR:</span><br><span class="line">                 dr6 = vmcs_readl(EXIT_QUALIFICATION);</span><br><span class="line">                 if (!(vcpu-&gt;guest_debug &amp;</span><br><span class="line">                       (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP))) &#123;</span><br><span class="line">                         vcpu-&gt;arch.dr6 &amp;= ~15;</span><br><span class="line">                         vcpu-&gt;arch.dr6 |= dr6 | DR6_RTM;</span><br><span class="line">                         if (is_icebp(intr_info))</span><br><span class="line">                                 skip_emulated_instruction(vcpu);</span><br><span class="line"></span><br><span class="line">                         kvm_queue_exception(vcpu, DB_VECTOR);</span><br><span class="line">                         return 1;</span><br><span class="line">                 &#125;</span><br><span class="line">                 kvm_run-&gt;debug.arch.dr6 = dr6 | DR6_FIXED_1;</span><br><span class="line">                 kvm_run-&gt;debug.arch.dr7 = vmcs_readl(GUEST_DR7);</span><br><span class="line">                 /* fall through */</span><br><span class="line">         case BP_VECTOR:</span><br><span class="line">                 /*</span><br><span class="line">                  * Update instruction length as we may reinject #BP from</span><br><span class="line">                  * user space while in guest debugging mode. Reading it for</span><br><span class="line">                  * #DB as well causes no harm, it is not used in that case.</span><br><span class="line">                  */</span><br><span class="line">                 vmx-&gt;vcpu.arch.event_exit_inst_len =</span><br><span class="line">                         vmcs_read32(VM_EXIT_INSTRUCTION_LEN);</span><br><span class="line">                 kvm_run-&gt;exit_reason = KVM_EXIT_DEBUG;</span><br><span class="line">                 rip = kvm_rip_read(vcpu);</span><br><span class="line">                 kvm_run-&gt;debug.arch.pc = vmcs_readl(GUEST_CS_BASE) + rip;</span><br><span class="line">                 kvm_run-&gt;debug.arch.exception = ex_no;</span><br><span class="line">                 break;</span><br><span class="line">         default:</span><br><span class="line">                 kvm_run-&gt;exit_reason = KVM_EXIT_EXCEPTION;</span><br><span class="line">                 kvm_run-&gt;ex.exception = ex_no;</span><br><span class="line">                 kvm_run-&gt;ex.error_code = error_code;</span><br><span class="line">                 break;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从这个函数，可以看到对vmcs的使用。通过读vmcs的域，可以获得退出vm的原因。如果是page_fault引起，则调用kvm_mmu_page_fault去处理。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/mmu.c:</span><br><span class="line">int kvm_mmu_page_fault(struct kvm_vcpu *vcpu, gva_t cr2, u32 error_code)</span><br><span class="line">&#123;</span><br><span class="line">        int r, emulation_type = 0;</span><br><span class="line">        enum emulation_result er;</span><br><span class="line">        bool direct = vcpu-&gt;arch.mmu-&gt;direct_map;</span><br><span class="line"></span><br><span class="line">        /* With shadow page tables, fault_address contains a GVA or nGPA.  */</span><br><span class="line">        if (vcpu-&gt;arch.mmu-&gt;direct_map) &#123;</span><br><span class="line">                vcpu-&gt;arch.gpa_available = true;</span><br><span class="line">                vcpu-&gt;arch.gpa_val = cr2;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        r = RET_PF_INVALID;</span><br><span class="line">        if (unlikely(error_code &amp; PFERR_RSVD_MASK)) &#123;</span><br><span class="line">                r = handle_mmio_page_fault(vcpu, cr2, direct);</span><br><span class="line">                if (r == RET_PF_EMULATE)</span><br><span class="line">                        goto emulate;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">       /*调用mmu的page_fault*/</span><br><span class="line">        if (r == RET_PF_INVALID) &#123;</span><br><span class="line">                r = vcpu-&gt;arch.mmu-&gt;page_fault(vcpu, cr2,</span><br><span class="line">                                               lower_32_bits(error_code),</span><br><span class="line">                                               false);</span><br><span class="line">                WARN_ON(r == RET_PF_INVALID);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        er = x86_emulate_instruction(vcpu, cr2, emulation_type, insn, insn_len);</span><br><span class="line"></span><br><span class="line">        switch (er) &#123;</span><br><span class="line">        case EMULATE_DONE:</span><br><span class="line">                return 1;</span><br><span class="line">        case EMULATE_USER_EXIT:</span><br><span class="line">                ++vcpu-&gt;stat.mmio_exits;</span><br><span class="line">                /* fall through */</span><br><span class="line">        case EMULATE_FAIL:</span><br><span class="line">                return 0;</span><br><span class="line">        default:</span><br><span class="line">                BUG();</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里调用了MMU的page_fault处理函数。这个函数就是前面初始化时候设置的paging64_page_fault。也就是通过FNAME宏展开的FNAME(page_fault)。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/paging_tmpl.h:</span><br><span class="line">static int FNAME(page_fault)(struct kvm_vcpu *vcpu, gva_t addr,</span><br><span class="line">       u32 error_code)</span><br><span class="line">&#123;</span><br><span class="line">/*查guest页表，物理地址是否存在 */</span><br><span class="line">r = FNAME(walk_addr)(&amp;walker, vcpu, addr, write_fault, user_fault,</span><br><span class="line">     fetch_fault);</span><br><span class="line"></span><br><span class="line">/*页还没映射，交Guest OS处理 */</span><br><span class="line">if (!r) &#123;</span><br><span class="line">pgprintk(&quot;%s: guest page fault\n&quot;, __func__);</span><br><span class="line">----&gt;inject_page_fault(vcpu, addr, walker.error_code);</span><br><span class="line">vcpu-&gt;arch.last_pt_write_count = 0; /* reset fork detector */</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (walker.level &gt;= PT_DIRECTORY_LEVEL) &#123;</span><br><span class="line">level = min(walker.level, mapping_level(vcpu, walker.gfn));</span><br><span class="line">walker.gfn = walker.gfn &amp; ~(KVM_PAGES_PER_HPAGE(level) - 1);</span><br><span class="line">&#125;</span><br><span class="line">----&gt;if (try_async_pf(vcpu, prefault, walker.gfn, addr, &amp;pfn, write_fault,</span><br><span class="line">&amp;map_writable))</span><br><span class="line">return RET_PF_RETRY;</span><br><span class="line"></span><br><span class="line">        if (handle_abnormal_pfn(vcpu, addr, walker.gfn, pfn, walker.pte_access, &amp;r))</span><br><span class="line">                 return r;</span><br><span class="line"></span><br><span class="line">         /*</span><br><span class="line">          * Do not change pte_access if the pfn is a mmio page, otherwise</span><br><span class="line">          * we will cache the incorrect access into mmio spte.</span><br><span class="line">          */</span><br><span class="line">         if (write_fault &amp;&amp; !(walker.pte_access &amp; ACC_WRITE_MASK) &amp;&amp;</span><br><span class="line">              !is_write_protection(vcpu) &amp;&amp; !user_fault &amp;&amp;</span><br><span class="line">               !is_noslot_pfn(pfn)) &#123;</span><br><span class="line">                 walker.pte_access |= ACC_WRITE_MASK;</span><br><span class="line">                 walker.pte_access &amp;= ~ACC_USER_MASK;</span><br><span class="line"></span><br><span class="line">                 /*</span><br><span class="line">                  * If we converted a user page to a kernel page,</span><br><span class="line">                  * so that the kernel can write to it when cr0.wp=0,</span><br><span class="line">                  * then we should prevent the kernel from executing it</span><br><span class="line">                  * if SMEP is enabled.</span><br><span class="line">                  */</span><br><span class="line">                 if (kvm_read_cr4_bits(vcpu, X86_CR4_SMEP))</span><br><span class="line">                         walker.pte_access &amp;= ~ACC_EXEC_MASK;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         spin_lock(&amp;vcpu-&gt;kvm-&gt;mmu_lock);</span><br><span class="line">         if (mmu_notifier_retry(vcpu-&gt;kvm, mmu_seq))</span><br><span class="line">                 goto out_unlock;</span><br><span class="line"></span><br><span class="line">         kvm_mmu_audit(vcpu, AUDIT_PRE_PAGE_FAULT);</span><br><span class="line">         if (make_mmu_pages_available(vcpu) &lt; 0)</span><br><span class="line">                 goto out_unlock;</span><br><span class="line">         if (!force_pt_level)</span><br><span class="line">                 transparent_hugepage_adjust(vcpu, &amp;walker.gfn, &amp;pfn, &amp;level);</span><br><span class="line">       /*写入HVA到页表*/</span><br><span class="line">         r = FNAME(fetch)(vcpu, addr, &amp;walker, write_fault,</span><br><span class="line">                          level, pfn, map_writable, prefault);</span><br><span class="line">         ++vcpu-&gt;stat.pf_fixed;</span><br><span class="line">kvm_mmu_audit(vcpu, AUDIT_POST_PAGE_FAULT);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>对照前面的分析，比较容易理解这个函数了。首先是查guest的页表，如果从GVA到GPA的映射都没建立，那么返回，让Guest OS做这个工作。<br>然后，如果映射已经建立，GPA存在，那么从Guest的页面号，查找Host的页面号,try_async_pf函数根据GFN获取对应的PFN。从memslot可以知道user space首地址，就可以把物理地址GPA转为HVA，通过HVA就可以查到HPA，然后找到所在页的页号。<br>最后，写HVA到页表里面。页表在那里？回顾一下前面kvm_mmu_load的过程，页表是host申请的，host知道页表的真实物理地址。通过页表一层层的搜索，就可以找到要写入的页表项。<br>已知虚拟地址，一级级查找页表找到要写的页表项位置，是经常用的一种操作，这个函数可以认真分析一下实现过程。</p><h2 id="IO虚拟化"><a href="#IO虚拟化" class="headerlink" title="IO虚拟化"></a>IO虚拟化</h2><p>IO虚拟化有两种方案，一种是半虚拟化方案，一种是全虚拟化方案。全虚拟化方案不需要修改Guest的代码，那么Guest里面的io操作最终都变成io指令。在前面的分析中，其实已经涉及了io虚拟化的流程。在VM-exit的时候，前文分析过page fault导致的退出。那么io指令，同样会导致VM-exit退出，然后kvm会把io交给Qemu进程处理。<br>而半虚拟化方案，基本都是把io变成了消息处理，从guest机器发消息出来，然后由host机器处理。此时，在guest机器的驱动都被接管。</p><h3 id="Vmm对io的处理"><a href="#Vmm对io的处理" class="headerlink" title="Vmm对io的处理"></a>Vmm对io的处理</h3><p>当guest因为执行io执行退出后，由handle_io函数处理.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/vmx.c:</span><br><span class="line">static int handle_io(struct kvm_vcpu *vcpu)</span><br><span class="line">&#123;</span><br><span class="line">        unsigned long exit_qualification;</span><br><span class="line">        int size, in, string;</span><br><span class="line">        unsigned port;</span><br><span class="line"></span><br><span class="line">        exit_qualification = vmcs_readl(EXIT_QUALIFICATION);</span><br><span class="line">        string = (exit_qualification &amp; 16) != 0;</span><br><span class="line"></span><br><span class="line">        ++vcpu-&gt;stat.io_exits;</span><br><span class="line"></span><br><span class="line">        if (string)</span><br><span class="line">                return kvm_emulate_instruction(vcpu, 0) == EMULATE_DONE;</span><br><span class="line"></span><br><span class="line">        port = exit_qualification &gt;&gt; 16;</span><br><span class="line">        size = (exit_qualification &amp; 7) + 1;</span><br><span class="line">        in = (exit_qualification &amp; 8) != 0;</span><br><span class="line"></span><br><span class="line">        return kvm_fast_pio(vcpu, size, port, in);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>要从vmcs读退出的信息，然后调用kvm_fast_pio处理,最终走到真正的处理函数emulator_pio_in_out。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">arch/x86/kvm/x86.c:</span><br><span class="line">tatic int emulator_pio_in_out(struct kvm_vcpu *vcpu, int size,</span><br><span class="line">                               unsigned short port, void *val,</span><br><span class="line">                               unsigned int count, bool in)</span><br><span class="line">&#123;</span><br><span class="line">        vcpu-&gt;arch.pio.port = port;</span><br><span class="line">        vcpu-&gt;arch.pio.in = in;</span><br><span class="line">        vcpu-&gt;arch.pio.count  = count;</span><br><span class="line">        vcpu-&gt;arch.pio.size = size;</span><br><span class="line"></span><br><span class="line">        if (!kernel_pio(vcpu, vcpu-&gt;arch.pio_data)) &#123;</span><br><span class="line">                vcpu-&gt;arch.pio.count = 0;</span><br><span class="line">                return 1;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">       /*要赋值退出的种种参数*/</span><br><span class="line">        vcpu-&gt;run-&gt;exit_reason = KVM_EXIT_IO;</span><br><span class="line">        vcpu-&gt;run-&gt;io.direction = in ? KVM_EXIT_IO_IN : KVM_EXIT_IO_OUT;</span><br><span class="line">        vcpu-&gt;run-&gt;io.size = size;</span><br><span class="line">        vcpu-&gt;run-&gt;io.data_offset = KVM_PIO_PAGE_OFFSET * PAGE_SIZE;</span><br><span class="line">        vcpu-&gt;run-&gt;io.count = count;</span><br><span class="line">        vcpu-&gt;run-&gt;io.port = port;</span><br><span class="line"></span><br><span class="line">        return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这里要为io处理赋值各种参数，然后看内核能否处理这个io，如果内核能处理，就不用Qemu进程处理，否则退出内核态，返回用户态。</p><h3 id="虚拟化io流程"><a href="#虚拟化io流程" class="headerlink" title="虚拟化io流程"></a>虚拟化io流程</h3><p>从前文的分析中，我们知道返回是到Qemu的线程上下文中。实际上就是kvm_handle_io这个函数里面。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line">kvm-all.c:</span><br><span class="line">static void kvm_handle_io(uint16_t port, MemTxAttrs attrs, void *data, int di</span><br><span class="line">rection,</span><br><span class="line">                          int size, uint32_t count)</span><br><span class="line">&#123;</span><br><span class="line">    int i;</span><br><span class="line">    uint8_t *ptr = data;</span><br><span class="line"></span><br><span class="line">    for (i = 0; i &lt; count; i++) &#123;</span><br><span class="line">        address_space_rw(&amp;address_space_io, port, attrs,</span><br><span class="line">                         ptr, size,</span><br><span class="line">                         direction == KVM_EXIT_IO_OUT);</span><br><span class="line">        ptr += size;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">exec.c:</span><br><span class="line">MemTxResult address_space_rw(AddressSpace *as, hwaddr addr, MemTxAttrs attrs,</span><br><span class="line">                             uint8_t *buf, int len, bool is_write)</span><br><span class="line">&#123;</span><br><span class="line">    hwaddr l;</span><br><span class="line">    uint8_t *ptr;</span><br><span class="line">    uint64_t val;</span><br><span class="line">    hwaddr addr1;</span><br><span class="line">    MemoryRegion *mr;</span><br><span class="line">    MemTxResult result = MEMTX_OK;</span><br><span class="line">    bool release_lock = false;</span><br><span class="line"></span><br><span class="line">    while (len &gt; 0) &#123;</span><br><span class="line">        l = len;</span><br><span class="line">        mr = address_space_translate(as, addr, &amp;addr1, &amp;l, is_write);</span><br><span class="line"></span><br><span class="line">        if (is_write) &#123;</span><br><span class="line">            if (!memory_access_is_direct(mr, is_write)) &#123;</span><br><span class="line">                release_lock |= prepare_mmio_access(mr);</span><br><span class="line">                l = memory_access_size(mr, l, addr1);</span><br><span class="line">                /* XXX: could force current_cpu to NULL to avoid</span><br><span class="line">                   potential bugs */</span><br><span class="line">                switch (l) &#123;</span><br><span class="line">                case 8:</span><br><span class="line">                    /* 64 bit write access */</span><br><span class="line">                    val = ldq_p(buf);</span><br><span class="line">                    result |= memory_region_dispatch_write(mr, addr1, val, 8,</span><br><span class="line">                                                           attrs);</span><br><span class="line">                    break;</span><br><span class="line">                case 4:</span><br><span class="line">                    /* 32 bit write access */</span><br><span class="line">                    break;</span><br><span class="line">                case 2:</span><br><span class="line">                    /* 16 bit write access */</span><br><span class="line">                    break;</span><br><span class="line">                case 1:</span><br><span class="line">                    /* 8 bit write access */</span><br><span class="line">                    break;</span><br><span class="line">                default:</span><br><span class="line">                    abort();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                addr1 += memory_region_get_ram_addr(mr);</span><br><span class="line">                /* RAM case */</span><br><span class="line">                ptr = qemu_get_ram_ptr(addr1);</span><br><span class="line">                memcpy(ptr, buf, l);</span><br><span class="line">                invalidate_and_set_dirty(mr, addr1, l);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            if (!memory_access_is_direct(mr, is_write)) &#123;</span><br><span class="line">                /* I/O case */</span><br><span class="line">                release_lock |= prepare_mmio_access(mr);</span><br><span class="line">                l = memory_access_size(mr, l, addr1);</span><br><span class="line">                switch (l) &#123;</span><br><span class="line">                case 8:</span><br><span class="line">                    /* 64 bit read access */</span><br><span class="line">                    result |= memory_region_dispatch_read(mr, addr1, &amp;val, 8,</span><br><span class="line">                                                          attrs);</span><br><span class="line">                    stq_p(buf, val);</span><br><span class="line">                    break;</span><br><span class="line">                case 4:</span><br><span class="line">                    /* 32 bit read access */</span><br><span class="line">                    break;</span><br><span class="line">                case 2:</span><br><span class="line">                    /* 16 bit read access */</span><br><span class="line">                    break;</span><br><span class="line">                case 1:</span><br><span class="line">                    /* 8 bit read access */</span><br><span class="line">                    break;</span><br><span class="line">                default:</span><br><span class="line">                    abort();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                /* RAM case */</span><br><span class="line">                ptr = qemu_get_ram_ptr(mr-&gt;ram_addr + addr1);</span><br><span class="line">                memcpy(buf, ptr, l);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (release_lock) &#123;</span><br><span class="line">            qemu_mutex_unlock_iothread();</span><br><span class="line">            release_lock = false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        len -= l;</span><br><span class="line">        buf += l;</span><br><span class="line">        addr += l;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后调用每种设备所登记的指令处理函数处理，完成io。<br>各种设备都有自己的处理函数，所以Qemu需要支持各种不同的设备，Qemu的大部分代码都是各种各样设备的驱动代码（注意这里驱动的意义和传统驱动程序的含义有所不同）。</p><h3 id="设备注册和设备模拟"><a href="#设备注册和设备模拟" class="headerlink" title="设备注册和设备模拟"></a>设备注册和设备模拟</h3><p>QEMU设备注册可以移步<a href="https://www.owalle.com/2018/12/26/qemu-qom/">qemu-qom详解</a></p><h2 id="虚拟化概述脑图"><a href="#虚拟化概述脑图" class="headerlink" title="虚拟化概述脑图"></a>虚拟化概述脑图</h2><p>脑图有待进一步完善</p><p><strong><em> 查看大图请点击<a href="kvm-src-analysis-mind.svg">这里</a> </em></strong></p><p><img src="/2019/02/20/kvm-src-analysis/kvm-src-analysis-mind.svg" alt=""></p><!-- \" style="height:800px" 部分为自定义高度，因为有点bug--><blockquote class="raw-class mindmap mindmap-lg \" style="height:800px" "=""># 虚拟化## CPU虚拟化### 概述#### 指令的模拟##### 陷入（利用处理器的保护机制，中断和异常）1，基于处理器保护机制出发的异常2，虚拟机主动触发的异常3，异步zhognduan###### 虚拟处理器###### 虚拟寄存器###### 上下文#### 中断和异常的虚拟化#### 对称对处理器技术的虚拟化（SMP）##### VMM选择第一个虚拟处理器，BSP##### 其他虚拟处理器，AP### 主要函数#### 创建VCPU##### kvm_vm_ioctl_create_vcpu###### kvm->created_vcpus++;###### kvm_arch_vcpu_create####### kvm_x86_ops->vcpu_create = vmx_create_vcpu######## kvm_vcpu_init######### kvm_arch_vcpu_init########## kvm_mmu_create########## kvm_create_lapic###### kvm_arch_vcpu_setup####### kvm_init_mmu######## init_kvm_tdp_mmu###### create_vcpu_fd#### 创建VM##### kvm_dev_ioctl_create_vm###### kvm_create_vm####### kvm_arch_create_vm######## kvm->mm = current->mm;######## vmx_create_vcpu######### vmx->guest_msrs = kmalloc(PAGE_SIZE, GFP_KERNEL);######### vmx->host_msrs = kmalloc(PAGE_SIZE, GFP_KERNEL);######### alloc_loaded_vmcs(&vmx->vmcs01);######### alloc_apic_access_page####### kvm_arch_vcpu_setup######## vmcs_write64######## vmcs_write64####### kvm->mm = current->mm####### kvm_eventfd_init#### VCPU运行##### kvm_arch_vcpu_ioctl_run###### vcpu_run####### vcpu_enter_guest######## kvm_x86_ops->run(vcpu); ######### vmx_vcpu_run########## asm();######## kvm_x86_ops->handle_external_intr(vcpu);######## kvm_x86_ops->handle_exit(vcpu);####### kvm_inject_pending_timer_irqs####### kvm_vcpu_ready_for_interrupt_injection######## exit_reason = KVM_EXIT_IRQ_WINDOW_OPEN####### kvm_check_async_pf_completion#### 调度##### QEMU###### qemu_kvm_start_vcpu####### qemu_thread_create(cpu->thread, thread_name, qemu_kvm_cpu_thread_fn, cpu, QEMU_THREAD_JOINABLE);######## kvm_cpu_exec######### kvm_vcpu_ioctl(cpu, KVM_RUN, 0);######### kvm_handle_io######### address_space_rw#### 中断##### 中断注入###### vmx_inject_irq####### vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);##### 中断控制芯片模拟###### QEMU####### kvm_irqchip_create######## kvm_vm_ioctl(s, KVM_CREATE_IRQCHIP); ####### kvm_vm_ioctl(s, s->irq_set_ioctl, &event); ######## KVM_IRQ_LINE####### qemu_cpu_kick_thread######## err = pthread_kill(cpu->thread->thread, SIG_IPI);####### kvm_set_irq###### Kernel####### kvm_vm_ioctl_irq_line######## kvm_set_irq######### kvm_pic_set_irq######## kvm_pic_update_irq######### pic_update_irq########## kvm_vcpu_kick########### send_ipi_message(cpumask_of(cpu), IPI_RESCHEDULE);## Memory虚拟化### 概述#### 内存地址连续#### 物理地址从0开始### 主要函数#### kvm_init_mmu##### init_kvm_tdp_mmu###### context->page_fault = tdp_page_fault;####### mmu_topup_memory_caches####### mapping_level####### fast_page_fault####### try_async_pf()######## kvm_find_async_pf_gfn (PV)######### yes: kvm_make_request(KVM_REQ_APF_HALT, vcpu);######### no: kvm_arch_setup_async_pf(vcpu, gva, gfn)########## kvm_setup_async_pf(vcpu, gva, kvm_vcpu_gfn_to_hva(vcpu, gfn), &arch)########### INIT_WORK(&work->work, async_pf_execute);########### kvm_inject_page_fault(vcpu, &fault);####### __direct_map(vcpu, write, map_writable, level, gfn, pfn, prefault);######## for_each_shadow_entry(vcpu, (u64)gfn << PAGE_SHIFT, iterator)######## kvm_mmu_get_page######### for_each_gfn_sp######### kvm_mmu_alloc_page(vcpu, parent_pte, direct); ########## mmu_memory_cache_alloc(&vcpu->arch.mmu_page_header_cache)########## mmu_memory_cache_alloc(&vcpu->arch.mmu_page_cache);######## link_shadow_page###### context->root_level = is_la57_mode(vcpu) ?PT64_ROOT_5LEVEL : PT64_ROOT_4LEVEL;##### init_kvm_softmmu###### kvm_init_shadow_mmu####### paging64_init_context######## paging64_init_context_common######### paging64_page_fault########## FNAME(page_fault)########### inject_page_fault########### try_async_pf########### FNAME(fetch)#### kvm_mmu_reload##### kvm_mmu_load###### mmu_alloc_roots###### kvm_mmu_load_cr3#### __kvm_set_memory_region##### new.userspace_addr = mem->userspace_addr##### kvzalloc(sizeof(struct kvm_memslots), GFP_KERNEL);#### handle_exception##### intr_info = vmx->exit_intr_info;##### kvm_mmu_page_fault## I/O虚拟化### 概述#### 设备发现##### 总线类型的设备###### 总线类型不可枚举####### ISA设备####### PS/2键盘、鼠标、RTC####### 传统IDE控制器###### 总线类型可枚举、资源可配置####### PCI##### 完全模拟的设备###### Frontend / backend 模型#### 访问截获##### I/O端口的访问###### I/O位图来决定##### MMIO访问###### 页表项设置为无效#### 设备模拟### 主要函数#### PIO##### handle_io###### emulator_pio_in_out####### kernel_pio##### kvm_handle_io###### address_space_rw#### MMIO##### vmx_enable_tdp###### ept_set_mmio_spte_mask####### kvm_mmu_set_mmio_spte_mask(, 110b) an EPT paging-structure entry is 110b (write/execute).##### vcpu_run/entry_guest之后###### vm_exit//tdp_page_fault####### kvm_check_async_pf_completion######## kvm_arch_async_page_ready######### context->page_fault = tdp_page_fault########## __direct_map / 构建EPT########### mmu_set_spte############  if (unlikely(is_noslot_pfn(pfn)))  mark_mmio_spte(vcpu, sptep, gfn, access);##### handle_ept_misconfig###### kvm_mmu_page_fault####### ++vcpu->stat.mmio_exits;return 1;//Qemu process first## 中断虚拟化### 概述#### Local APIC per VCPU##### 虚拟PIC (i8259)##### 虚拟IO-APIC##### 虚拟Local APIC#### 中断采集#### 中断注入### 主要函数#### IOCTL (KVM_CREATE_IRQCHIP)##### kvm_pic_init###### kvm_io_bus_register_dev(kvm, KVM_PIO_BUS###### kvm->arch.vpic##### kvm_ioapic_init###### kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, ioapic->base_address,###### kvm->arch.vioapic##### kvm_setup_default_irq_routing###### kvm_set_irq_routing(kvm, default_routing,####### setup_routing_entry#### 虚拟设备中断##### IOCTL(KVM_IRQ_LINE)中断注入###### kvm_set_irqirq_set[i].set(####### kvm_set_pic_irq######## kvm_vcpu_kick####### kvm_set_ioapic_irq######## ioapic_service######### kvm_irq_delivery_to_apic########## kvm_apic_set_irq########### kvm_make_request########### kvm_vcpu_kick###### vcpu_enter_guest / guest_run之前！####### inject_pending_event######## kvm_x86_ops->set_irq(vcpu);######### vmx_inject_irq########## vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);#### 外部设备中断external interrupt##### vcpu_enter_guest###### kvm_x86_ops->handle_external_intr####### vmx_handle_external_intr######## vector =  exit_intr_info & INTR_INFO_VECTOR_MASK######## 直接把vector送给host上的中断handler### LAPIC 虚拟化#### alloc_apic_access_page#### page = gfn_to_page(kvm, 0xfee00 000)##### vmcs_write64(VIRTUAL_APIC_PAGE_ADDR, __pa(vmx->vcpu.arch.apic->regs))##### vmcs_write64(APIC_ACCESS_ADDR, page_to_phys(vmx->vcpu.kvm->arch.apic_access_page));</blockquote>]]></content>
      
      
      <categories>
          
          <category> kvm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kvm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>英特尔®64和IA-32架构软件开发人员手册(Intel SDM)</title>
      <link href="/2019/01/29/Intel-SDM/"/>
      <url>/2019/01/29/Intel-SDM/</url>
      
        <content type="html"><![CDATA[<h3 id="23-1-概述"><a href="#23-1-概述" class="headerlink" title="23.1 概述"></a>23.1 概述</h3><p>本章介绍虚拟机体系结构的基础知识和虚拟机扩展的概述(VMX),支持多个软件环境的处理器硬件虚拟化。<br>关于VMX指令的信息参考英特尔®64和IA-32架构软件开发人员手册中的第2B卷。其他关于VMX和系统编程参考SDM 第3B卷</p><h3 id="23-2虚拟机器结构"><a href="#23-2虚拟机器结构" class="headerlink" title="23.2虚拟机器结构"></a>23.2虚拟机器结构</h3><p>虚拟机扩展为IA-32处理器上的虚拟机定义了处理器级支持。两个重要支持的软件类别：</p><ul><li><p>虚拟机监视器(VMM)<br>VMM充当主机，可以完全控制处理器和其他处理器平台硬件。 VMM使用虚拟的抽象来呈现客户软件(参见下一段)<br>处理器并允许它直接在逻辑处理器上执行。 VMM能够保留选择性控制处理器资源，物理内存，中断管理和I / O。</p></li><li><p>Guest- 每个虚拟机(VM)<br>是一个支持堆栈组成的客户软件环境,操作系统(OS)和应用程序软件。每个都独立于其他虚拟机运行在物理的处理器上，内存，存储器，图形和I / O的相同接口上使用平台。软件堆栈就像在没有VMM的平台上运行一样。软件执行中虚拟机必须以降低的权限运行，以便VMM可以保留对平台资源的控制。</p></li></ul><h3 id="23-3-VMX操作简介"><a href="#23-3-VMX操作简介" class="headerlink" title="23.3 VMX操作简介"></a>23.3 VMX操作简介</h3><p>虚拟化的处理器支持由称为VMX操作的处理器操作形式提供。有两种VMX操作：VMX root和VMX non-root操作。通常，VMM运行在VMX root模式下，同时将guest 软件运行在non-root模式下。<br>VMX root操作和VMX non-root操作的转换称为VMX转换。有两种VMX转换:</p><ul><li>从VMX root过渡到VMX non-root模式称为VM entry； </li><li>从VMX not-root操作到VMX root的转换成为VM exit。<br>VMX root操作中的处理器行为与VMX操作之外的处理器行为非常相似。主要区别是一组新指令(VMX指令)（见第23.8节）。<br>VMX non-root操作中的处理器行为受到限制和修改，以便于虚拟化。那些指令（包括新的VMCALL指令）和事件会导致VM EXIT的发生，而不仅仅是他们原来的操作。由于这些VM Exit取代了普通行为，因此VMX non-root操作中的软件功能是有限制的。正是这种限制允许VMM保持对处理器资源的控制。<br>并不存在用于通知guest“是否处于VMX non-root”的寄存器。这一事实可以防止guest软件察觉它正在虚拟机中运行。<br>因为VMX操作对(CPL)Level 0做了限制，guest的软件可以在最初设计的权限级别运行。这样就可以简化VMM的开发。</li></ul><h3 id="23-4-VMM软件的生命周期"><a href="#23-4-VMM软件的生命周期" class="headerlink" title="23.4 VMM软件的生命周期"></a>23.4 VMM软件的生命周期</h3><p>图23-1说明了VMM及其客户软件的生命周期以及它们之间的交互。以下项目总结了生命周期：<br><img src="/2019/01/29/Intel-SDM/figure23-1.png" alt=""></p><ul><li>软件通过执行VMXON指令进入VMX操作</li><li>使用VM entry，VMM可以执行guest，一次一个。</li><li>VMM通过使用VMLAUNCH和VMRESUME指令干预虚拟机。通过VM EXIT，VMM重新获得控制权。</li><li>VM移交控制权到VMM指定的入口点。VMM可以采取适当的措施使得VM exit发生，然后可以使用VM entry返回到虚拟机。</li><li>最终，VMM可以通过执行VMXOFF自行决定关闭并离开VMX操作。</li></ul><h3 id="23-5虚拟机控制结构"><a href="#23-5虚拟机控制结构" class="headerlink" title="23.5虚拟机控制结构"></a>23.5虚拟机控制结构</h3><p>VMX non-root的操作以及VMX转换由名为“虚拟机控制”(VMCS)的数据结构控制。<br>通过VMCS指针(每个逻辑CPU一个)来管理对VMCS的访问。VMCS指针的值是64位地址。读取和写入VMCS指针使用指令VMPTRST和VMPTRLD。并且VMM使用VMREAD，VMWRITE和VMCLEAR指令来配置VMCS。<br>VMM可以为其支持的每个虚拟机使用不同的VMCS。对于具有多个的虚拟机在逻辑处理器（虚拟处理器）中，VMM可以为每个虚拟处理器使用不同的VMCS。</p><h3 id="23-6-发现对VMX的支持"><a href="#23-6-发现对VMX的支持" class="headerlink" title="23.6 发现对VMX的支持"></a>23.6 发现对VMX的支持</h3><p>在系统软件进入VMX操作之前，它必须检查处理器中是否存在VMX支持。系统软件可以使用CPUID确定处理器是否支持VMX操作。如果<code>CPUID.1：ECX.VMX [bit 5] = 1</code>那么当前平台支持VMX操作。请参见第3章“指令集参考，A-L”英特尔®64和IA-32架构软件开发人员手册，第2A卷。<br>VMX体系结构旨在实现可扩展性，以便VMX操作中的未来处理器可以支持VMX体系结构的第一代实现中不存在的其他功能。使用一组VMX功能MSR向软件报告可扩展VMX功能的可用性（参见附录A，“VMX功能”)。</p><h3 id="23-7启用和进入VMX操作"><a href="#23-7启用和进入VMX操作" class="headerlink" title="23.7启用和进入VMX操作"></a>23.7启用和进入VMX操作</h3><p>在系统软件进入VMX操作之前，它通过设置<code>CR4.VMXE [bit 13] = 1</code> VMX操作来启用VMX。然后通过执行VMXON指令进入。当’CR4.VMXE = 0’时，如果执行指令VMXON会导致无效操作码异常（#UD)；一旦执行过VMX操作，就无法清除CR4.VMXE（参见第23.8节）。系统软件通过执行VMXOFF指令离开VMX操作。执行VMXOFF后，可以在VMX操作之外清除CR4.VMXE。<br>VMXON也由IA32_FEATURE_CONTROL MSR（MSR地址3AH）控制。该MSR清零重置逻辑处理器时MSR的相关位是：</p><ul><li>位0是锁定位。如果该位清零，则VMXON会导致general-protection异常。如果设置了锁定位，WRMSR到此MSR会导致general-protection异常;在上电复位之前，不能修改MSR。系统BIOS可以使用此位为BIOS提供设置选项以禁用对VMX的支持。在平台中启用VMX支持，BIOS必须设置位1或者位2或两者（见下文）以及锁定位。</li><li>位1在SMX操作中启用VMXON。如果该位清零，则在SMX操作中执行VMXON会导致general-protection expection。尝试在不支持两个VMX的逻辑处理器上设置此位操作（参见第23.6节）和SMX操作（参见英特尔®中的第6章“安全模式扩展参考”第2D卷）导致general-proction异常。</li><li>位2在SMX操作之外启用VMXON。如果该位清零，则在SMX外部执行VMXON操作会导致general-proction异常。尝试在没有的逻辑处理器上设置此位支持VMX操作（参见第23.6节）导致general-proction异常。</li></ul><p>在执行VMXON之前，软件应该分配一个逻辑上自然对齐的4 KB内存区域,处理器可用于支持VMX操作.1该区域称为VMXON region。VMXON zone的地址区域（VMXON指针）在VMXON的操作数中提供。第24节</p><h3 id="23-8-VMX操作限制"><a href="#23-8-VMX操作限制" class="headerlink" title="23.8 VMX操作限制"></a>23.8 VMX操作限制</h3><p>（作者：限制还有很有一些的，暂且不一一列举了吧，这里挑1-2点）</p><ul><li>当逻辑处理器在VMX root操作时，中断信号是被block的。但当在VMX non-root模式的时候，不会被block，相反中断信号会触发VM exit。</li></ul><h3 id="24-1-虚拟机控制结构-VMCS"><a href="#24-1-虚拟机控制结构-VMCS" class="headerlink" title="24.1 虚拟机控制结构(VMCS)"></a>24.1 虚拟机控制结构(VMCS)</h3><p>逻辑处理器在VMX操作中使用”虚拟机控制结构”（VMCS）。这些管理VMX进出非root与root操作（VM entry和VM exit）以及处理器在VMX non-root时的行为。这个结构由新指令VMCLEAR，VMPTRLD，VMREAD, VMWRITE操纵。<br>VMM可以为其支持的每个虚拟机使用不同的VMCS。对于具有多个的虚拟机在逻辑处理器（虚拟处理器）中，VMM可以为每个虚拟处理器使用不同的VMCS。<br>逻辑处理器将存储器中的区域与每个VMCS相关联。该区域称为VMCS region。软件使用区域的64位物理地址（VMCS指针）引用特定VMCS。 VMCS指针必须在4 KB边界上对齐（位11：0必须为零）。这些指针不能设置超出理器的物理地址宽度。<br>逻辑处理器可以维护多个活动的VMCS。处理器通过维护内存中活跃VMCS的状态来优化VMX操作。在任何给定时间，最多一个活动VMCS的数量是当前VMCS。 （本文档经常使用术语“VMCS”来指代当前VMCS。）VMLAUNCH，VMREAD，VMRESUME和VMWRITE指令仅对当前操作VMCS。<br>以下各项描述了逻辑处理器如何确定哪些VMCS处于活动状态以及哪些VMCS处于当前状态：</p><ul><li>VMPTRLD指令的内存操作数是VMCS的地址。执行完指令后VMCS在逻辑处理器上既是活动的和也是当前的。任何其他活动的VMCS都不是当前VMCS。</li><li>VMCS中的VMCS链接指针字段（参见第24.4.2节）本身就是VMCS的地址。如果VM entry正确执行了，并且“VMCS shadow”VM执行控制（VMCS）的1设置成功，那么VMCS链接指针字段引用的字符在逻辑处理器上变为活动状态。当前VMCS不会改变。</li><li>VMCLEAR指令的内存操作数也是VMCS的地址。执行完毕后指令，VMCS在逻辑处理器上既不是活动的也不是当前的。如果VMCS已经开启逻辑处理器，逻辑处理器不再具有当前的VMCS。</li></ul><p>VMPTRST指令将逻辑处理器的当前VMCS的地址存储到指定的存储器位置（如果没有当前的VMCS，则存储值FFFFFFFF_FFFFFFFFH）。<br>VMCS的启动状态确定哪个VM-entry指令应该与该VMCS一起使用：VMLAUNCH指令需要VMCS，其启动状态为“清除”; VMRESUME指令需要VMCS，其发射状态是“发射”。逻辑处理器在相应的VMCS中维护VMCS的启动状态区域。以下各项描述了逻辑处理器如何管理VMCS的启动状态：</p><ul><li>如果当前VMCS的启动状态为“clear”，则VMLAUNCH指令的成功执行会发生变化发射状态为“launched”。</li><li>VMCLEAR指令的内存操作数是VMCS的地址。执行完指令后VMCS的启动状态是“clear”。</li><li>没有其他方法可以修改VMCS的启动状态（无法使用VMWRITE进行修改）也没有直接的方法来发现它（它无法使用VMREAD读取）</li></ul><p>图24-1说明了VMCS的不同状态。它使用“X”表示VMCS，使用“Y”表示任何其他VMCS。因此：“VMPTRLD X”总是使得VMCS变为当前和活动状态; “VMPTRLD Y”让X不再是当前状态（因为它使Y变为当前状态）;如果X是当前的并且其启动状态时，则VMLAUNCH的会将X变为“launched”; VMCLEAR X总是使X处于非活动状态而不是当前状态，并使其启动状态“clear”。<br>该图未示出相对于这些参数不修改VMCS状态的操作（例如，当X已经是当前时执行VMPTRLD X）。请注意，VMCLEAR X使X“处于非活动状态，非当前状态，并且clear。即使X的当前状态未定义（例如，即使X尚未初始化）。见24.11.3节。<br>由于影子VMCS（请参阅第24.10节）不能用于VM条目，因此影子VMCS的启动状态为没有意义。图24-1未说明可以使影子VMCS处于活动状态的所有方式。<br><img src="/2019/01/29/Intel-SDM/figure24-1.png" alt=""></p><h3 id="24-2-VMCS-Region的格式"><a href="#24-2-VMCS-Region的格式" class="headerlink" title="24.2 VMCS Region的格式"></a>24.2 VMCS Region的格式</h3><p>VMCS的格式包含了4K，VMCS的格式如表24-1</p><table><thead><tr><th>byte offside</th><th>内容</th></tr></thead><tbody><tr><td>0</td><td>0~30位 VMCS保留，识别符<br>31位: shadow-VMCS标识位</td></tr><tr><td>4</td><td>VMCS终止位</td></tr><tr><td>8</td><td>VMCS 数据</td></tr></tbody></table><p>VMCS区域的前4个字节包含位30：0的VMCS修订标识符。维护的处理器不同格式的VMCS数据（见下文）使用不同的VMCS修订标识符。位31：shadow-VMCS指标（参见第24.10节）</p><p>在将该区域用于VMCS之前，软件应将VMCS标识符写入VMCS区域。该VMCS标识符永远不会被处理器写入;如果VMPTRLD的操作数引用VMCS区域的标识符与处理器正在使用的VMCS不同，则VMPTRLD会失败。 （如果是影子VMCS，并且处理器不支持shadow-VMCS，那么VMPTRLD也会失败）软件可以通过读取VMX相关MSR IA32_VMX_BASIC来检查处理器VMCS标识符。<br>软件应根据VMCS是否为普通还是shadow-vmcs来设置或者清楚shadow-VMCS标识符.不支持“VMCS阴影”VM执行控件的1设置。软件可以通过读取VMX功能MSR IA32_VMX_PROCBASED_CTLS2来检查是否支持。<br>VMCS区域的接下来的4个字节用于VMX中止指示符。这些位的内容没有控制处理器。当VMX中止发生时，逻辑处理器将非零值写入这些位。软件也可以写入此字段。<br>VMCS区域的其余部分用于VMCS数据（控制VMX non-root操作以及VMX转换）。这些数据的格式是特定的。写回可缓存内存中的VMCS区域和相关结构（在第24.11.4节中列举）。未来实现可以允许或要求不同的存储器类型。软件应参考VMX功能MSR<br>IA32_VMX_BASIC（见附录A.1）</p><p>未完待续…… </p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>利用QOM(Qemu Object Model)创建虚拟设备</title>
      <link href="/2018/12/26/qemu-qom/"/>
      <url>/2018/12/26/qemu-qom/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是QOM"><a href="#什么是QOM" class="headerlink" title="什么是QOM"></a>什么是QOM</h2><p>QOM(Qemu Object Model)是QEMU最新的设备模型，将所有的模拟设备整合成了一种单根结点(系统总线)的树状形式，并具有热插拔功能。后来可能由于Device和Bus之间的复杂关系，又开发了QOM。<br>QOM是QEMU在C的基础上自己实现的一套面向对象机制，负责将device、bus等设备都抽象成为对象。</p><h2 id="QOM-的初始化"><a href="#QOM-的初始化" class="headerlink" title="QOM 的初始化"></a>QOM 的初始化</h2><p>对象的初始化分为四步：</p><ul><li>将 TypeInfo 注册 TypeImpl</li><li>实例化 ObjectClass</li><li>实例化 Object</li><li>添加 Property</li></ul><p>根据QEMU的wiki ，QOM没有构造和析构的概念。但矛盾的是根据代码，TypeInfo 中定义的 class_init 和 instance_init 无论从名字还是实现上都做了对象的初始化工作，比如设置对象成员的值。但为什么说它们最多只能算是初始化函数呢？<br><code>Everything in QOM is a device</code><br>根据实现，经过 class_init 和 instance_init 产生设备对应Object后，这个Object是不能直接使用的。其真正初始化逻辑的大头都放在 realize 中做，比如创建对应的memory region，挂载到对应bus上等等。只有在 realize 后，设备才算真正构造完成，可以拿来用了。因此QEMU认为，类似构造和析构的是realize和unrealize。而在设备的生命周期中，可以被realize和unrealize多次。<br>为了保持习惯，本文会依然将 class_init 和 instance_init 当做构造函数，称前者为类构造函数，后者为类实例构造函数。</p><h2 id="使用QOM添加设备源码分析"><a href="#使用QOM添加设备源码分析" class="headerlink" title="使用QOM添加设备源码分析"></a>使用QOM添加设备源码分析</h2><p>下面我们就利用一个真实的案例，讲解一下利用QOM添加设备的具体实现步骤</p><h3 id="TypeInfo-gt-ModuleEntry"><a href="#TypeInfo-gt-ModuleEntry" class="headerlink" title="TypeInfo =&gt; ModuleEntry"></a>TypeInfo =&gt; ModuleEntry</h3><p>设备相关代码的入口就是这里了, TypeInfo 定义了一种类型，并且使用函数type_register_static注册：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">static const TypeInfo caffee_agent_info = &#123;</span><br><span class="line">    .name          = &quot;caffee-agent&quot;,</span><br><span class="line">    .parent        = TYPE_ISA_DEVICE,</span><br><span class="line">    .class_init    = caffee_agent_class_init,</span><br><span class="line">    .instance_size = sizeof(CaffeeAgentState),</span><br><span class="line">    .instance_init = caffee_agent_initfn,</span><br><span class="line">&#125;;</span><br><span class="line">                                             </span><br><span class="line">static void caffee_agent_register_types (void)</span><br><span class="line">&#123;</span><br><span class="line">    type_register_static (&amp;caffee_agent_info);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type_init(cafe_agent_register_types)</span><br></pre></td></tr></table></figure><p>包含 类型的名称(name)、父类名称(parent)、Object实例的大小(instance_size)、是否抽象类(abstract)、初始化函数(class_init)。<br>代码底部有 type_init ，由 C run-time(CRT)负责执行：<br><!--`type_init(kvm_type_init) => module_init(function, MODULE_INIT_QOM) => register_module_init(function, type)`--></p><div id="flowchart-0" class="flow-chart"></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void register_module_init(void (*fn)(void), module_init_type type)</span><br><span class="line">&#123;</span><br><span class="line">    ModuleEntry *e;</span><br><span class="line">    ModuleTypeList *l;</span><br><span class="line"></span><br><span class="line">    e = g_malloc0(sizeof(*e));</span><br><span class="line">    e-&gt;init = fn;</span><br><span class="line">    e-&gt;type = type;</span><br><span class="line"></span><br><span class="line">    l = find_type(type);</span><br><span class="line"></span><br><span class="line">    QTAILQ_INSERT_TAIL(l, e, node);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建了 type 为 MODULE_INIT_QOM ，init为 kvm_type_init 的 ModuleEntry ，并加入到 MODULE_INIT_QOM 的 ModuleTypeList 中。</p><h3 id="ModuleEntry-gt-TypeImpl"><a href="#ModuleEntry-gt-TypeImpl" class="headerlink" title="ModuleEntry =&gt; TypeImpl"></a>ModuleEntry =&gt; TypeImpl</h3><p>在 main.c(vl.c) 的一开始执行了 module_call_init(MODULE_INIT_QOM) ，它从 init_type_list 中取出对应的 ModuleTypeList ，然后对里面的 ModuleEntry 成员都调用 init 函数。<br>对于上文提到的 ModuleEntry ，调用的是：<br><!---`kvm_type_init => type_register_static(&kvm_accel_type) => type_register => type_register_internal`--></p><div id="flowchart-1" class="flow-chart"></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">static TypeImpl *type_register_internal(const TypeInfo *info)</span><br><span class="line">&#123;</span><br><span class="line">    TypeImpl *ti;</span><br><span class="line">    ti = type_new(info);</span><br><span class="line"></span><br><span class="line">    type_table_add(ti);</span><br><span class="line">    return ti;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它根据 kvm_accel_type(TypeInfo) 创建一个名为TYPE_KVM_ACCEL的 TypeImpl 类型的结构。<br>同时将该 TypeImpl 注册到全局 type_table 中，key为类型名称，即 TYPE_KVM_ACCEL</p><h3 id="ObjectClass"><a href="#ObjectClass" class="headerlink" title="ObjectClass"></a>ObjectClass</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">struct ObjectClass</span><br><span class="line">&#123;</span><br><span class="line">    /*&lt; private &gt;*/</span><br><span class="line">    Type type;              // 用typedef定义的 TypeImpl 指针</span><br><span class="line">    GSList *interfaces;</span><br><span class="line"></span><br><span class="line">    const char *object_cast_cache[OBJECT_CLASS_CAST_CACHE];</span><br><span class="line">    const char *class_cast_cache[OBJECT_CLASS_CAST_CACHE];</span><br><span class="line"></span><br><span class="line">    ObjectUnparent *unparent;</span><br><span class="line"></span><br><span class="line">    GHashTable *properties;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>ObjectClass 属于类对象，它是所有类对象的基类。</p><h4 id="TypeImpl-gt-ObjectClass"><a href="#TypeImpl-gt-ObjectClass" class="headerlink" title="TypeImpl =&gt; ObjectClass"></a>TypeImpl =&gt; ObjectClass</h4><p>有两种路径，一种是主动地调用：<br><!---`object_class_get_list => object_class_foreach => g_hash_table_foreach(object_class_foreach_tramp) => object_class_foreach_tramp => type_initialize`--></p><p><div id="flowchart-2" class="flow-chart"></div><br>比如 object_class_get_list(TYPE_DEVICE, false) 创建 TYPE_DEVICE 类型的 ObjectClass<br>该过程用到glic的函数 g_hash_table_foreach ，见 <a href="https://developer.gnome.org/glib/stable/glib-Hash-Tables.html#g-hash-table-foreach" target="_blank" rel="noopener">https://developer.gnome.org/glib/stable/glib-Hash-Tables.html#g-hash-table-foreach</a><br>另一种是被动调用，如:</p><ul><li>object_class_by_name</li><li>object_class_get_parent</li><li>object_new_with_type</li><li>object_initialize_with_type</li></ul><p>在获取 class、class的parent、创建type的object、初始化TypeImpl的object时，调用 type_initialize<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">type_initialize</span><br><span class="line">=&gt; 如果 TypeImpl 已创建(class成员有值)，返回</span><br><span class="line">=&gt; ti-&gt;class = g_malloc0(ti-&gt;class_size)                    根据class_size分配内存空间</span><br><span class="line">=&gt; type_get_parent(ti)                                      获取父类的TypeImpl</span><br><span class="line">=&gt; memcpy(ti-&gt;class, parent-&gt;class, parent-&gt;class_size)     将parent的class拷贝到自己class的最前面</span><br><span class="line">=&gt; ti-&gt;class-&gt;properties = g_hash_table_new_full            创建存放property的hash table</span><br><span class="line">=&gt; type_initialize_interface                                初始化class的接口，包括父类和自己的</span><br><span class="line">=&gt; ti-&gt;class-&gt;type = ti                                     设置class的type为对应TypeImpl</span><br><span class="line">=&gt; parent-&gt;class_base_init                                  如果parent定义了 class_base_init ，调用之</span><br><span class="line">=&gt; ti-&gt;class_init(ti-&gt;class, ti-&gt;class_data)                调用class的 class_init</span><br></pre></td></tr></table></figure></p><p>对于 kvm_accel_type 这个 TypeInfo 的 TypeImpl ，调用的class_init是 kvm_accel_class_init ，它将传入的 ObjectClass 强转为子类 AccelClass ，设置 init_machine 成员为 kvm_init<br>这里的class是该类型的类实例，它的基类是 ObjectClass 。</p><h4 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h4><p>从创建流程可以看出，在创建类对象时，会调用 type_initialize ，其会递归地对 TypeImpl 中的 parent 成员(TypeImpl)递归调用 type_initialize ，然后将创建出来的相应 ObjectClass 拷贝到自己class的最前面。<br>类对象的第一个成员是 parent_class ，由于父类对象会拷到子类对象的最前面，因此可以认为其指向父类的对象，如此构成链状的继承链，最终指向基类对象 ObjectClass<br>比如 kvm_accel_type 对应的类对象，该类对象作为叶子类型并没有定义，但其父类 AccelClass 在代码中有定义，其的第一个成员为 ObjectClass ，表示其继承自 ObjectClass 。为了能表示该叶子类型继承 AccelClass ，它修改了 AccelClass的一些对象成员，这样在某种程度上表示了继承关系。比如修改了函数指针成员的指向，相当于实现了虚函数。<br>又如： <code>register_info 对应的类对象 =&gt; PCIDeviceClass =&gt; DeviceClass =&gt; ObjectClass</code> 构成继承链，最前端的叶子类型通过修改 PCIDeviceClass 成员进行定义。</p><h4 id="强制类型转换"><a href="#强制类型转换" class="headerlink" title="强制类型转换"></a>强制类型转换</h4><p>将一个父类的指针转换为子类的指针是不安全的，为了实现这种转换，各类需要提供强制类型转换的宏，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#define ACCEL_CLASS(klass) \</span><br><span class="line">    OBJECT_CLASS_CHECK(AccelClass, (klass), TYPE_ACCEL)</span><br><span class="line"></span><br><span class="line">#define OBJECT_CLASS_CHECK(class_type, class, name) \</span><br><span class="line">    ((class_type *)object_class_dynamic_cast_assert(OBJECT_CLASS(class), (name), \</span><br><span class="line">                                               __FILE__, __LINE__, __func__))</span><br></pre></td></tr></table></figure></p><p>如果类对象指针的name和目标子类的name一致，或类对象指针是目标子类的祖先，则执行转换，否则 abort<br>反过来，从子类指针转换为父类指针是安全的，因为类的第一项就指向父类，访问时不会存在越界等问题。 </p><h3 id="Object"><a href="#Object" class="headerlink" title="Object"></a>Object</h3><p>Object 属于类实例对象，它是所有类实例对象的基类。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">struct Object</span><br><span class="line">&#123;</span><br><span class="line">    /*&lt; private &gt;*/</span><br><span class="line">    ObjectClass *class;             // 指向类对象</span><br><span class="line">    ObjectFree *free;</span><br><span class="line">    GHashTable *properties;         // 维护属性的哈希表</span><br><span class="line">    uint32_t ref;                   // 引用计数</span><br><span class="line">    Object *parent;                 // 指向父类实例对象，实现继承</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>可以看到其第一个成员指向类对象，同时维护有区别于类属性的类实例属性。</p><h4 id="创建流程"><a href="#创建流程" class="headerlink" title="创建流程"></a>创建流程</h4><p>就流程而言，在C runtime 根据 TypeInfo 创建了 TypeImpl 后，此后主要根据 TypeImpl 创建 ObjectClass 和 Object<br>以 TypeInfo(kvm_accel_type) 为例，其创建的 TypeImpl 在以下流程发挥作用：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">main =&gt; configure_accelerator =&gt; accel_init_machine(acc, ms)</span><br><span class="line">=&gt; ObjectClass *oc = OBJECT_CLASS(acc)                                  将AccelClass指针转换成父类(ObjectClass)指针</span><br><span class="line">=&gt; object_class_get_name                                                获取 ObjectClass-&gt;TypeImpl 的类名，如 kvm-accel</span><br><span class="line">=&gt; ACCEL(object_new(cname))                                             利用名称创建 AccelState 对象</span><br><span class="line">=&gt; acc-&gt;init_machine(ms)                                                初始化machine，实际上是调用 kvm_init</span><br><span class="line"></span><br><span class="line">object_new</span><br><span class="line">=&gt; type_get_by_name(typename)                                           根据类名查type_table获取 TypeImpl</span><br><span class="line">=&gt; object_new_with_type =&gt; type_initialize                              创建 TypeImpl 对应的类对象，设置到对应 TypeImpl-&gt;class 中</span><br><span class="line">                        =&gt; g_malloc(type-&gt;instance_size)                分配类实例对象的内存</span><br><span class="line">                        =&gt; object_initialize_with_type                  创建类实例对象</span><br><span class="line">                            =&gt; type_initialize  会再次尝试实例化类对象</span><br><span class="line">                            =&gt; obj-&gt;class = type-&gt;class                 设置类实例对象的类对象为 TypeImpl-&gt;class</span><br><span class="line">                            =&gt; obj-&gt;properties = g_hash_table_new_full  创建存放类实例对象property的hash table</span><br><span class="line">                            =&gt; object_init_with_type =&gt; object_init_with_type   如果 TypeImpl 有父类，递归调用object_init_with_type</span><br><span class="line">                                                     =&gt; ti-&gt;instance_init(obj)  如果定义了类实例的构造函数，调用之</span><br></pre></td></tr></table></figure></p><h4 id="继承-1"><a href="#继承-1" class="headerlink" title="继承"></a>继承</h4><p>定义上的继承主要指类的继承，既然类对象已经通过包含的方式实现了继承，那么类实例对象就可以通过调用自己的class成员调用父类的函数，访问父类的class property。<br>但在QEMU实现的这套面向对象模型中，类实例对象也拥有自己的构造函数，因此根据继承关系，需要对父类实例对象的构造函数进行调用。<br>从创建流程可以看出，在创建类实例对象时，会调用 object_init_with_type ，其会递归地对 TypeImpl 中的 parent 成员递归调用 object_init_with_type ，从而让所有父类的 instance_init 都得到调用，在调用时传入的是当前对象的地址，相当于在当前对象上对父类实例对象进行构造。<br>同理，类实例对象的第一个成员是 parent_obj ，指向父类的实例对象，如此构成链状的继承链，最终指向基类实例对象 Object<br>如： kvm_accel_type的类实例Object =&gt; AccelState =&gt; Object<br>又如： register_info的类实例Object =&gt; PCIDevice =&gt; DeviceState =&gt; Object</p><h4 id="强制类型转换-1"><a href="#强制类型转换-1" class="headerlink" title="强制类型转换"></a>强制类型转换</h4><p>同理，将一个父类实例的指针转换为子类实例指针是不安全的。为了实现这种转换，各类需要提供强制类型转换的宏，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#define ACCEL(obj) \</span><br><span class="line">    OBJECT_CHECK(AccelState, (obj), TYPE_ACCEL)</span><br><span class="line"></span><br><span class="line">#define OBJECT_CHECK(type, obj, name) \</span><br><span class="line">    ((type *)object_dynamic_cast_assert(OBJECT(obj), (name), \</span><br><span class="line">                                        __FILE__, __LINE__, __func__))</span><br></pre></td></tr></table></figure></p><p>如果类实例对象指针的name和目标子类实例的name一致，或类实例对象指针是目标子类的祖先，则执行转换，否则 abort。<br>反过来，从子类实例指针转换为父类实例指针是安全的，因为类实例的第一项就指向父类实例，访问时不会存在越界等问题。</p><h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><p>属性分为类对象(ObjectClass)属性和类实例对象(Object)属性，存储于 properties 成员中。properties 是一个 GHashTable ，存储了属性名到ObjectProperty的映射。</p><h4 id="属性模版"><a href="#属性模版" class="headerlink" title="属性模版"></a>属性模版</h4><p>用于创建属性对象 ObjectProperty<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">struct Property &#123;</span><br><span class="line">    const char   *name;</span><br><span class="line">    PropertyInfo *info;</span><br><span class="line">    ptrdiff_t    offset;</span><br><span class="line">    uint8_t      bitnr;</span><br><span class="line">    QType        qtype;</span><br><span class="line">    int64_t      defval;</span><br><span class="line">    int          arrayoffset;</span><br><span class="line">    PropertyInfo *arrayinfo;</span><br><span class="line">    int          arrayfieldsize;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><h4 id="属性对象"><a href="#属性对象" class="headerlink" title="属性对象"></a>属性对象</h4><p>属性对象包含属性名称、类型、描述，类型对应的属性结构，以及相应访问函数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">typedef struct ObjectProperty</span><br><span class="line">&#123;</span><br><span class="line">    gchar *name;</span><br><span class="line">    gchar *type;</span><br><span class="line">    gchar *description;</span><br><span class="line">    ObjectPropertyAccessor *get;</span><br><span class="line">    ObjectPropertyAccessor *set;</span><br><span class="line">    ObjectPropertyResolve *resolve;</span><br><span class="line">    ObjectPropertyRelease *release;</span><br><span class="line">    void *opaque;</span><br><span class="line">&#125; ObjectProperty;</span><br></pre></td></tr></table></figure></p><p>如对于bool类型的属性，opaque为 BoolProperty ，set为 property_set_bool ，get为 property_get_bool 。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">typedef struct BoolProperty</span><br><span class="line">&#123;</span><br><span class="line">    bool (*get)(Object *, Error **);</span><br><span class="line">    void (*set)(Object *, bool, Error **);</span><br><span class="line">&#125; BoolProperty;</span><br></pre></td></tr></table></figure></p><p>用于保存用户传入的 getter 和 setter 。</p><h4 id="getter-setter-callback-hook"><a href="#getter-setter-callback-hook" class="headerlink" title="getter / setter (callback hook)"></a>getter / setter (callback hook)</h4><p>定义了在设置/读取属性时触发的函数。<br>比如 device 类型的 instance_init 即 device_initfn 中，定义了 realized 属性：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">object_property_add_bool(obj, &quot;realized&quot;, device_get_realized, device_set_realized, NULL)</span><br></pre></td></tr></table></figure></p><p>则 getter 为 device_get_realized ， setter 为 device_set_realized</p><h4 id="静态属性"><a href="#静态属性" class="headerlink" title="静态属性"></a>静态属性</h4><p>凡是在代码中就已经定义好名称和类型的属性，都是静态属性。包括在初始化过程中添加 和 props 。</p><h5 id="初始化过程中添加"><a href="#初始化过程中添加" class="headerlink" title="初始化过程中添加"></a>初始化过程中添加</h5><p>比如对于 TypeInfo x86_cpu_type_info ，类实例初始化函数 x86_cpu_initfn 定义好了属性：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">object_property_add(obj, &quot;family&quot;, &quot;int&quot;,</span><br><span class="line">                    x86_cpuid_version_get_family,</span><br><span class="line">                    x86_cpuid_version_set_family, NULL, NULL, NULL);</span><br><span class="line"></span><br><span class="line">object_property_add_alias(obj, &quot;kvm_steal_time&quot;, obj, &quot;kvm-steal-time&quot;, &amp;error_abort);</span><br></pre></td></tr></table></figure></p><p>该属性会直接加到类实例对象的properties中。</p><h5 id="props"><a href="#props" class="headerlink" title="props"></a>props</h5><p>一些类对象会在 class_init 中设置 props 成员，比如 TypeInfo host_x86_cpu_type_info 在 host_x86_cpu_class_init 设置为 host_x86_cpu_properties：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">static Property host_x86_cpu_properties[] = &#123;</span><br><span class="line">    DEFINE_PROP_BOOL(&quot;migratable&quot;, X86CPU, migratable, true),</span><br><span class="line">    DEFINE_PROP_BOOL(&quot;host-cache-info&quot;, X86CPU, cache_info_passthrough, false),</span><br><span class="line">    DEFINE_PROP_END_OF_LIST()</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">#define DEFINE_PROP_BOOL(_name, _state, _field, _defval) &#123;       \</span><br><span class="line">        .name      = (_name),                                    \</span><br><span class="line">        .info      = &amp;(qdev_prop_bool),                          \</span><br><span class="line">        .offset    = offsetof(_state, _field)                    \</span><br><span class="line">            + type_check(bool, typeof_field(_state, _field)),    \</span><br><span class="line">        .qtype     = QTYPE_QBOOL,                                \</span><br><span class="line">        .defval    = (bool)_defval,                              \</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">// 闭包</span><br><span class="line">PropertyInfo qdev_prop_bool = &#123;</span><br><span class="line">    .name  = &quot;bool&quot;,</span><br><span class="line">    .get   = get_bool,</span><br><span class="line">    .set   = set_bool,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>而类实例 X86CPU 中定义了这些属性：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">struct X86CPU &#123;</span><br><span class="line">    bool migratable;</span><br><span class="line">    ...</span><br><span class="line">    bool cache_info_passthrough;</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>于是 X86CPU.migratable 和 X86CPU.cache_info_passthrough 两个成员被定义成属性。</p><p>在父类 device_type_info 的类实例初始化函数 device_initfn 中，对所有的props，有：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">do &#123;</span><br><span class="line">    for (prop = DEVICE_CLASS(class)-&gt;props; prop &amp;&amp; prop-&gt;name; prop++) &#123;</span><br><span class="line">        qdev_property_add_legacy(dev, prop, &amp;error_abort);</span><br><span class="line">        qdev_property_add_static(dev, prop, &amp;error_abort);</span><br><span class="line">    &#125;</span><br><span class="line">    class = object_class_get_parent(class);</span><br><span class="line">&#125; while (class != object_class_by_name(TYPE_DEVICE));</span><br></pre></td></tr></table></figure></p><p>而 qdev_property_add_static ：</p><p><pre><br>=&gt; object_property_add(obj, prop-&gt;name, prop-&gt;info-&gt;name, prop-&gt;info-&gt;get, prop-&gt;info-&gt;set, prop-&gt;info-&gt;release, prop, &amp;local_err)<br>    根据Property中的数据，创建ObjectProperty，并将其加到类实例对象的 properties 中<br>    关键是将闭包中的get和set取出，作为ObjectProperty的get和set<br>=&gt; object_property_set_description     设置属性的描述字符串<br>=&gt; 设置属性的默认值<br></pre></p><h5 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h5><p>可通过命令查看设备的静态属性，参数为设备 TypeInfo 的 name：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/binss/work/qemu/qemu-2.8.1.1/x86_64-softmmu/qemu-system-x86_64 -device Broadwell-x86_64-cpu,?</span><br></pre></td></tr></table></figure></p><p>但是， x86_64-cpu 抽象设备无法打。 host-x86_64-cpu 无法列出。</p><h4 id="动态属性"><a href="#动态属性" class="headerlink" title="动态属性"></a>动态属性</h4><p>指在运行时动态进行添加的属性。比如用户通过参数传入了一个设备，需要作为属性和其它设备关联起来。<br>典型的动态属性就是 child&lt;&gt; 和 link&lt;&gt; (因为其类型就是这样构造的，后文简称child和link) 。</p><h5 id="child"><a href="#child" class="headerlink" title="child"></a>child</h5><p>child实现了composition关系，表示一个设备(parent)创建了另外一个设备(child)，parent掌控child的生命周期，负责向其发送事件。一个device只能有一个parent，但能有多个child。这样就构成一棵组合树。<br>通过 object_property_add_child 添加child：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">=&gt; object_property_add            将 child 作为 obj 的属性，属性名name，类型为 &quot;child&lt;child的类名&gt;&quot;，同时getter为object_get_child_property，没有setter</span><br><span class="line">=&gt; child-&gt;parent = obj</span><br></pre></td></tr></table></figure></p><p>例如 x86_cpu_realizefn =&gt; x86_cpu_apic_create =&gt; object_property_add_child(OBJECT(cpu), “lapic”, OBJECT(cpu-&gt;apic_state), &amp;error_abort) 将创建 APICCommonState ，并设置为 X86CPU 的child。<br>可以在qemu hmp查询到：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(qemu) info qom-tree</span><br><span class="line">/machine (pc-q35-2.8-machine)</span><br><span class="line">  /unattached (container)</span><br><span class="line">    /device[0] (host-x86_64-cpu)</span><br></pre></td></tr></table></figure></p><h5 id="link"><a href="#link" class="headerlink" title="link"></a>link</h5><p>link实现了backlink关系，表示一个设备引用了另外一个设备，是一种松散的联系。两个设备之间能有多个link关系，可以进行修改。它完善了组合树，使其构成构成了一幅有向图。<br>通过 object_property_add_link 添加link：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">=&gt; 创建 LinkProperty ，填充目标(child)的信息</span><br><span class="line">=&gt; object_property_add            将 LinkProperty 作为 obj 的属性，属性名name，类型为 &quot;link&lt;child的类名&gt;&quot;，同时getter为 object_get_link_property 。如果传入了check函数，则需要回调，设置setter为 object_set_link_property</span><br></pre></td></tr></table></figure></p><p>例如 q35 有以下link：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">static void q35_host_initfn(Object *obj)</span><br><span class="line">&#123;</span><br><span class="line">    object_property_add_link(obj, MCH_HOST_PROP_RAM_MEM, TYPE_MEMORY_REGION,</span><br><span class="line">                             (Object **) &amp;s-&gt;mch.ram_memory,</span><br><span class="line">                             qdev_prop_allow_set_link_before_realize, 0, NULL);</span><br><span class="line"></span><br><span class="line">    object_property_add_link(obj, MCH_HOST_PROP_PCI_MEM, TYPE_MEMORY_REGION,</span><br><span class="line">                             (Object **) &amp;s-&gt;mch.pci_address_space,</span><br><span class="line">                             qdev_prop_allow_set_link_before_realize, 0, NULL);</span><br><span class="line"></span><br><span class="line">    object_property_add_link(obj, MCH_HOST_PROP_SYSTEM_MEM, TYPE_MEMORY_REGION,</span><br><span class="line">                             (Object **) &amp;s-&gt;mch.system_memory,</span><br><span class="line">                             qdev_prop_allow_set_link_before_realize, 0, NULL);</span><br><span class="line"></span><br><span class="line">    object_property_add_link(obj, MCH_HOST_PROP_IO_MEM, TYPE_MEMORY_REGION,</span><br><span class="line">                             (Object **) &amp;s-&gt;mch.address_space_io,</span><br><span class="line">                             qdev_prop_allow_set_link_before_realize, 0, NULL);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>将 Q35PCIHost 和 ram_memory / pci_address_space / system_memory / address_space_io 链接起来。</p><h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4><p>根据前面所述，属性有两种定义方式，一种是通过 <code>DEFINE_PROP_*</code> 定义，另一种是通过 <code>object_property_add_&lt;type&gt;</code> 进行定义。根据不同的定义方式，set会不同，设置值的方式也有所不同。</p><h5 id="object-property-set-lt-type-gt"><a href="#object-property-set-lt-type-gt" class="headerlink" title="object_property_set_&lt;type&gt;"></a><code>object_property_set_&lt;type&gt;</code></h5><p>用于设置某个属性的值。比如 object_property_set_bool ：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">=&gt; qbool_from_bool                                              将要设置的值包装成相应的 QObject ，这里是QBool</span><br><span class="line">=&gt; object_property_set_qobject</span><br><span class="line">    =&gt; qobject_input_visitor_new                                将传入的QObject包装成Visitor，其中含各类型的处理函数</span><br><span class="line">    =&gt; object_property_set =&gt; object_property_find              从props的hash table中找到对应的 ObjectProperty</span><br><span class="line">                           =&gt; prop-&gt;set</span><br></pre></td></tr></table></figure></p><p>对于 DEFINE_PROP_BOOL 创建的属性来说，其闭包为qdev_prop_bool，因此在初始化时 set 被设置为 set_bool<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">set_bool</span><br><span class="line">=&gt; qdev_get_prop_ptr                                                                       将设备指针加上属性值在其中的偏移量，得到属性值的地址</span><br><span class="line">=&gt; visit_type_bool =&gt; v-&gt;type_bool (qobject_input_type_bool) =&gt; qobject_input_get_object   从Visitor中取出QObject</span><br><span class="line">                                                             =&gt; qbool_get_bool             从QObject中取出值，设置到属性值的地址</span><br></pre></td></tr></table></figure></p><p>对于 object_property_add_bool 创建的属性来说，它在 object_property_add 时设置 set 为 property_set_bool<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">property_set_bool</span><br><span class="line">=&gt; visit_type_bool =&gt; v-&gt;type_bool (qobject_input_type_bool) =&gt; qobject_input_get_object  找到QObject</span><br><span class="line">=&gt; (BoolProperty)prop-&gt;set    调用setter</span><br></pre></td></tr></table></figure></p><p>比如 device 类型的 instance_init 即 device_initfn 中，定义了 realized 属性：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">object_property_add_bool(obj, &quot;realized&quot;, device_get_realized, device_set_realized, NULL)</span><br></pre></td></tr></table></figure></p><p>于是 setter 为 device_set_realized<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">=&gt; dc-&gt;realize                                      调用realize函数，其在 class_init 中定义</span><br><span class="line">=&gt; dev-&gt;realized = value                            设置类实例对象的成员</span><br></pre></td></tr></table></figure></p><p>一句话总结，前者的属性值的设置由 type_bool 负责设置，而后者由 setter 负责设置。</p><h5 id="object-property-get-lt-type-gt"><a href="#object-property-get-lt-type-gt" class="headerlink" title="object_property_get_&lt;type&gt;"></a><code>object_property_get_&lt;type&gt;</code></h5><p>用于读取某个属性的值。比如 object_property_get_bool ：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">=&gt; object_property_get_qobject</span><br><span class="line">    =&gt; 创建空的QObject指针</span><br><span class="line">    =&gt; qobject_output_visitor_new                                                           将传入的QObject包装成Visitor，其中含各类型的处理函数</span><br><span class="line">    =&gt; object_property_get =&gt; object_property_find                                          从props的hash table中找到对应的 ObjectProperty</span><br><span class="line">                           =&gt; prop-&gt;get                                                     调用get函数，设置QObject</span><br><span class="line">=&gt; qobject_to_qbool                                                                         将QObject转成QBool</span><br><span class="line">=&gt; qbool_get_bool                                                                           从QBool中取出值，返回</span><br></pre></td></tr></table></figure></p><p>对于 DEFINE_PROP_BOOL 创建的属性来说，其闭包为qdev_prop_bool，因此在初始化时 get 被设置为 get_bool<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">get_bool</span><br><span class="line">=&gt; qdev_get_prop_ptr(dev, prop)                                                             将设备指针加上属性值在其中的偏移量，得到属性值的地址</span><br><span class="line">=&gt; visit_type_bool =&gt; v-&gt;type_bool (qobject_output_type_bool) =&gt; qobject_input_get_object   将属性值包装成QObject</span><br></pre></td></tr></table></figure></p><p>对于 object_property_add_bool 创建的属性来说，它在 object_property_add 时设置 get 为 property_get_bool ：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">property_get_bool</span><br><span class="line">=&gt; prop-&gt;get                                                                                调用getter，得到属性值</span><br><span class="line">=&gt; visit_type_bool =&gt; v-&gt;type_bool (qobject_output_type_bool) =&gt; qobject_input_get_object   将属性值包装成QObject</span><br></pre></td></tr></table></figure></p><p>个人的理解是，set 和 get 都需要通过 QObject 和 Visitor 两层包装。前者把要设置属性值包装成QObject再到Visitor，然后再取出设置到相应地址。后者根据属性值地址将属性值包装成QObject，设置为Visitor中QObject指针指向，然后再从QObject中取出值。</p><h5 id="object-property-parse"><a href="#object-property-parse" class="headerlink" title="object_property_parse"></a>object_property_parse</h5><p>在用一个string设置不知道类型的属性的值时，使用 object_property_parse：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">void object_property_parse(Object *obj, const char *string,</span><br><span class="line">                           const char *name, Error **errp)</span><br><span class="line">&#123;</span><br><span class="line">    Visitor *v = string_input_visitor_new(string);</span><br><span class="line">    object_property_set(obj, v, name, errp);</span><br><span class="line">    visit_free(v);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>它会创建一个 Visitor 并将值设置到里面，这里定义了string转其他类型属性的函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">v-&gt;visitor.type = VISITOR_INPUT;</span><br><span class="line">v-&gt;visitor.type_int64 = parse_type_int64;</span><br><span class="line">v-&gt;visitor.type_uint64 = parse_type_uint64;</span><br><span class="line">v-&gt;visitor.type_size = parse_type_size;</span><br><span class="line">v-&gt;visitor.type_bool = parse_type_bool;</span><br><span class="line">v-&gt;visitor.type_str = parse_type_str;</span><br><span class="line">v-&gt;visitor.type_number = parse_type_number;</span><br></pre></td></tr></table></figure></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>如此一来，根据 TypeInfo 创建了 TypeImpl ，然后根据 TypeImpl 创建了对应的 ObjectClass ，再根据 TypeImpl 创建了对应的 Object ， ObjectClass 和 Object 都有自己的 Property，关系如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">                TypeImpl</span><br><span class="line">                class      -&gt;  ObjectClass(AccelClass)    Object(AccelState)</span><br><span class="line">                           &lt;-       type            &lt;-         class</span><br><span class="line">TypeImpl  &lt;-  parent_type    properties(GHashTable)     properties(GHashTable)</span><br></pre></td></tr></table></figure></p><p><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.8/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.11.3/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">op1=>operation: type_init(kvm_type_init)op2=>operation: module_init(function, MODULE_INIT_QOM)op3=>operation: register_module_init(function, type)op1(right)->op2(right)->op3</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script><textarea id="flowchart-1-code" style="display: none">op1=>operation: kvm_type_initop2=>operation: type_register_static(&kvm_accel_type)op3=>operation: type_registerop4=>operation: type_register_internalop1(right)->op2(right)->op3(right)->op4</textarea><textarea id="flowchart-1-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-1-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-1", options);</script><textarea id="flowchart-2-code" style="display: none">op1=>operation: object_class_get_listop2=>operation: object_class_foreachop3=>operation: g_hash_table_foreach(object_class_foreach_tramp)op4=>operation: object_class_foreach_trampop5=>operation: type_initializeop1(right)->op2(right)->op3(right)->op4(right)->op5</textarea><textarea id="flowchart-2-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-2-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-2-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-2", options);</script></p>]]></content>
      
      
      <categories>
          
          <category> QEMU </category>
          
      </categories>
      
      
        <tags>
            
            <tag> QEMU QOM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Debug QEMU with GDB</title>
      <link href="/2018/12/24/qemu-debug/"/>
      <url>/2018/12/24/qemu-debug/</url>
      
        <content type="html"><![CDATA[<p>学习Qemu-KVM虚拟机最重要的一步——调试QEMU，我们这里提前帮大家简单的总结归纳一下。<br>Qemu的调试稍微有点特殊的地方就是，除了Qemu程序自身源代码的调试以外，我们可以通过Qemu+GDB来调试我们虚拟机程序。下面将两个不同方面的调试方法介绍一下。</p><h2 id="1-调试QEMU源码"><a href="#1-调试QEMU源码" class="headerlink" title="1. 调试QEMU源码"></a>1. 调试QEMU源码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gdb --args x86_64-softmmu/qemu-system-x86_64 --enable-kvm -m 1024 -drive file=test.qcow2 -append console=ttyS0 -kernel /boot/vmlinuz -initrd /boot/initrd.gz</span><br></pre></td></tr></table></figure><p>当然以上参数中从–enable-kvm开始之后的参数因人而异，不尽相同。执行过之后，就会进入gdb界面，就可以跟其他普通应用程序一样，进行单步调试、设置断点、查看栈、寄存器内容等</p><h2 id="2-调试虚拟机"><a href="#2-调试虚拟机" class="headerlink" title="2. 调试虚拟机"></a>2. 调试虚拟机</h2><p>这部分是本文的重点。跟调试应用程序不同，调试虚拟机时gdb和qemu分开执行，似乎并不能用gdb来调用qemu。长话短说，先来看如何启动qemu：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./x86_64-softmmu/qemu-system-x86_64 -s -S --enable-kvm -m 1024 -hda test.qcow2</span><br></pre></td></tr></table></figure></p><p>同样，参数从–enable-kvm开始之后的参数也都不是必须的。着重了解下两个必须的参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-s shorthand for -gdb tcp::1234</span><br><span class="line">-S freeze CPU at startup (use &apos;c&apos; to start execution)</span><br></pre></td></tr></table></figure></p><p>然后新开一个终端执行gdb，这样就跟调试应用程序一样，会看到同样的’(gdb)’ 提示符。<br>在提示符中输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">target remote localhost:1234</span><br></pre></td></tr></table></figure></p><p>1234是默认用于远程调试连接的端口号。<br>然后设置断点”break *0x7c00”，这样就将一个断点设置在了bootloader被加载到的内存地址，接下来就任你玩了。</p><pre>[root@ccd-sdv6 ~]# gdbGNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-100.el7Copyright (C) 2013 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later <http: gnu.org="" licenses="" gpl.html="">This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.  Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:<http: www.gnu.org="" software="" gdb="" bugs="">.<font color="#0099ff" face="黑体">(gdb) target remote localhost:1234</font>Remote debugging using localhost:12340x0000fff0 in ?? ()(gdb) cContinuing.Program received signal SIGINT, Interrupt.0x00002bcb in ?? ()<font color="#0099ff" face="黑体">(gdb) b *0x7c00</font>Breakpoint 1 at 0x7c00.<font color="#0099ff" face="黑体">(gdb) info breakpoints</font>Num     Type           Disp Enb Address    What1       breakpoint     keep y   0x00007c00(gdb)</http:></http:></pre><h2 id="顺便附上一些用到的gdb的快捷键以及命令"><a href="#顺便附上一些用到的gdb的快捷键以及命令" class="headerlink" title="顺便附上一些用到的gdb的快捷键以及命令"></a>顺便附上一些用到的gdb的快捷键以及命令</h2><h3 id="TUI-窗口"><a href="#TUI-窗口" class="headerlink" title="TUI 窗口"></a>TUI 窗口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Ctrl + x, Ctrl + a</span><br><span class="line">好像等效</span><br><span class="line">Ctrl + x, a</span><br></pre></td></tr></table></figure><p>一般也就按着Ctrl键，依次按下字母x 和a就可以再TUI和非TUI间切换</p><h3 id="TUI-窗口概述"><a href="#TUI-窗口概述" class="headerlink" title="TUI 窗口概述"></a>TUI 窗口概述</h3><p>在TUI模式中，可以显示以下几个窗口：</p><ul><li>命令窗口<br>用于GDB调试时的命令输入和命令结果输出显示，与普通GDB窗口无异。</li><li>源代码窗口<br>用于显示程序源代码，包括当前运行行、中断以中断标识等。</li><li>汇编窗口<br>显示当前程序的汇编代码。</li><li>寄存器窗口<br>显示处理器的寄存器内容，当寄存器内容发生改变时会高亮显示。<br>源代码窗口和汇编窗口会高亮显示程序运行位置并以’&gt;’符号标记。有两个特殊标记用于标识断点，第一个标记用于标识断点类型：<ul><li>B : 程序至少有一次运行到了该断点</li><li>b : 程序没有运行到过该断点</li><li>H : 程序至少有一次运行到了该硬件断点</li><li>h : 程序没有运行到过该硬件断点<br>第二个标记用于标识断点使能与否:</li><li>+ : 断点使能Breakpointis enabled. </li><li>- : 断点被禁用Breakpointis disabled. </li></ul></li></ul><h3 id="三窗口模式"><a href="#三窗口模式" class="headerlink" title="三窗口模式"></a>三窗口模式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Ctrl + 2</span><br></pre></td></tr></table></figure><p>使TUI的上半部分分割成两个窗口，连接按此快捷键可在三种组合中切换。<br>寄存器窗口、代码窗口、汇编窗口 三个窗口只能同时显示两个，共3种组合。</p><h3 id="更换激活窗口"><a href="#更换激活窗口" class="headerlink" title="更换激活窗口"></a>更换激活窗口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Ctrl + o</span><br></pre></td></tr></table></figure><p>之所以需要切换激活窗口，是因为有些快捷键，比如箭头上下左右，page up/down只有在当前窗口起作用</p><h3 id="GDB-command"><a href="#GDB-command" class="headerlink" title="GDB command"></a>GDB command</h3><p><code>c</code> : continue<br><code>r</code> : run<br><code>n</code> : next<br><code>s</code> : step</p><h3 id="TUI-特有命令"><a href="#TUI-特有命令" class="headerlink" title="TUI 特有命令"></a>TUI 特有命令</h3><p><code>info win</code> ：显示正在显示的窗口大小信息<br><code>layout next</code> ：显示下一个窗口<br><code>layout prev</code> ：显示上一个窗口<br><code>layout src</code> ：显示源代码窗口<br><code>layout asm</code> ：显示汇编窗口<br><code>layout split</code> ：显示源代码和汇编窗口<br><code>layout regs</code> ：显示寄存器窗口<br><code>focus next</code> ： 将一个窗口置为激活状态<br><code>focus prev</code> ：将上一个窗口置为激活状态<br><code>focus src</code> : 将源代码窗口置为激活状态<br><code>focus asm</code> ：将汇编窗口置为激活状态<br><code>focus regs</code> ： 将寄存器窗口置为激活状态<br><code>focus cmd</code> ：将命令行窗口置为激活状态<br><code>refresh</code> ： 更新窗口，与C-L快捷键同</p><p><code>tuireg float</code> ：寄存器窗口显示内容为浮点寄存器<br><code>tuireg general</code> ：寄存器窗口显示内容为普通寄存器<br><code>tuireg next</code> ：显示下一组寄存器，预定义的寄存器组: general, float,system, vector,all, save,restore.<br><code>tuireg system</code> ：显示上一组寄存器<br><code>update</code> ：更新源代码窗口到当前运行点<br><code>winname + count</code> ：增加指定窗口的高度<br><code>winname + count</code> ：减小指定窗口的高度<br><code>tabset nchars</code> : Set the width of tab stops to be nchars characters</p><h3 id="条件断点："><a href="#条件断点：" class="headerlink" title="条件断点："></a>条件断点：</h3><p>在gdb中可以watch一个寄存器，命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">watch $eax == 0x0000ffaa</span><br></pre></td></tr></table></figure><p>另外，当我们想有条件的设置某一个断点的时候，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">break test.c:120 if $eax == 0x0000ffaa</span><br></pre></td></tr></table></figure></p><p><img src="/2018/12/24/qemu-debug/gdb_tui.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> QEMU </category>
          
      </categories>
      
      
        <tags>
            
            <tag> QEMU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KVM 虚拟化原理4--内存</title>
      <link href="/2018/12/10/kvm-memory/"/>
      <url>/2018/12/10/kvm-memory/</url>
      
        <content type="html"><![CDATA[<h2 id="内存虚拟化简介"><a href="#内存虚拟化简介" class="headerlink" title="内存虚拟化简介"></a>内存虚拟化简介</h2><p>前一章介绍了CPU虚拟化的内容，这一章介绍一下KVM的内存虚拟化原理。可以说内存是除了CPU外最重要的组件，Guest最终使用的还是宿主机的内存，所以内存虚拟化其实就是关于如何做Guest到宿主机物理内存之间的各种地址转换，如何转换会让转换效率更高呢，KVM经历了三代的内存虚拟化技术，大大加快了内存的访问速率。</p><h2 id="传统的地址转换"><a href="#传统的地址转换" class="headerlink" title="传统的地址转换"></a>传统的地址转换</h2><p>在保护模式下，普通的应用进程使用的都是自己的虚拟地址空间，一个64位的机器上的每一个进程都可以访问0到2^64的地址范围，实际上内存并没有这么多，也不会给你这么多。对于进程而言，他拥有所有的内存，对内核而言，只分配了一小段内存给进程，待进程需要更多的进程的时候再分配给进程。<br>通常应用进程所使用的内存叫做虚拟地址，而内核所使用的是物理内存。内核负责为每个进程维护虚拟地址到物理内存的转换关系映射。<br>首先，逻辑地址需要转换为线性地址，然后由线性地址转换为物理地址。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">逻辑地址 ==&gt; 线性地址 ==&gt; 物理地址</span><br></pre></td></tr></table></figure><p>逻辑地址和线性地址之间通过简单的偏移来完成。<br><img src="/2018/12/10/kvm-memory/logical_address.png" alt=""></p><p>一个完整的逻辑地址 = [段选择符：段内偏移地址]，查找GDT或者LDT（通过寄存器gdtr，ldtr）找到描述符，通过段选择符(selector)前13位在段描述符做index，找到Base地址，Base+offset就是线性地址。</p><p>为什么要这么做？据说是Intel为了保证兼容性。</p><p>逻辑地址到线性地址的转换在虚拟化中没有太多的需要介绍的，这一层不存在实际的虚拟化操作，和传统方式一样，最重要的是线性地址到物理地址这一层的转换。</p><p>传统的线性地址到物理地址的转换由CPU的页式内存管理，页式内存管理。<br>页式内存管理负责将线性地址转换到物理地址，一个线性地址被分五段描述，第一段为基地址，通过与当前CR3寄存器（CR3寄存器每个进程有一个，线程共享，当发生进程切换的时候，CR3被载入到对应的寄存器中，这也是各个进程的内存隔离的基础）做运算，得到页表的地址index，通过四次运算，最终得到一个大小为4K的页（有可能更大，比如设置了hugepages以后）。整个过程都是CPU完成，进程不需要参与其中，如果在查询中发现页已经存在，直接返回物理地址，如果页不存在，那么将产生一个缺页中断，内核负责处理缺页中断，并把页加载到页表中，中断返回后，CPU获取到页地址后继续进行运算。</p><p><img src="/2018/12/10/kvm-memory/page.png" alt=""></p><h2 id="KVM中的内存结构"><a href="#KVM中的内存结构" class="headerlink" title="KVM中的内存结构"></a>KVM中的内存结构</h2><p>由于qemu-kvm进程在宿主机上作为一个普通进程，那对于Guest而言，需要的转换过程就是这样。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Guest虚拟内存地址(GVA)</span><br><span class="line">          |</span><br><span class="line">    Guest线性地址 </span><br><span class="line">          |</span><br><span class="line">   Guest物理地址(GPA)</span><br><span class="line">          |             Guest</span><br><span class="line">   ------------------</span><br><span class="line">          |             HV</span><br><span class="line">    HV虚拟地址(HVA)</span><br><span class="line">          |</span><br><span class="line">      HV线性地址</span><br><span class="line">          |</span><br><span class="line">    HV物理地址(HPA)</span><br></pre></td></tr></table></figure><p>What’s the fu*k ？这么多…<br>别着急，Guest虚拟地址到HV线性地址之间的转换和HV虚拟地址到线性地址的转换过程可以省略，这样看起来就更清晰一点。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Guest虚拟内存地址(GVA)</span><br><span class="line">          |</span><br><span class="line">   Guest物理地址(GPA)</span><br><span class="line">          |             Guest</span><br><span class="line">  ------------------</span><br><span class="line">          |             HV</span><br><span class="line">    HV虚拟地址(HVA)</span><br><span class="line">          |</span><br><span class="line">    HV物理地址(HPA)</span><br></pre></td></tr></table></figure><p>前面也说到KVM通过不断的改进转换过程，让KVM的内存虚拟化更加的高效，我们从最初的软件虚拟化的方式介绍。</p><h2 id="软件虚拟化方式实现"><a href="#软件虚拟化方式实现" class="headerlink" title="软件虚拟化方式实现"></a>软件虚拟化方式实现</h2><p>第一层转换，由GVA-&gt;GPA的转换和传统的转换关系一样，通过查找CR3然后进行页表查询，找到对应的GPA，GPA到HVA的关系由qemu-kvm负责维护，我们在<a href="http://www.cnblogs.com/Bozh/p/5753379.html" target="_blank" rel="noopener">第二章KVM启动过程</a>的demo里面就有介绍到怎样给KVM映射内存，通过mmap的方式把HV的内存映射给Guest。</p><p><img src="/2018/12/10/kvm-memory/gpa_hpa.png" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">struct kvm_userspace_memory_region region = &#123;</span><br><span class="line">    .slot = 0,</span><br><span class="line">    .guest_phys_addr = 0x1000,</span><br><span class="line">    .memory_size = 0x1000,</span><br><span class="line">    .userspace_addr = (uint64_t)mem,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>可以看到，qemu-kvm的kvm_userspace_memory_region结构体描述了guest的物理地址起始位置和内存大小，然后描述了Guest的物理内存在HV的映射<code>userspace_addr</code>，通过多个slot，可以把不连续的HV的虚拟地址空间映射给Guest的连续的物理地址空间。</p><p><img src="/2018/12/10/kvm-memory/gpa_hpa2.png" alt=""></p><p>软件模拟的虚拟化方式由qemu-kvm来负责维护GPA-&gt;HVA的转换，然后再经过一次HVA-&gt;HPA的方式，从过程上来看，这样的访问是很低效的，特别是在当GVA到GPA转换时候产生缺页中断，这时候产生一个异常Guest退出，HV捕获异常后计算出物理地址（分配新的内存给Guest），然后重新Entry。这个过程会可能导致频繁的Guest退出，且转换过程过长。于是KVM使用了一种叫做影子页表的技术。</p><h2 id="影子页表的虚拟化方式"><a href="#影子页表的虚拟化方式" class="headerlink" title="影子页表的虚拟化方式"></a>影子页表的虚拟化方式</h2><p>影子页表的出现，就是为了减少地址转换带来的开销，直接把GVA转换到HVP的技术。在软件虚拟化的内存转换中，GVA到GPA的转换通过查询CR3寄存器来完成，CR3保存了Guest中的页表基地址，然后载入MMU来做地址转换。<br>在加入了影子页表的技术后，当访问到CR3寄存器的时候（可能是由于Guest进程后导致的），KVM捕获到这个操作，<a href="http://www.cnblogs.com/Bozh/p/5757274.html" target="_blank" rel="noopener">CPU虚拟化章节</a> EXIT_REASON_CR_ACCESS，qemu-kvm通过载入特俗的CR3和影子页表来欺骗Guest这个就是真实的CR3，后面的操作就和传统的访问内存的方式一致，当需要访问物理内存的时候，只会经过一层的影子页表的转换。</p><p><img src="/2018/12/10/kvm-memory/gpa_hpa3_shadow.png" alt=""></p><p>影子页表由qemu-kvm进程维护，实际上就是一个Guest的页表到宿主机页表的映射，每一级的页表的hash值对应到qemu-kvm中影子页表的一个目录。在初次GVA-&gt;HPA的转换时候，影子页表没有建立，此时Guest产生缺页中断，和传统的转换过程一样，经过两次转换(VA-&gt;PA)，然后影子页表记录GVA-&gt;GPA-&gt;HVA-&gt;HPA。这样产生GVA-&gt;GPA的直接关系，保存到影子页表中。</p><p><img src="/2018/12/10/kvm-memory/gpa_hpa4.png" alt=""></p><p>影子页表的引入，减少了GVA-&gt;HPA的转换过程，但是坏处在于qemu-kvm需要为Guest的每个进程维护一个影子页表，这将带来很大的内存开销，同时影子页表的建立是很耗时的，如果Guest进程过多，将导致频繁的影子页表的导入与导出，虽然用了cache技术，但是还是软件层面的，效率并不是最好，所以Intel和AMD在此基础上提供了硬件虚拟化技术。</p><h2 id="EPT硬件加速的虚拟化方式"><a href="#EPT硬件加速的虚拟化方式" class="headerlink" title="EPT硬件加速的虚拟化方式"></a>EPT硬件加速的虚拟化方式</h2><p><img src="/2018/12/10/kvm-memory/gpa_hpa5_ept.png" alt=""><br>EPT(extended page table)可以看做一个硬件的影子页表，在Guest中通过增加EPT寄存器，当Guest产生了CR3和页表的访问的时候，由于对CR3中的页表地址的访问是GPA，当地址为空时候，也就是Page fault后，产生缺页异常，如果在软件模拟或者影子页表的虚拟化方式中，此时会有VM退出，qemu-kvm进程接管并获取到此异常。但是在EPT的虚拟化方式中，qemu-kvm忽略此异常，Guest并不退出，而是按照传统的缺页中断处理，在缺页中断处理的过程中会产生EXIT_REASON_EPT_VIOLATION，Guest退出，qemu-kvm捕获到异常后，分配物理地址并建立GVA-&gt;HPA的映射，并保存到EPT中，将EPT载入到MMU，下次转换时候直接查询根据CR3查询EPT表来完成GVA-&gt;HPA的转换。以后的转换都由硬件直接完成，大大提高了效率，且不需要为每个进程维护一套页表，减少了内存开销。<br>在笔者的测试中，Guest和HV的内存访问速率对比为3756MB/s对比4340MB/s。可以看到内存访问已经很接近宿主机的水平了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>KVM内存的虚拟化就是一个将虚拟机的虚拟内存转换为宿主机物理内存的过程，Guest使用的依然是宿主机的物理内存，只是在这个过程中怎样减少转换带来的开销成为优化的主要点。<br>KVM经过软件模拟-&gt;影子页表-&gt;EPT的技术的进化，效率也越来越高。</p>]]></content>
      
      
      <categories>
          
          <category> KVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KVM 虚拟化原理3--CPU</title>
      <link href="/2018/12/10/kvm-cpu/"/>
      <url>/2018/12/10/kvm-cpu/</url>
      
        <content type="html"><![CDATA[<h2 id="CPU-虚拟化简介"><a href="#CPU-虚拟化简介" class="headerlink" title="CPU 虚拟化简介"></a>CPU 虚拟化简介</h2><p>上一篇文章笼统的介绍了一个虚拟机的诞生过程，从demo中也可以看到，运行一个虚拟机再也不需要像以前想象的那样，需要用软件来模拟硬件指令集了。虚拟机的指令集直接运行在宿主机物理CPU上，当虚拟机中的指令设计到IO操作或者一些特殊指令的时候，控制权转让给了宿主机（这里其实是转让给了vm monitor，下面检查VMM），也就是一个demo进程，他在宿主机上的表现形式也就是一个用户级进程。</p><p>用一张图来解释更为贴切。</p><p><img src="/2018/12/10/kvm-cpu/vcpu-follow.png" alt=""></p><p>VMM完成vCPU，内存的初始化后，通过ioctl调用KVM的接口，完成虚拟机的创建，并创建一个线程来运行VM，由于VM在前期初始化的时候会设置各种寄存器来帮助KVM查找到需要加载的指令的入口（main函数）。所以线程在调用了KVM接口后，物理CPU的控制权就交给了VM。VM运行在VMX non-root模式，这是Intel-V或者AMD-V提供的一种特殊的CPU执行模式。然后当VM执行了特殊指令的时候，CPU将当前VM的上下文保存到VMCS寄存器（这个寄存器是一个指针，保存了实际的上下文地址），然后执行权切换到VMM。VMM 获取 VM 返回原因，并做处理。如果是IO请求，VMM 可以直接读取VM的内存并将IO操作模拟出来，然后再调用VMRESUME指令，VM继续执行，此时在VM看来，IO操作的指令被CPU执行了。</p><h2 id="Intel-V-技术"><a href="#Intel-V-技术" class="headerlink" title="Intel-V 技术"></a>Intel-V 技术</h2><p>Intel-V 技术是Intel为了支持虚拟化而提供的一套CPU特殊运行模式。</p><h3 id="Intel-V虚拟化技术结构"><a href="#Intel-V虚拟化技术结构" class="headerlink" title="Intel-V虚拟化技术结构"></a>Intel-V虚拟化技术结构</h3><p>Intel-V 在IA-32处理器上扩展了处理器等级，原来的CPU支持ring0~ring3 4个等级，但是Linux只使用了其中的两个ring0,ring3。当CPU寄存器标示了当前CPU处于ring0级别的时候，表示此时CPU正在运行的是内核的代码。而当CPU处于ring3级别的时候，表示此时CPU正在运行的是用户级别的代码。当发生系统调用或者进程切换的时候，CPU会从ring3级别转到ring0级别。ring3级别是不允许执行硬件操作的，所有硬件操作都需要系统提供的API来完成。<br>比如说一个IO操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int nread = read(fd, buffer, 1024);</span><br></pre></td></tr></table></figure><p>当执行到此段代码的时候，然后查找到系统调用号，保存到寄存器eax，然后会将对应的参数压栈后产生一个系统调用中断，对应的是 int $0x80。产生了系统调用中断后，此时CPU将切换到ring0模式，内核通过寄存器读取到参数，并完成最后的IO后续操作，操作完成后返回ring3模式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">movel　　$3,%eax</span><br><span class="line">movel　　fd,%ebx</span><br><span class="line">movel　　buffer,%ecx</span><br><span class="line">movel　　1024,%edx　　　　　　</span><br><span class="line">int　　  $0x80</span><br></pre></td></tr></table></figure><p>Intel-V 在 ring0~ring3 的基础上，增加了VMX模式，VMX分为root和non-root。这里的VMX root模式是给VMM（前面有提到VM monitor)，在KVM体系中，就是qemu-kvm进程所运行的模式。VMX non-root模式就是运行的Guest，Guest也分ring0~ring3，不过他并不感知自己处于VMX non-root模式下。</p><p><img src="/2018/12/10/kvm-cpu/vcpu-ring.png" alt=""></p><p>Intel的虚拟架构基本上分两个部分:</p><ul><li>虚拟机监视器</li><li>客户机（Guest VM)</li></ul><h4 id="虚拟机监视器（Virtual-machine-monitors-VMM"><a href="#虚拟机监视器（Virtual-machine-monitors-VMM" class="headerlink" title="虚拟机监视器（Virtual-machine monitors - VMM)"></a>虚拟机监视器（Virtual-machine monitors - VMM)</h4><p>虚拟机监视器在宿主机上表现为一个提供虚拟机CPU，内存以及一系列硬件虚拟的实体，这个实体在KVM体系中就是一个进程，如qemu-kvm。VMM负责管理虚拟机的资源，并拥有所有虚拟机资源的控制权，包括切换虚拟机的CPU上下文等。</p><h4 id="Guest"><a href="#Guest" class="headerlink" title="Guest"></a>Guest</h4><p>这个Guest在前面的Demo里面也提到，可能是一个操作系统（OS），也可能就是一个二进制程序，whatever，对于VMM来说，他就是一堆指令集，只需要知道入口（rip寄存器值）就可以加载。<br>Guest运行需要虚拟CPU，当Guest代码运行的时候，处于VMX non-root模式，此模式下，该用什么指令还是用什么指令，该用寄存器该用cache还是用cache，但是在执行到特殊指令的时候（比如Demo中的out指令），把CPU控制权交给VMM，由VMM来处理特殊指令，完成硬件操作。</p><h4 id="VMM-与-Guest-的切换"><a href="#VMM-与-Guest-的切换" class="headerlink" title="VMM 与 Guest 的切换"></a>VMM 与 Guest 的切换</h4><p><img src="/2018/12/10/kvm-cpu/vmm_guest_switch.png" alt=""></p><p>Guest与VMM之间的切换分两个部分：VM entry 和 VM exit。有几种情况会导致VM exit，比如说Guest执行了硬件访问操作，或者Guest调用了VMCALL指令或者调用了退出指令或者产生了一个page fault，或者访问了特殊设备的寄存器等。当Guest处于VMX模式的时候，没有提供获取是否处于此模式下的指令或者寄存器，也就是说，Guest不能判断当前CPU是否处于VMX模式。当产生VM exit的时候，CPU会将exit reason保存到MSRs（VMX模式的特殊寄存器组），对应到KVM就是vCPU-&gt;kvm_run-&gt;exit_reason。VMM根据exit_reason做相应的处理。</p><h4 id="VMM-的生命周期"><a href="#VMM-的生命周期" class="headerlink" title="VMM 的生命周期"></a>VMM 的生命周期</h4><p>如上图所示，VMM 开始于VMXON 指令，结束与VMXOFF指令。<br>第一次启动Guest，通过VMLAUNCH指令加载Guest，这时候一切都是新的，比如说起始的rip寄存器等。后续Guest exit后再entry，是通过VMRESUME指令，此指令会将VMCS(后面会介绍到）所指向的内容加载到当前Guest的上下文，以便Guest继续执行。</p><h4 id="VMCS-（Virtual-Machine-control-structure"><a href="#VMCS-（Virtual-Machine-control-structure" class="headerlink" title="VMCS （Virtual-Machine control structure)"></a>VMCS （Virtual-Machine control structure)</h4><p>顾名思义，VMCS就是虚拟机控制结构，前面提到过很多次，Guest Exit的时候，会将当前Guest的上下文保存到VMCS中，Guest entry的时候把VMCS上下文恢复到VMM。VMCS是一个64位的指针，指向一个真实的内存地址，VMCS是以vCPU为单位的，就是说当前有多少个vCPU，就有多少个VMCS指针。VMCS的操作包括VMREAD，VMWRITE，VMCLEAR。</p><h4 id="Guest-exit-Reason"><a href="#Guest-exit-Reason" class="headerlink" title="Guest exit Reason"></a>Guest exit Reason</h4><p>下面是qemu-kvm定义的exit reason。可以看到有很多可能会导致Guest转让控制权。选取几个解释一下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">static int (*const kvm_vmx_exit_handlers[])(struct kvm_vcpu *vcpu) = &#123;</span><br><span class="line">    [EXIT_REASON_EXCEPTION_NMI]           = handle_exception, </span><br><span class="line">    [EXIT_REASON_EXTERNAL_INTERRUPT]      = handle_external_interrupt, </span><br><span class="line">    [EXIT_REASON_TRIPLE_FAULT]            = handle_triple_fault,</span><br><span class="line">    [EXIT_REASON_NMI_WINDOW]              = handle_nmi_window,</span><br><span class="line">     // 访问了IO设备</span><br><span class="line">    [EXIT_REASON_IO_INSTRUCTION]          = handle_io,</span><br><span class="line">     // 访问了CR寄存器，地址寄存器，和DR寄存器（debug register)一样，用于调试</span><br><span class="line">    [EXIT_REASON_CR_ACCESS]               = handle_cr,</span><br><span class="line">    [EXIT_REASON_DR_ACCESS]               = handle_dr, </span><br><span class="line">    [EXIT_REASON_CPUID]                   = handle_cpuid,</span><br><span class="line">    // 访问了MSR寄存器</span><br><span class="line">    [EXIT_REASON_MSR_READ]                = handle_rdmsr,</span><br><span class="line">    [EXIT_REASON_MSR_WRITE]               = handle_wrmsr,</span><br><span class="line">    [EXIT_REASON_PENDING_INTERRUPT]       = handle_interrupt_window,</span><br><span class="line">    // Guest执行了HLT指令，Demo开胃菜就是这个指令</span><br><span class="line">    [EXIT_REASON_HLT]                     = handle_halt,</span><br><span class="line">    [EXIT_REASON_INVD]                    = handle_invd,</span><br><span class="line">    [EXIT_REASON_INVLPG]                  = handle_invlpg,</span><br><span class="line">    [EXIT_REASON_RDPMC]                   = handle_rdpmc,</span><br><span class="line">    // 不太清楚以下VM系列的指令有什么用，猜测是递归VM（虚拟机里面运行虚拟机）</span><br><span class="line">    [EXIT_REASON_VMCALL]                  = handle_vmcall, </span><br><span class="line">    [EXIT_REASON_VMCLEAR]                 = handle_vmclear,</span><br><span class="line">    [EXIT_REASON_VMLAUNCH]                = handle_vmlaunch,</span><br><span class="line">    [EXIT_REASON_VMPTRLD]                 = handle_vmptrld,</span><br><span class="line">    [EXIT_REASON_VMPTRST]                 = handle_vmptrst,</span><br><span class="line">    [EXIT_REASON_VMREAD]                  = handle_vmread,</span><br><span class="line">    [EXIT_REASON_VMRESUME]                = handle_vmresume,</span><br><span class="line">    [EXIT_REASON_VMWRITE]                 = handle_vmwrite,</span><br><span class="line">    [EXIT_REASON_VMOFF]                   = handle_vmoff,</span><br><span class="line">    [EXIT_REASON_VMON]                    = handle_vmon,</span><br><span class="line"></span><br><span class="line">    [EXIT_REASON_TPR_BELOW_THRESHOLD]     = handle_tpr_below_threshold,</span><br><span class="line">    // 访问了高级PCI设备</span><br><span class="line">    [EXIT_REASON_APIC_ACCESS]             = handle_apic_access,</span><br><span class="line">    [EXIT_REASON_APIC_WRITE]              = handle_apic_write,</span><br><span class="line">    [EXIT_REASON_EOI_INDUCED]             = handle_apic_eoi_induced,</span><br><span class="line">    [EXIT_REASON_WBINVD]                  = handle_wbinvd,</span><br><span class="line">    [EXIT_REASON_XSETBV]                  = handle_xsetbv,</span><br><span class="line">    // 进程切换</span><br><span class="line">    [EXIT_REASON_TASK_SWITCH]             = handle_task_switch,</span><br><span class="line">    [EXIT_REASON_MCE_DURING_VMENTRY]      = handle_machine_check,</span><br><span class="line">    // ept 是Intel的一个硬件内存虚拟化技术</span><br><span class="line">    [EXIT_REASON_EPT_VIOLATION]           = handle_ept_violation,</span><br><span class="line">    [EXIT_REASON_EPT_MISCONFIG]           = handle_ept_misconfig,</span><br><span class="line">    // 执行了暂停指令</span><br><span class="line">    [EXIT_REASON_PAUSE_INSTRUCTION]       = handle_pause,</span><br><span class="line">    [EXIT_REASON_MWAIT_INSTRUCTION]       = handle_invalid_op,</span><br><span class="line">    [EXIT_REASON_MONITOR_INSTRUCTION]     = handle_invalid_op,</span><br><span class="line">    [EXIT_REASON_INVEPT]                  = handle_invept,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>KVM的CPU虚拟化依托于Intel-V提供的虚拟化技术，将Guest运行于VMX模式，当执行了特殊操作的时候，将控制权返回给VMM。VMM处理完特殊操作后再把结果返回给Guest。<br>CPU虚拟化可以说是KVM的最关键的核心，弄清楚了VM Exit和VM Entry。后续的IO虚拟化，内存虚拟化都是建立在此基础上。下一章介绍内存虚拟化。</p>]]></content>
      
      
      <categories>
          
          <category> KVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KVM 虚拟化原理2— QEMU启动过程</title>
      <link href="/2018/12/10/kvm-boot/"/>
      <url>/2018/12/10/kvm-boot/</url>
      
        <content type="html"><![CDATA[<h2 id="虚拟机启动过程"><a href="#虚拟机启动过程" class="headerlink" title="虚拟机启动过程"></a>虚拟机启动过程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">第一步，获取到kvm句柄</span><br><span class="line">kvmfd = open(&quot;/dev/kvm&quot;, O_RDWR);</span><br><span class="line"></span><br><span class="line">第二步，创建虚拟机，获取到虚拟机句柄。</span><br><span class="line">vmfd = ioctl(kvmfd, KVM_CREATE_VM, 0);</span><br><span class="line"></span><br><span class="line">第三步，为虚拟机映射内存，还有其他的PCI，信号处理的初始化。</span><br><span class="line">ioctl(vmfd, KVM_SET_USER_MEMORY_REGION, &amp;mem);</span><br><span class="line"></span><br><span class="line">第四步，创建vCPU</span><br><span class="line">vcpufd = ioctl(vmfd, KVM_CREATE_VCPU, vcpuio)</span><br><span class="line"></span><br><span class="line">第五步，为vCPU分配内存</span><br><span class="line">vcpu_size=ioctl(kvmfd, KVM_GET_VCPU_MMAP_SIZE, NULL)</span><br><span class="line">run = (struct kvm_run*)mmap(NULL, mmap_size, PROT_READ|PROT_WRITE, MAP_SHARED, vcpufd, 0)</span><br><span class="line"></span><br><span class="line">第六步，创建vCPU个数的线程并运行虚拟机。</span><br><span class="line">ioctl(vcpufd, KVM_RUN, 0);</span><br><span class="line">将汇编代码加载到用户内存中，并且设置vCPU的寄存器，例如RIP</span><br><span class="line"></span><br><span class="line">第七步，线程进入循环，并捕获虚拟机退出原因，做相应的处理。</span><br><span class="line">while(1) &#123; ioctl(kvm-&gt;vcpus-&gt;vcpu_fd, KVM_RUN, 0); &#125;;</span><br><span class="line">这里的退出并不一定是虚拟机关机，虚拟机如果遇到IO操作，访问硬件设备，缺页中断等都会退出执行，退出执行可以理解为将CPU执行上下文返回到QEMU。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">open(&quot;/dev/kvm&quot;)</span><br><span class="line">ioctl(KVM_CREATE_VM)</span><br><span class="line">ioctl(KVM_CREATE_VCPU)</span><br><span class="line">for (;;) &#123;</span><br><span class="line">     ioctl(KVM_RUN)</span><br><span class="line">     switch (exit_reason) &#123;</span><br><span class="line">     case KVM_EXIT_IO:  /* ... */</span><br><span class="line">     case KVM_EXIT_HLT: /* ... */</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于KVM_CREATE_VM参数的描述，创建的VM是没有cpu和内存的，需要QEMU进程利用mmap系统调用映射一块内存给VM的描述符，其实也就是给VM创建内存的过程。</p><p><a href="https://github.com/torvalds/linux/blob/master/Documentation/virtual/kvm/api.txt" target="_blank" rel="noopener">KVM ioctl接口文档</a></p><h2 id="先来一个KVM-API开胃菜"><a href="#先来一个KVM-API开胃菜" class="headerlink" title="先来一个KVM API开胃菜"></a>先来一个KVM API开胃菜</h2><p>下面是一个KVM的简单demo，其目的在于加载 code 并使用KVM运行起来.<br>这是一个at&amp;t的8086汇编，.code16表示他是一个16位的，当然直接运行是运行不起来的，为了让他运行起来，我们可以用KVM提供的API，将这个程序看做一个最简单的操作系统，让其运行起来。<br>这个汇编的作用是输出al寄存器的值到0x3f8端口。对于x86架构来说，通过IN/OUT指令访问。PC架构一共有65536个8bit的I/O端口，组成64KI/O地址空间，编号从0~0xFFFF。连续两个8bit的端口可以组成一个16bit的端口，连续4个组成一个32bit的端口。I/O地址空间和CPU的物理地址空间是两个不同的概念，例如I/O地址空间为64K，一个32bit的CPU物理地址空间是4G。<br>最终程序理想的输出应该是，al，bl的值后面KVM初始化的时候有赋值。<br>4\n (并不直接输出\n，而是换了一行），hlt 指令表示虚拟机退出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">.globl _start</span><br><span class="line">    .code16</span><br><span class="line">_start:</span><br><span class="line">    mov $0x3f8, %dx</span><br><span class="line">    add %bl, %al</span><br><span class="line">    add $&apos;0&apos;, %al</span><br><span class="line">    out %al, (%dx)</span><br><span class="line">    mov $&apos;\n&apos;, %al</span><br><span class="line">    out %al, (%dx)</span><br><span class="line">    hlt</span><br></pre></td></tr></table></figure><p>我们编译一下这个汇编，得到一个 Bin.bin 的二进制文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">as -32 bin.S -o bin.o</span><br><span class="line">ld -m elf_i386 --oformat binary -N -e _start -Ttext 0x10000 -o Bin.bin bin.o</span><br></pre></td></tr></table></figure><p>查看一下二进制格式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜  demo1 hexdump -C bin.bin</span><br><span class="line">00000000  ba f8 03 00 d8 04 30 ee  b0 0a ee f4              |......0.....|</span><br><span class="line">0000000c</span><br><span class="line">对应了下面的code数组，这样直接加载字节码就不需要再从文件加载了</span><br><span class="line">    const uint8_t code[] = &#123;</span><br><span class="line">        0xba, 0xf8, 0x03, /* mov $0x3f8, %dx */</span><br><span class="line">        0x00, 0xd8,       /* add %bl, %al */</span><br><span class="line">        0x04, &apos;0&apos;,        /* add $&apos;0&apos;, %al */</span><br><span class="line">        0xee,             /* out %al, (%dx) */</span><br><span class="line">        0xb0, &apos;\n&apos;,       /* mov $&apos;\n&apos;, %al */</span><br><span class="line">        0xee,             /* out %al, (%dx) */</span><br><span class="line">        0xf4,             /* hlt */</span><br><span class="line">    &#125;;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;err.h&gt;</span><br><span class="line">#include &lt;fcntl.h&gt;</span><br><span class="line">#include &lt;linux/kvm.h&gt;</span><br><span class="line">#include &lt;stdint.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;string.h&gt;</span><br><span class="line">#include &lt;sys/ioctl.h&gt;</span><br><span class="line">#include &lt;sys/mman.h&gt;</span><br><span class="line">#include &lt;sys/stat.h&gt;</span><br><span class="line">#include &lt;sys/types.h&gt;</span><br><span class="line"></span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">    int kvm, vmfd, vcpufd, ret;</span><br><span class="line">    const uint8_t code[] = &#123;</span><br><span class="line">        0xba, 0xf8, 0x03, /* mov $0x3f8, %dx */</span><br><span class="line">        0x00, 0xd8,       /* add %bl, %al */</span><br><span class="line">        0x04, &apos;0&apos;,        /* add $&apos;0&apos;, %al */</span><br><span class="line">        0xee,             /* out %al, (%dx) */</span><br><span class="line">        0xb0, &apos;\n&apos;,       /* mov $&apos;\n&apos;, %al */</span><br><span class="line">        0xee,             /* out %al, (%dx) */</span><br><span class="line">        0xf4,             /* hlt */</span><br><span class="line">    &#125;;</span><br><span class="line">    uint8_t *mem;</span><br><span class="line">    struct kvm_sregs sregs;</span><br><span class="line">    size_t mmap_size;</span><br><span class="line">    struct kvm_run *run;</span><br><span class="line"></span><br><span class="line">    // 获取 kvm 句柄 第一步</span><br><span class="line">    kvm = open(&quot;/dev/kvm&quot;, O_RDWR | O_CLOEXEC);</span><br><span class="line">    if (kvm == -1)</span><br><span class="line">        err(1, &quot;/dev/kvm&quot;);</span><br><span class="line"></span><br><span class="line">    // 确保是正确的 API 版本</span><br><span class="line">    ret = ioctl(kvm, KVM_GET_API_VERSION, NULL);</span><br><span class="line">    if (ret == -1)</span><br><span class="line">        err(1, &quot;KVM_GET_API_VERSION&quot;);</span><br><span class="line">    if (ret != 12)</span><br><span class="line">        errx(1, &quot;KVM_GET_API_VERSION %d, expected 12&quot;, ret);</span><br><span class="line"></span><br><span class="line">    // 创建一虚拟机 第二步</span><br><span class="line">    vmfd = ioctl(kvm, KVM_CREATE_VM, (unsigned long)0);</span><br><span class="line">    if (vmfd == -1)</span><br><span class="line">        err(1, &quot;KVM_CREATE_VM&quot;);</span><br><span class="line"></span><br><span class="line">    // 为这个虚拟机申请内存，并将代码（镜像）加载到虚拟机内存中</span><br><span class="line">    mem = mmap(NULL, 0x1000, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0);</span><br><span class="line">    if (!mem)</span><br><span class="line">        err(1, &quot;allocating guest memory&quot;);</span><br><span class="line">    memcpy(mem, code, sizeof(code));</span><br><span class="line"></span><br><span class="line">    // 为什么从 0x1000 开始呢，因为页表空间的前4K是留给页表目录</span><br><span class="line">    struct kvm_userspace_memory_region region = &#123;</span><br><span class="line">        .slot = 0,</span><br><span class="line">        .guest_phys_addr = 0x1000,</span><br><span class="line">        .memory_size = 0x1000,</span><br><span class="line">        .userspace_addr = (uint64_t)mem,</span><br><span class="line">    &#125;;</span><br><span class="line">    // 设置 KVM 的内存区域 第三部</span><br><span class="line">    ret = ioctl(vmfd, KVM_SET_USER_MEMORY_REGION, &amp;region);</span><br><span class="line">    if (ret == -1)</span><br><span class="line">        err(1, &quot;KVM_SET_USER_MEMORY_REGION&quot;);</span><br><span class="line"></span><br><span class="line">    // 创建虚拟CPU 第四部</span><br><span class="line">    vcpufd = ioctl(vmfd, KVM_CREATE_VCPU, (unsigned long)0);</span><br><span class="line">    if (vcpufd == -1)</span><br><span class="line">        err(1, &quot;KVM_CREATE_VCPU&quot;);</span><br><span class="line"></span><br><span class="line">    // 获取 KVM 运行时结构的大小</span><br><span class="line">    ret = ioctl(kvm, KVM_GET_VCPU_MMAP_SIZE, NULL);</span><br><span class="line">    if (ret == -1)</span><br><span class="line">        err(1, &quot;KVM_GET_VCPU_MMAP_SIZE&quot;);</span><br><span class="line">    mmap_size = ret;</span><br><span class="line">    if (mmap_size &lt; sizeof(*run))</span><br><span class="line">        errx(1, &quot;KVM_GET_VCPU_MMAP_SIZE unexpectedly small&quot;);</span><br><span class="line">    // 将 kvm run 与 vcpu 做关联，这样能够获取到kvm的运行时信息 第五步</span><br><span class="line">    run = mmap(NULL, mmap_size, PROT_READ | PROT_WRITE, MAP_SHARED, vcpufd, 0);</span><br><span class="line">    if (!run)</span><br><span class="line">        err(1, &quot;mmap vcpu&quot;);</span><br><span class="line"></span><br><span class="line">    // 获取特殊寄存器  第六步</span><br><span class="line">    ret = ioctl(vcpufd, KVM_GET_SREGS, &amp;sregs);</span><br><span class="line">    if (ret == -1)</span><br><span class="line">        err(1, &quot;KVM_GET_SREGS&quot;);</span><br><span class="line">    // 设置代码段为从地址0处开始，我们的代码被加载到了0x0000的起始位置</span><br><span class="line">    sregs.cs.base = 0;</span><br><span class="line">    sregs.cs.selector = 0;</span><br><span class="line">    // KVM_SET_SREGS 设置特殊寄存器</span><br><span class="line">    ret = ioctl(vcpufd, KVM_SET_SREGS, &amp;sregs);</span><br><span class="line">    if (ret == -1)</span><br><span class="line">        err(1, &quot;KVM_SET_SREGS&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    // 设置代码的入口地址，相当于32位main函数的地址，这里16位汇编都是由0x1000处开始。</span><br><span class="line">    // 如果是正式的镜像，那么rip的值应该是类似引导扇区加载进来的指令</span><br><span class="line">    struct kvm_regs regs = &#123;</span><br><span class="line">        .rip = 0x1000,</span><br><span class="line">        .rax = 2,    // 设置 ax 寄存器初始值为 2</span><br><span class="line">        .rbx = 2,    // 同理</span><br><span class="line">        .rflags = 0x2,   // 初始化flags寄存器，x86架构下需要设置，否则会粗错</span><br><span class="line">    &#125;;</span><br><span class="line">    ret = ioctl(vcpufd, KVM_SET_REGS, &amp;regs);</span><br><span class="line">    if (ret == -1)</span><br><span class="line">        err(1, &quot;KVM_SET_REGS&quot;);</span><br><span class="line"></span><br><span class="line">    // 开始运行虚拟机，如果是qemu-kvm，会用一个线程来执行这个vCPU，并加载指令 第七步</span><br><span class="line">    while (1) &#123;</span><br><span class="line">        // 开始运行虚拟机</span><br><span class="line">        ret = ioctl(vcpufd, KVM_RUN, NULL);</span><br><span class="line">        if (ret == -1)</span><br><span class="line">            err(1, &quot;KVM_RUN&quot;);</span><br><span class="line">        // 获取虚拟机退出原因</span><br><span class="line">        switch (run-&gt;exit_reason) &#123;</span><br><span class="line">        case KVM_EXIT_HLT:</span><br><span class="line">            puts(&quot;KVM_EXIT_HLT&quot;);</span><br><span class="line">            return 0;</span><br><span class="line">        // 汇编调用了 out 指令，vmx 模式下不允许执行这个操作，所以</span><br><span class="line">        // 将操作权切换到了宿主机，切换的时候会将上下文保存到VMCS寄存器</span><br><span class="line">        // 后面CPU虚拟化会讲到这部分</span><br><span class="line">        // 因为虚拟机的内存宿主机能够直接读取到，所以直接在宿主机上获取到</span><br><span class="line">        // 虚拟机的输出（out指令），这也是后面PCI设备虚拟化的一个基础，DMA模式的PCI设备</span><br><span class="line">        case KVM_EXIT_IO:</span><br><span class="line">            if (run-&gt;io.direction == KVM_EXIT_IO_OUT &amp;&amp; run-&gt;io.size == 1 &amp;&amp; run-&gt;io.port == 0x3f8 &amp;&amp; run-&gt;io.count == 1)</span><br><span class="line">                putchar(*(((char *)run) + run-&gt;io.data_offset));</span><br><span class="line">            else</span><br><span class="line">                errx(1, &quot;unhandled KVM_EXIT_IO&quot;);</span><br><span class="line">            break;</span><br><span class="line">        case KVM_EXIT_FAIL_ENTRY:</span><br><span class="line">            errx(1, &quot;KVM_EXIT_FAIL_ENTRY: hardware_entry_failure_reason = 0x%llx&quot;,</span><br><span class="line">                 (unsigned long long)run-&gt;fail_entry.hardware_entry_failure_reason);</span><br><span class="line">        case KVM_EXIT_INTERNAL_ERROR:</span><br><span class="line">            errx(1, &quot;KVM_EXIT_INTERNAL_ERROR: suberror = 0x%x&quot;, run-&gt;internal.suberror);</span><br><span class="line">        default:</span><br><span class="line">            errx(1, &quot;exit_reason = 0x%x&quot;, run-&gt;exit_reason);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译并运行这个demo</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gcc -g demo.c -o demo</span><br><span class="line">➜  demo1 ./demo</span><br><span class="line">4</span><br><span class="line">KVM_EXIT_HLT</span><br></pre></td></tr></table></figure><h2 id="另外一个简单的QEMU-emulator-demo"><a href="#另外一个简单的QEMU-emulator-demo" class="headerlink" title="另外一个简单的QEMU emulator demo"></a>另外一个简单的QEMU emulator demo</h2><p><a href="http://soulxu.github.io/blog/2014/08/11/use-kvm-api-write-emulator/" target="_blank" rel="noopener">IBM的徐同学有做过介绍</a>，在此基础上我再详细介绍一下qemu-kvm的启动过程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">.globl _start</span><br><span class="line">    .code16</span><br><span class="line">_start:</span><br><span class="line">    xorw %ax, %ax   # 将 ax 寄存器清零</span><br><span class="line"></span><br><span class="line">loop1:</span><br><span class="line">    out %ax, $0x10  # 像 0x10 的端口输出 ax 的内容，at&amp;t汇编的操作数和Intel的相反。</span><br><span class="line">    inc %ax         # ax 值加一</span><br><span class="line">    jmp loop1       # 继续循环</span><br></pre></td></tr></table></figure><p>这个汇编的作用就是一直不停的向0x10端口输出一字节的值。</p><p>从main函数开始说起</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">int main(int argc, char **argv) &#123;</span><br><span class="line">    int ret = 0;</span><br><span class="line">    // 初始化kvm结构体</span><br><span class="line">    struct kvm *kvm = kvm_init();</span><br><span class="line"></span><br><span class="line">    if (kvm == NULL) &#123;</span><br><span class="line">        fprintf(stderr, &quot;kvm init fauilt\n&quot;);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 创建VM，并分配内存空间</span><br><span class="line">    if (kvm_create_vm(kvm, RAM_SIZE) &lt; 0) &#123;</span><br><span class="line">        fprintf(stderr, &quot;create vm fault\n&quot;);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 加载镜像</span><br><span class="line">    load_binary(kvm);</span><br><span class="line"></span><br><span class="line">    // only support one vcpu now</span><br><span class="line">    kvm-&gt;vcpu_number = 1;</span><br><span class="line">    // 创建执行现场</span><br><span class="line">    kvm-&gt;vcpus = kvm_init_vcpu(kvm, 0, kvm_cpu_thread);</span><br><span class="line"></span><br><span class="line">    // 启动虚拟机</span><br><span class="line">    kvm_run_vm(kvm);</span><br><span class="line"></span><br><span class="line">    kvm_clean_vm(kvm);</span><br><span class="line">    kvm_clean_vcpu(kvm-&gt;vcpus);</span><br><span class="line">    kvm_clean(kvm);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一步，调用kvm_init() 初始化了 kvm 结构体。先来看看怎么定义一个简单的kvm。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">struct kvm &#123;</span><br><span class="line">   int dev_fd;              // /dev/kvm 的句柄</span><br><span class="line">   int vm_fd;               // GUEST 的句柄</span><br><span class="line">   __u64 ram_size;          // GUEST 的内存大小</span><br><span class="line">   __u64 ram_start;         // GUEST 的内存起始地址，</span><br><span class="line">                            // 这个地址是qemu emulator通过mmap映射的地址</span><br><span class="line"></span><br><span class="line">   int kvm_version;         </span><br><span class="line">   struct kvm_userspace_memory_region mem; // slot 内存结构，由用户空间填充、</span><br><span class="line">                                           // 允许对guest的地址做分段。将多个slot组成线性地址</span><br><span class="line"></span><br><span class="line">   struct vcpu *vcpus;      // vcpu 数组</span><br><span class="line">   int vcpu_number;         // vcpu 个数</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>初始化 kvm 结构体。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">struct kvm *kvm_init(void) &#123;</span><br><span class="line">    struct kvm *kvm = malloc(sizeof(struct kvm));</span><br><span class="line">    kvm-&gt;dev_fd = open(KVM_DEVICE, O_RDWR);  // 打开 /dev/kvm 获取 kvm 句柄</span><br><span class="line"></span><br><span class="line">    if (kvm-&gt;dev_fd &lt; 0) &#123;</span><br><span class="line">        perror(&quot;open kvm device fault: &quot;);</span><br><span class="line">        return NULL;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    kvm-&gt;kvm_version = ioctl(kvm-&gt;dev_fd, KVM_GET_API_VERSION, 0);  // 获取 kvm API 版本</span><br><span class="line"></span><br><span class="line">    return kvm;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第二步+第三步，创建虚拟机，获取到虚拟机句柄，并为其分配内存。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">int kvm_create_vm(struct kvm *kvm, int ram_size) &#123;</span><br><span class="line">    int ret = 0;</span><br><span class="line">    // 调用 KVM_CREATE_KVM 接口获取 vm 句柄</span><br><span class="line">    kvm-&gt;vm_fd = ioctl(kvm-&gt;dev_fd, KVM_CREATE_VM, 0);</span><br><span class="line"></span><br><span class="line">    if (kvm-&gt;vm_fd &lt; 0) &#123;</span><br><span class="line">        perror(&quot;can not create vm&quot;);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 为 kvm 分配内存。通过系统调用.</span><br><span class="line">    kvm-&gt;ram_size = ram_size;</span><br><span class="line">    kvm-&gt;ram_start =  (__u64)mmap(NULL, kvm-&gt;ram_size, </span><br><span class="line">                PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_NORESERVE, </span><br><span class="line">                -1, 0);</span><br><span class="line"></span><br><span class="line">    if ((void *)kvm-&gt;ram_start == MAP_FAILED) &#123;</span><br><span class="line">        perror(&quot;can not mmap ram&quot;);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // kvm-&gt;mem 结构需要初始化后传递给 KVM_SET_USER_MEMORY_REGION 接口</span><br><span class="line">    // 只有一个内存槽</span><br><span class="line">    kvm-&gt;mem.slot = 0;</span><br><span class="line">    // guest 物理内存起始地址</span><br><span class="line">    kvm-&gt;mem.guest_phys_addr = 0;</span><br><span class="line">    // 虚拟机内存大小</span><br><span class="line">    kvm-&gt;mem.memory_size = kvm-&gt;ram_size;</span><br><span class="line">    // 虚拟机内存在host上的用户空间地址，这里就是绑定内存给guest</span><br><span class="line">    kvm-&gt;mem.userspace_addr = kvm-&gt;ram_start;</span><br><span class="line"></span><br><span class="line">    // 调用 KVM_SET_USER_MEMORY_REGION 为虚拟机分配内存。</span><br><span class="line">    ret = ioctl(kvm-&gt;vm_fd, KVM_SET_USER_MEMORY_REGION, &amp;(kvm-&gt;mem));</span><br><span class="line"></span><br><span class="line">    if (ret &lt; 0) &#123;</span><br><span class="line">        perror(&quot;can not set user memory region&quot;);</span><br><span class="line">        return ret;</span><br><span class="line">    &#125;</span><br><span class="line">    return ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来就是load_binary把二进制文件load到虚拟机的内存中来，在第一个demo中我们是直接把字节码放到了内存中，这里模拟镜像加载步骤，把二进制文件加载到内存中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">void load_binary(struct kvm *kvm) &#123;</span><br><span class="line">    int fd = open(BINARY_FILE, O_RDONLY);  // 打开这个二进制文件(镜像）</span><br><span class="line"></span><br><span class="line">    if (fd &lt; 0) &#123;</span><br><span class="line">        fprintf(stderr, &quot;can not open binary file\n&quot;);</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int ret = 0;</span><br><span class="line">    char *p = (char *)kvm-&gt;ram_start;</span><br><span class="line"></span><br><span class="line">    while(1) &#123;</span><br><span class="line">        ret = read(fd, p, 4096);           // 将镜像内容加载到虚拟机的内存中</span><br><span class="line">        if (ret &lt;= 0) &#123;</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line">        printf(&quot;read size: %d&quot;, ret);</span><br><span class="line">        p += ret;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>加载完镜像后，需要初始化vCPU，以便能够运行镜像内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">struct vcpu &#123;</span><br><span class="line">    int vcpu_id;                 // vCPU id，vCPU</span><br><span class="line">    int vcpu_fd;                 // vCPU 句柄</span><br><span class="line">    pthread_t vcpu_thread;       // vCPU 线程句柄</span><br><span class="line">    struct kvm_run *kvm_run;     // KVM 运行时结构，也可以看做是上下文</span><br><span class="line">    int kvm_run_mmap_size;       // 运行时结构大小</span><br><span class="line">    struct kvm_regs regs;        // vCPU的寄存器</span><br><span class="line">    struct kvm_sregs sregs;      // vCPU的特殊寄存器</span><br><span class="line">    void *(*vcpu_thread_func)(void *);  // 线程执行函数</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">struct vcpu *kvm_init_vcpu(struct kvm *kvm, int vcpu_id, void *(*fn)(void *)) &#123;</span><br><span class="line">    // 申请vcpu结构</span><br><span class="line">    struct vcpu *vcpu = malloc(sizeof(struct vcpu));</span><br><span class="line">    // 只有一个 vCPU，所以这里只初始化一个</span><br><span class="line">    vcpu-&gt;vcpu_id = 0;</span><br><span class="line">    // 调用 KVM_CREATE_VCPU 获取 vCPU 句柄，并关联到kvm-&gt;vm_fd（由KVM_CREATE_VM返回）</span><br><span class="line">    vcpu-&gt;vcpu_fd = ioctl(kvm-&gt;vm_fd, KVM_CREATE_VCPU, vcpu-&gt;vcpu_id);</span><br><span class="line"></span><br><span class="line">    if (vcpu-&gt;vcpu_fd &lt; 0) &#123;</span><br><span class="line">        perror(&quot;can not create vcpu&quot;);</span><br><span class="line">        return NULL;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 获取KVM运行时结构大小</span><br><span class="line">    vcpu-&gt;kvm_run_mmap_size = ioctl(kvm-&gt;dev_fd, KVM_GET_VCPU_MMAP_SIZE, 0);</span><br><span class="line"></span><br><span class="line">    if (vcpu-&gt;kvm_run_mmap_size &lt; 0) &#123;</span><br><span class="line">        perror(&quot;can not get vcpu mmsize&quot;);</span><br><span class="line">        return NULL;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    printf(&quot;%d\n&quot;, vcpu-&gt;kvm_run_mmap_size);</span><br><span class="line">    // 将 vcpu_fd 的内存映射给 vcpu-&gt;kvm_run结构。相当于一个关联操作</span><br><span class="line">    // 以便能够在虚拟机退出的时候获取到vCPU的返回值等信息</span><br><span class="line">    vcpu-&gt;kvm_run = mmap(NULL, vcpu-&gt;kvm_run_mmap_size, PROT_READ | PROT_WRITE, MAP_SHARED, vcpu-&gt;vcpu_fd, 0);</span><br><span class="line"></span><br><span class="line">    if (vcpu-&gt;kvm_run == MAP_FAILED) &#123;</span><br><span class="line">        perror(&quot;can not mmap kvm_run&quot;);</span><br><span class="line">        return NULL;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 设置线程执行函数</span><br><span class="line">    vcpu-&gt;vcpu_thread_func = fn;</span><br><span class="line">    return vcpu;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后一步，以上工作就绪后，启动虚拟机。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void kvm_run_vm(struct kvm *kvm) &#123;</span><br><span class="line">    int i = 0;</span><br><span class="line"></span><br><span class="line">    for (i = 0; i &lt; kvm-&gt;vcpu_number; i++) &#123;</span><br><span class="line">        // 启动线程执行 vcpu_thread_func 并将 kvm 结构作为参数传递给线程</span><br><span class="line">        if (pthread_create(&amp;(kvm-&gt;vcpus-&gt;vcpu_thread), (const pthread_attr_t *)NULL, kvm-&gt;vcpus[i].vcpu_thread_func, kvm) != 0) &#123;</span><br><span class="line">            perror(&quot;can not create kvm thread&quot;);</span><br><span class="line">            exit(1);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    pthread_join(kvm-&gt;vcpus-&gt;vcpu_thread, NULL);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动虚拟机其实就是创建线程，并执行相应的线程回调函数。<br>线程回调函数在kvm_init_vcpu的时候传入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line">void *kvm_cpu_thread(void *data) &#123;</span><br><span class="line">    // 获取参数</span><br><span class="line">    struct kvm *kvm = (struct kvm *)data;</span><br><span class="line">    int ret = 0;</span><br><span class="line">    // 设置KVM的参数</span><br><span class="line">    kvm_reset_vcpu(kvm-&gt;vcpus);</span><br><span class="line"></span><br><span class="line">    while (1) &#123;</span><br><span class="line">        printf(&quot;KVM start run\n&quot;);</span><br><span class="line">        // 启动虚拟机，此时的虚拟机已经有内存和CPU了，可以运行起来了。</span><br><span class="line">        ret = ioctl(kvm-&gt;vcpus-&gt;vcpu_fd, KVM_RUN, 0);</span><br><span class="line"></span><br><span class="line">        if (ret &lt; 0) &#123;</span><br><span class="line">            fprintf(stderr, &quot;KVM_RUN failed\n&quot;);</span><br><span class="line">            exit(1);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 前文 kvm_init_vcpu 函数中，将 kvm_run 关联了 vCPU 结构的内存</span><br><span class="line">        // 所以这里虚拟机退出的时候，可以获取到 exit_reason，虚拟机退出原因</span><br><span class="line">        switch (kvm-&gt;vcpus-&gt;kvm_run-&gt;exit_reason) &#123;</span><br><span class="line">        case KVM_EXIT_UNKNOWN:</span><br><span class="line">            printf(&quot;KVM_EXIT_UNKNOWN\n&quot;);</span><br><span class="line">            break;</span><br><span class="line">        case KVM_EXIT_DEBUG:</span><br><span class="line">            printf(&quot;KVM_EXIT_DEBUG\n&quot;);</span><br><span class="line">            break;</span><br><span class="line">        // 虚拟机执行了IO操作，虚拟机模式下的CPU会暂停虚拟机并</span><br><span class="line">        // 把执行权交给emulator</span><br><span class="line">        case KVM_EXIT_IO:</span><br><span class="line">            printf(&quot;KVM_EXIT_IO\n&quot;);</span><br><span class="line">            printf(&quot;out port: %d, data: %d\n&quot;, </span><br><span class="line">                kvm-&gt;vcpus-&gt;kvm_run-&gt;io.port,  </span><br><span class="line">                *(int *)((char *)(kvm-&gt;vcpus-&gt;kvm_run) + kvm-&gt;vcpus-&gt;kvm_run-&gt;io.data_offset)</span><br><span class="line">                );</span><br><span class="line">            sleep(1);</span><br><span class="line">            break;</span><br><span class="line">        // 虚拟机执行了memory map IO操作</span><br><span class="line">        case KVM_EXIT_MMIO:</span><br><span class="line">            printf(&quot;KVM_EXIT_MMIO\n&quot;);</span><br><span class="line">            break;</span><br><span class="line">        case KVM_EXIT_INTR:</span><br><span class="line">            printf(&quot;KVM_EXIT_INTR\n&quot;);</span><br><span class="line">            break;</span><br><span class="line">        case KVM_EXIT_SHUTDOWN:</span><br><span class="line">            printf(&quot;KVM_EXIT_SHUTDOWN\n&quot;);</span><br><span class="line">            goto exit_kvm;</span><br><span class="line">            break;</span><br><span class="line">        default:</span><br><span class="line">            printf(&quot;KVM PANIC\n&quot;);</span><br><span class="line">            goto exit_kvm;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">exit_kvm:</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void kvm_reset_vcpu (struct vcpu *vcpu) &#123;</span><br><span class="line">    if (ioctl(vcpu-&gt;vcpu_fd, KVM_GET_SREGS, &amp;(vcpu-&gt;sregs)) &lt; 0) &#123;</span><br><span class="line">        perror(&quot;can not get sregs\n&quot;);</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line">    // #define CODE_START 0x1000</span><br><span class="line">    /* sregs 结构体</span><br><span class="line">        x86</span><br><span class="line">        struct kvm_sregs &#123;</span><br><span class="line">            struct kvm_segment cs, ds, es, fs, gs, ss;</span><br><span class="line">            struct kvm_segment tr, ldt;</span><br><span class="line">            struct kvm_dtable gdt, idt;</span><br><span class="line">            __u64 cr0, cr2, cr3, cr4, cr8;</span><br><span class="line">            __u64 efer;</span><br><span class="line">            __u64 apic_base;</span><br><span class="line">            __u64 interrupt_bitmap[(KVM_NR_INTERRUPTS + 63) / 64];</span><br><span class="line">        &#125;;</span><br><span class="line">    */</span><br><span class="line">    // cs 为code start寄存器，存放了程序的起始地址</span><br><span class="line">    vcpu-&gt;sregs.cs.selector = CODE_START;</span><br><span class="line">    vcpu-&gt;sregs.cs.base = CODE_START * 16;</span><br><span class="line">    // ss 为堆栈寄存器，存放了堆栈的起始位置</span><br><span class="line">    vcpu-&gt;sregs.ss.selector = CODE_START;</span><br><span class="line">    vcpu-&gt;sregs.ss.base = CODE_START * 16;</span><br><span class="line">    // ds 为数据段寄存器，存放了数据开始地址</span><br><span class="line">    vcpu-&gt;sregs.ds.selector = CODE_START;</span><br><span class="line">    vcpu-&gt;sregs.ds.base = CODE_START *16;</span><br><span class="line">    // es 为附加段寄存器</span><br><span class="line">    vcpu-&gt;sregs.es.selector = CODE_START;</span><br><span class="line">    vcpu-&gt;sregs.es.base = CODE_START * 16;</span><br><span class="line">    // fs, gs 同样为段寄存器</span><br><span class="line">    vcpu-&gt;sregs.fs.selector = CODE_START;</span><br><span class="line">    vcpu-&gt;sregs.fs.base = CODE_START * 16;</span><br><span class="line">    vcpu-&gt;sregs.gs.selector = CODE_START;</span><br><span class="line"></span><br><span class="line">    // 为vCPU设置以上寄存器的值</span><br><span class="line">    if (ioctl(vcpu-&gt;vcpu_fd, KVM_SET_SREGS, &amp;vcpu-&gt;sregs) &lt; 0) &#123;</span><br><span class="line">        perror(&quot;can not set sregs&quot;);</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 设置寄存器标志位</span><br><span class="line">    vcpu-&gt;regs.rflags = 0x0000000000000002ULL;</span><br><span class="line">    // rip 表示了程序的起始指针，地址为 0x0000000</span><br><span class="line">    // 在加载镜像的时候，我们直接将binary读取到了虚拟机的内存起始位</span><br><span class="line">    // 所以虚拟机开始的时候会直接运行binary</span><br><span class="line">    vcpu-&gt;regs.rip = 0;</span><br><span class="line">    // rsp 为堆栈顶</span><br><span class="line">    vcpu-&gt;regs.rsp = 0xffffffff;</span><br><span class="line">    // rbp 为堆栈底部</span><br><span class="line">    vcpu-&gt;regs.rbp= 0;</span><br><span class="line"></span><br><span class="line">    if (ioctl(vcpu-&gt;vcpu_fd, KVM_SET_REGS, &amp;(vcpu-&gt;regs)) &lt; 0) &#123;</span><br><span class="line">        perror(&quot;KVM SET REGS\n&quot;);</span><br><span class="line">        exit(1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行一下结果，可以看到当虚拟机执行了指令 <code>out %ax, $0x10</code> 的时候，会引起虚拟机的退出，这是CPU虚拟化里面将要介绍的特殊机制。<br>宿主机获取到虚拟机退出的原因后，获取相应的输出。这里的步骤就类似于IO虚拟化，直接读取IO模块的内存，并输出结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">➜  kvmsample git:(master) ✗ ./kvmsample</span><br><span class="line">read size: 712288</span><br><span class="line">KVM start run</span><br><span class="line">KVM_EXIT_IO</span><br><span class="line">out port: 16, data: 0</span><br><span class="line">KVM start run</span><br><span class="line">KVM_EXIT_IO</span><br><span class="line">out port: 16, data: 1</span><br><span class="line">KVM start run</span><br><span class="line">KVM_EXIT_IO</span><br><span class="line">out port: 16, data: 2</span><br><span class="line">KVM start run</span><br><span class="line">KVM_EXIT_IO</span><br><span class="line">out port: 16, data: 3</span><br><span class="line">KVM start run</span><br><span class="line">KVM_EXIT_IO</span><br><span class="line">out port: 16, data: 4</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虚拟机的启动过程基本上可以这么总结：<br>创建kvm句柄-&gt;创建vm-&gt;分配内存-&gt;加载镜像到内存-&gt;启动线程执行KVM_RUN。从这个虚拟机的demo可以看出，虚拟机的内存是由宿主机通过mmap调用映射给虚拟机的，而vCPU是宿主机的一个线程，这个线程通过设置相应的vCPU的寄存器指定了虚拟机的程序加载地址后，开始运行虚拟机的指令，当虚拟机执行了IO操作后，CPU捕获到中断并把执行权又交回给宿主机。</p><p>当然真实的qemu-kvm比这个复杂的多，包括设置很多IO设备的MMIO，设置信号处理等。</p><h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><p>本文中提到的所有源代码都可以从这里下载到，仅供大家学习交流使用<br><a href="https://github.com/ysun/kvm-cheat" target="_blank" rel="noopener">github|kvm-cheat</a></p>]]></content>
      
      
      <categories>
          
          <category> KVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KVM 虚拟化原理1 -- 概述</title>
      <link href="/2018/12/10/kvm-overview/"/>
      <url>/2018/12/10/kvm-overview/</url>
      
        <content type="html"><![CDATA[<h2 id="KVM虚拟化简介"><a href="#KVM虚拟化简介" class="headerlink" title="KVM虚拟化简介"></a>KVM虚拟化简介</h2><p>KVM 全称 kernel-based virtual machine，由Qumranet公司发起，2008年被RedHat收购。<br>KVM实现主要基于Intel-V或者AMD-V提供的虚拟化平台，利用Linux进程模拟虚拟机CPU和内存等。KVM不提供硬件虚拟化操作，其IO操作等都借助QEMU来完成。</p><p>Qemu  是纯软件实现的虚拟化模拟器，几乎可以模拟任何硬件设备，我们最熟悉的就是能够模拟一台能够独立运行操作系统的虚拟机，虚拟机认为自己和硬件打交道，但其实是和 Qemu 模拟出来的硬件打交道，Qemu 将这些指令转译给真正的硬件。</p><p>正因为 Qemu 是纯软件实现的，所有的指令都要经 Qemu 过一手，性能非常低，所以，在生产环境中，大多数的做法都是配合 KVM 来完成虚拟化工作，因为 KVM 是硬件辅助的虚拟化技术，主要负责 比较繁琐的 CPU 和内存虚拟化，而 Qemu 则负责 I/O 虚拟化，两者合作各自发挥自身的优势，相得益彰。</p><p><img src="/2018/12/10/kvm-overview/01_brief.png" alt=""></p><p>KVM有如下特点：</p><ul><li>guest作为一个普通进程运行于宿主机</li><li>guest的CPU(vCPU)作为进程的线程存在，并受到宿主机内核的调度</li></ul><h2 id="KVM整体架构"><a href="#KVM整体架构" class="headerlink" title="KVM整体架构"></a>KVM整体架构</h2><p><img src="/2018/12/10/kvm-overview/02_kvm_framework.png" alt=""></p><h3 id="虚拟CPU"><a href="#虚拟CPU" class="headerlink" title="虚拟CPU"></a>虚拟CPU</h3><p>虚拟机所有用户级别(user)的指令集，都会直接由宿主机线程执行，此线程会调用KVM的ioctl方式提供的接口加载guest的指令并在特殊的CPU模式下运行，不需要经过CPU指令集的软件模拟转换，大大的减少了虚拟化成本，这也是KVM优于其他虚拟化方式的点之一。</p><p>KVM向外提供了一个虚拟设备/dev/kvm，通过ioctl(IO设备带外管理接口）来对KVM进行操作，包括虚拟机的初始化，分配内存，指令加载等等。</p><h3 id="虚拟IO设备"><a href="#虚拟IO设备" class="headerlink" title="虚拟IO设备"></a>虚拟IO设备</h3><p>guest作为一个进程存在，当然他的内核的所有驱动等都存在，只是硬件被QEMU所模拟。guest的所有虚拟的硬件操作都会有QEMU来接管，那些由host passthrough给guest的设备除外，QEMU负责与真实的宿主机硬件打交道。</p><h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><p>guest的内存在host上由emulator提供，对emulator来说，guest访问的内存就是他的虚拟地址空间，guest上需要经过一次虚拟地址到物理地址的转换，转换到guest的物理地址其实也就是emulator的虚拟地址，emulator再次经过一次转换，转换为host的物理地址。</p><blockquote class="raw-class mindmap mindmap-lg"># 虚拟化概述## CPU虚拟化### 指令的模拟#### 陷入（利用处理器的保护机制，中断和异常）1，基于处理器保护机制出发的异常2，虚拟机主动触发的异常3，异步zhognduan##### 虚拟处理器##### 虚拟寄存器##### 上下文### 中断和异常的虚拟化### 对称对处理器技术的虚拟化（SMP）#### VMM选择第一个虚拟处理器，BSP#### 其他虚拟处理器，AP## Memory虚拟化### 物理地址从0开始### 内存地址连续## I/O虚拟化### 设备发现#### 总线类型的设备##### 总线类型不可枚举###### ISA设备###### PS/2键盘、鼠标、RTC###### 传统IDE控制器##### 总线类型可枚举、资源可配置###### PCI#### 完全模拟的设备##### Frontend / backend 模型### 访问截获#### I/O端口的访问##### I/O位图来决定#### MMIO访问##### 页表项设置为无效### 设备模拟</blockquote>]]></content>
      
      
      <categories>
          
          <category> KVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>QMP 简介</title>
      <link href="/2018/12/10/qmp-introduction/"/>
      <url>/2018/12/10/qmp-introduction/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是QMP协议"><a href="#什么是QMP协议" class="headerlink" title="什么是QMP协议"></a>什么是QMP协议</h2><p>QMP，即QEMU Machine Protocol，就是qemu虚拟机中的一种协议，是qemu的一部分。qmp是基于json格式的一整套协议，通过这套协议我们可以控制qemu虚拟机实例的整个生命周期，包括挂起、暂停、快照、查询、外设的热插拔等，以及最简单的查询，都可以通过qmp实现。 有多种方法使用qmp，这里简要介绍通过tcp和unix socket使用qmp。</p><h2 id="QMP协议有哪些特征"><a href="#QMP协议有哪些特征" class="headerlink" title="QMP协议有哪些特征"></a>QMP协议有哪些特征</h2><p>1）轻量、基于文本、指令格式易于解析，因为它是json格式的；<br>2）支持异步消息，主要指通过qmp发送给虚拟机的指令支持异步；<br>3）Capabilities Negotiation，主要指我们初次建立qmp连接时，进入了capabilities negotiation模式,这时我们不能发送任何指令，除了qmp_capabilities指令，发送了qmp_capabilitie指令，我们就退出了capabilities negotiation模式，进入了指令模式（command mode），这时我们可以发送qmp指令，如{ “execute”: “query-status” }，这样就可以查询虚拟机的状态。</p><h2 id="QMP协议有哪些模式"><a href="#QMP协议有哪些模式" class="headerlink" title="QMP协议有哪些模式"></a>QMP协议有哪些模式</h2><p> 有两种模式：Capabilities Negotiation模式和Command模式。</p><h2 id="那么该如何建立qmp连接呢"><a href="#那么该如何建立qmp连接呢" class="headerlink" title="那么该如何建立qmp连接呢"></a>那么该如何建立qmp连接呢</h2><p>这里简要介绍通过tcp和unix socket使用qmp。</p><h3 id="通过TCP使用QMP"><a href="#通过TCP使用QMP" class="headerlink" title="通过TCP使用QMP"></a>通过TCP使用QMP</h3><p>使用-qmp添加qmp相关参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./qemu-system-x86_64 -m 2048 -hda /root/centos6.img -<span class="built_in">enable</span>-kvm -qmp tcp:localhost:1234,server,nowait</span><br></pre></td></tr></table></figure><p>新开一个终端使用telnet 链接localhost：1234</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">telnet localhost 1234</span><br></pre></td></tr></table></figure><p>之后就可以使用qmp的命令和虚拟机交互了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# telnet localhost 1234</span><br><span class="line">Trying ::1...</span><br><span class="line">Connected to localhost.</span><br><span class="line">Escape character is &apos;^]&apos;.</span><br><span class="line">&#123;&quot;QMP&quot;: &#123;&quot;version&quot;: &#123;&quot;qemu&quot;: &#123;&quot;micro&quot;: 0, &quot;minor&quot;: 6, &quot;major&quot;: 2&#125;, &quot;package&quot;: &quot;&quot;&#125;, &quot;capabilities&quot;: []&#125;&#125;</span><br><span class="line">&#123; &quot;execute&quot;: &quot;qmp_capabilities&quot; &#125;</span><br><span class="line">&#123;&quot;return&quot;: &#123;&#125;&#125;</span><br><span class="line">&#123; &quot;execute&quot;: &quot;query-status&quot; &#125;</span><br><span class="line">&#123;&quot;return&quot;: &#123;&quot;status&quot;: &quot;running&quot;, &quot;singlestep&quot;: false, &quot;running&quot;: true&#125;&#125;</span><br></pre></td></tr></table></figure><h3 id="通过unix-socket使用QMP"><a href="#通过unix-socket使用QMP" class="headerlink" title="通过unix socket使用QMP"></a>通过unix socket使用QMP</h3><p>使用unix socket创建qmp：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./qemu-system-x86_64 -m 2048 -hda /root/centos6.img -enable-kvm -qmp unix:/tmp/qmp-test,server,nowait</span><br></pre></td></tr></table></figure><p>使用nc连接该socket:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc -U /tmp/qmp-test</span><br></pre></td></tr></table></figure><p>之后就一样了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost qmp]# nc -U /tmp/qmp-test</span><br><span class="line">&#123;&quot;QMP&quot;: &#123;&quot;version&quot;: &#123;&quot;qemu&quot;: &#123;&quot;micro&quot;: 0, &quot;minor&quot;: 6, &quot;major&quot;: 2&#125;, &quot;package&quot;: &quot;&quot;&#125;, &quot;capabilities&quot;: []&#125;&#125;</span><br><span class="line">&#123; &quot;execute&quot;: &quot;qmp_capabilities&quot; &#125;</span><br><span class="line">&#123;&quot;return&quot;: &#123;&#125;&#125;</span><br><span class="line">&#123; &quot;execute&quot;: &quot;query-status&quot; &#125;</span><br><span class="line">&#123;&quot;return&quot;: &#123;&quot;status&quot;: &quot;running&quot;, &quot;singlestep&quot;: false, &quot;running&quot;: true&#125;&#125;</span><br></pre></td></tr></table></figure><p>QMP的详细命令格式可以在qemu的代码树主目录下面的qmp-commands.hx中找到。</p><h3 id="自动批量发送QMP命令"><a href="#自动批量发送QMP命令" class="headerlink" title="自动批量发送QMP命令"></a>自动批量发送QMP命令</h3><p>可以通过下面这个脚本给QEMU虚拟机发送命令。这对于测试虚拟机的一些功能是很有用的。试了一下，对于unix socket的方法能使用的，对于tcp连接的方法没有使用成功。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"># QEMU Monitor Protocol Python class</span><br><span class="line">#</span><br><span class="line"># Copyright (C) 2009 Red Hat Inc.</span><br><span class="line">#</span><br><span class="line"># This work is licensed under the terms of the GNU GPL, version 2.  See</span><br><span class="line"># the COPYING file in the top-level directory.</span><br><span class="line"></span><br><span class="line">import socket, json, time, commands</span><br><span class="line">from optparse import OptionParser</span><br><span class="line"></span><br><span class="line">class QMPError(Exception):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">class QMPConnectError(QMPError):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">class QEMUMonitorProtocol:</span><br><span class="line">    def connect(self):</span><br><span class="line">        print self.filename</span><br><span class="line">        self.sock.connect(self.filename)</span><br><span class="line">        data = self.__json_read()</span><br><span class="line">        if data == None:</span><br><span class="line">            raise QMPConnectError</span><br><span class="line">        if not data.has_key(&apos;QMP&apos;):</span><br><span class="line">            raise QMPConnectError</span><br><span class="line">        return data[&apos;QMP&apos;][&apos;capabilities&apos;]</span><br><span class="line"></span><br><span class="line">    def close(self):</span><br><span class="line">        self.sock.close()</span><br><span class="line"></span><br><span class="line">    def send_raw(self, line):</span><br><span class="line">        self.sock.send(str(line))</span><br><span class="line">        return self.__json_read()</span><br><span class="line"></span><br><span class="line">    def send(self, cmdline, timeout=30, convert=True):</span><br><span class="line">        end_time = time.time() + timeout</span><br><span class="line">        if convert:</span><br><span class="line">            cmd = self.__build_cmd(cmdline)</span><br><span class="line">        else:</span><br><span class="line">            cmd = cmdline</span><br><span class="line">    print(&quot;*cmdline = %s&quot; % cmd)</span><br><span class="line">        print cmd</span><br><span class="line">        self.__json_send(cmd)</span><br><span class="line">        while time.time() &lt; end_time:</span><br><span class="line">            resp = self.__json_read()</span><br><span class="line">            if resp == None:</span><br><span class="line">                return (False, None)</span><br><span class="line">            elif resp.has_key(&apos;error&apos;):</span><br><span class="line">                return (False, resp[&apos;error&apos;])</span><br><span class="line">            elif resp.has_key(&apos;return&apos;):</span><br><span class="line">                return (True, resp[&apos;return&apos;])</span><br><span class="line"></span><br><span class="line">    def read(self, timeout=30):</span><br><span class="line">        o = &quot;&quot;</span><br><span class="line">        end_time = time.time() + timeout</span><br><span class="line">        while time.time() &lt; end_time:</span><br><span class="line">            try:</span><br><span class="line">                o += self.sock.recv(1024)</span><br><span class="line">                if len(o) &gt; 0:</span><br><span class="line">                    break</span><br><span class="line">            except:</span><br><span class="line">                time.sleep(0.01)</span><br><span class="line">        if len(o) &gt; 0:</span><br><span class="line">            return json.loads(o)</span><br><span class="line">        else:</span><br><span class="line">            return None</span><br><span class="line"></span><br><span class="line">    def __build_cmd(self, cmdline):</span><br><span class="line">        cmdargs = cmdline.split()</span><br><span class="line">        qmpcmd = &#123; &apos;execute&apos;: cmdargs[0], &apos;arguments&apos;: &#123;&#125; &#125;</span><br><span class="line">        for arg in cmdargs[1:]:</span><br><span class="line">            opt = arg.split(&apos;=&apos;)</span><br><span class="line">            try:</span><br><span class="line">                value = int(opt[1])</span><br><span class="line">            except ValueError:</span><br><span class="line">                value = opt[1]</span><br><span class="line">            qmpcmd[&apos;arguments&apos;][opt[0]] = value</span><br><span class="line">print(&quot;*cmdline = %s&quot; % cmdline)</span><br><span class="line">        return qmpcmd</span><br><span class="line"></span><br><span class="line">    def __json_send(self, cmd):</span><br><span class="line">        # XXX: We have to send any additional char, otherwise</span><br><span class="line">        # the Server won&apos;t read our input</span><br><span class="line">        self.sock.send(json.dumps(cmd) + &apos; &apos;)</span><br><span class="line"></span><br><span class="line">    def __json_read(self):</span><br><span class="line">        try:</span><br><span class="line">            return json.loads(self.sock.recv(1024))</span><br><span class="line">        except ValueError:</span><br><span class="line">            return</span><br><span class="line"></span><br><span class="line">    def __init__(self, filename, protocol=&quot;tcp&quot;):</span><br><span class="line">        if protocol == &quot;tcp&quot;:</span><br><span class="line">            self.filename = (&quot;localhost&quot;, int(filename))</span><br><span class="line">            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">        elif protocol == &quot;unix&quot;:</span><br><span class="line">            self.filename = filename</span><br><span class="line">            print self.filename</span><br><span class="line">            self.sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)</span><br><span class="line">        #self.sock.setblocking(0)</span><br><span class="line">        self.sock.settimeout(5)</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    parser = OptionParser()</span><br><span class="line">    parser.add_option(&apos;-n&apos;, &apos;--num&apos;, dest=&apos;num&apos;, default=&apos;10&apos;, help=&apos;Times want to try&apos;)</span><br><span class="line">    parser.add_option(&apos;-f&apos;, &apos;--file&apos;, dest=&apos;port&apos;, default=&apos;4444&apos;, help=&apos;QMP port/filename&apos;)</span><br><span class="line">    parser.add_option(&apos;-p&apos;, &apos;--protocol&apos;, dest=&apos;protocol&apos;,default=&apos;tcp&apos;, help=&apos;QMP protocol&apos;)</span><br><span class="line">    def usage():</span><br><span class="line">        parser.print_help()</span><br><span class="line">        sys.exit(1)</span><br><span class="line"></span><br><span class="line">    options, args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    print options</span><br><span class="line">    if len(args) &gt; 0:</span><br><span class="line">        usage()</span><br><span class="line"></span><br><span class="line">    num = int(options.num)</span><br><span class="line">    qmp_filename = options.port</span><br><span class="line">    qmp_protocol = options.protocol</span><br><span class="line">    qmp_socket = QEMUMonitorProtocol(qmp_filename,qmp_protocol)</span><br><span class="line">    qmp_socket.connect()</span><br><span class="line">    qmp_socket.send(&quot;qmp_capabilities&quot;)</span><br><span class="line">    qmp_socket.close()</span><br><span class="line"></span><br><span class="line">##########################################################</span><br><span class="line">#Usage</span><br><span class="line">#Options:</span><br><span class="line">#  -h, --help            show this help message and exit</span><br><span class="line">#  -n NUM, --num=NUM     Times want to try</span><br><span class="line">#  -f PORT, --file=PORT  QMP port/filename</span><br><span class="line">#  -p PROTOCOL, --protocol=PROTOCOL</span><br><span class="line">#                        QMP protocol</span><br><span class="line"># e.g: # python xxxxx.py -n $NUM -f $PORT</span><br><span class="line">##########################################################</span><br></pre></td></tr></table></figure><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p>关于QMP更详细的文档，可以参考其官方文档：<br><a href="https://wiki.qemu.org/Documentation/QMP" target="_blank" rel="noopener">https://wiki.qemu.org/Documentation/QMP</a></p>]]></content>
      
      
      <categories>
          
          <category> QEMU </category>
          
      </categories>
      
      
        <tags>
            
            <tag> QEMU </tag>
            
            <tag> QMP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hexo+next主题</title>
      <link href="/2018/11/26/hexo-next%E4%B8%BB%E9%A2%98/"/>
      <url>/2018/11/26/hexo-next%E4%B8%BB%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>这篇内容详细记述了我在使用hexo搭载博客的过程中走过的路和跌过的坑。<br>另外，我搭建了一个新的博客作为自己的技术博客，地址是xuquan.site，欢迎来逛逛~</p><p>从印象笔记到简书到Hexo<br>我一直有收集资料的习惯，最开始把资料都放在印象笔记里，然后自己平时处理消化之后会添加一个Learning Card作为资料开头，方便自己复习和记忆。但是时间一久，资料就特别多，加上处理过和没处理过的都积攒在一起就显得特别臃肿，于是我就考虑将消化过的内容发布到简书上，给自己做一个记录，也算是自己的技术博客。</p><p>但使用了简书3个月之后，我就发现了一些问题：</p><p>首先，我是用Typora来写内容的，简书虽然支持Markdown，但是自带的编辑器功能不是特别完善，有些时候还得反复切换Markdown和富文本模式，很麻烦；</p><p>其次，直接复制Typora的内容到简书是无法同步图片的，因为Typora的图片是放在文件夹内的asset文件夹内的，复制到简书需要图片挨个重新上传，图片多的时候简直想放弃这一篇内容；</p><p>另外，简书无法添加标签，只能分笔记本来写不同的内容，而且也不能添加置顶，功能比较单一；</p><p>在综合考虑之后，我决定搭建一个自己的博客。正好看到有人推荐hexo搭建，而且大家搭建的博客都挺赏心悦目的，我就开始动手搭建自己的了。</p><p>Hexo部署<br>hexo有中文的文档，这一点非常方便，但是在安装过程中还是很容易有疏忽的地方，导致安装失败。</p><p>安装前提<br>安装Hexo之前，必须保证自己的电脑中已经安装好了Node.js和Git。因为这两个软件我之前都安装过，这里就不重复安装过程了，检验方式如下：</p><p>image-20180809141924679<br>安装Hexo<br>安装好node.js和git后，可以通过npm来安装Hexo。</p><p>npm install -g hexo-cli<br>建站<br>之后就可以在电脑里新建一个文件夹来作为存放博客全部内容的大本营了。我们直接用hexo命令来初始化博客文件夹：</p><p>hexo init <folder><br>cd <folder><br>npm install</folder></folder></p><p><folder>就是文件夹的名字，我们可以自己随意取这个名字，我的经验是，现在初始化应该不需要后面npm install这个步骤了，在创建的时候 ，文件夹初始化已经把需要的内容都下载进去了。</folder></p><p>文件夹开始初始化了<br>站内内容<br>新建好的文件夹目录如下：</p><p>.<br>├── _config.yml<br>├── package.json<br>├── scaffolds<br>├── source<br>|   ├── _drafts<br>|   └── _posts<br>└── themes<br>这里解释一下各个文件夹的作用：</p><p>config.yml<br>博客的配置文件，博客的名称、关键词、作者、语言、博客主题…设置都在里面。</p><p>package.json<br>应用程序信息，新添加的插件内容也会出现在这里面，我们可以不修改这里的内容。</p><p>scaffolds<br>scaffolds就是脚手架的意思，这里放了三个模板文件，分别是新添加博客文章（posts）、新添加博客页（page）和新添加草稿（draft）的目标样式。</p><p>这部分可以修改的内容是，我们可以在模板上添加比如categories等自定义内容</p><p>source<br>source是放置我们博客内容的地方，里面初始只有两个文件夹，一个是drafts（草稿），一个posts（文章），但之后我们通过命令新建tags（标签）还有categories（分类）页后，这里会相应地增加文件夹。</p><p>themes<br>放置主题文件包的地方。Hexo会根据这个文件来生成静态页面。</p><p>初始状态下只有landscape一个文件夹，后续我们可以添加自己喜欢的。</p><p>Hexo命令<br>init<br>新建一个网站。</p><p>hexo init <folder><br>new<br>新建文章或页面。</folder></p><p>hexo new <layout> “title”<br>这里的<layout>对应我们要添加的内容，如果是posts就是添加新的文章，如果是page就是添加新的页面。</layout></layout></p><p>默认是添加posts。</p><p>然后我们就可以在对应的posts或drafts文件夹里找到我们新建的文件，然后在文件里用Markdown的格式来写作了。</p><p>generate<br>生成静态页面</p><p>hexo generate<br>也可以简写成</p><p>hexo g<br>deploy<br>将内容部署到网站</p><p>hexo deploy<br>也可以简写成</p><p>hexo -d<br>publish<br>发布内容，实际上是将内容从drafts（草稿）文件夹移到posts（文章）文件夹。</p><p>hexo publish <layout> <filename><br>server<br>启动服务器，默认情况下，访问网站为<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a></filename></layout></p><p>hexo server<br>也可以简写成</p><p>hexo s<br>根据我的经验，除了第一次部署的时候，我们会重点用到hexo init这个命令外，在平时写博客和发布过程中最常用的就是：</p><p>hexo n <filename> 新建文章<br>hexo s 启动服务器，在本地查看内容<br>hexo g 生成静态页面<br>hexo deploy 部署到网站<br>以上四个步骤。</filename></p><p>其实以上命令我觉得就足够了，文档里还有很多功能，但我在实际使用的过程中都还没有遇到。</p><p>搭建好后我们在localhost:4000就可以看到这样的博客内容：</p><p>image-20180809152743968<br>实际操作<br>我在新建博客之后，做了以下改动：</p><ol><li>创建“分类”页面<br>新建分类页面</li></ol><p>hexo new page categories<br>给分类页面添加类型</p><p>我们在source文件夹中的categories文件夹下找到index.md文件，并在它的头部加上type属性。</p><hr><p>title: 文章分类<br>date: 2017-05-27 13:47:40</p><h2 id="type-“categories”-这部分是新添加的"><a href="#type-“categories”-这部分是新添加的" class="headerlink" title="type: “categories”   #这部分是新添加的"></a>type: “categories”   #这部分是新添加的</h2><p>给模板添加分类属性</p><p>现在我们打开scarffolds文件夹里的post.md文件，给它的头部加上categories:，这样我们创建的所有新的文章都会自带这个属性，我们只需要往里填分类，就可以自动在网站上形成分类了。</p><p>title: hexo+next主题<br>date: 1543200599000<br>categories:<br>tags:<br>给文章添加分类</p><p>现在我们可以找到一篇文章，然后尝试给它添加分类</p><p>layout: posts<br>title: 写给小白的express学习笔记1： express-static文件静态管理<br>date: 2018-06-07 00:38:36<br>categories: 学习笔记<br>tags: [node.js, express]</p><ol start="2"><li>创建“标签”页面<br>创建”标签”页的方式和创建“分类”一样。</li></ol><p>新建“标签”页面</p><p>hexo new page tags<br>给标签页面添加类型</p><p>我们在source文件夹中的tags文件夹下找到index.md文件，并在它的头部加上type属性。</p><p>title: tags<br>date: 2018-08-06 22:48:29<br>type: “tags” #新添加的内容<br>给文章添加标签</p><p>有两种写法都可以，第一种是类似数组的写法，把标签放在中括号[]里，用英文逗号隔开</p><p>layout: posts<br>title: 写给小白的express学习笔记1： express-static文件静态管理<br>date: 2018-06-07 00:38:36<br>categories: 学习笔记<br>tags: [node.js, express]<br>第二种写法是用-短划线列出来</p><p>layout: posts<br>title: 写给小白的express学习笔记1： express-static文件静态管理<br>date: 2018-06-07 00:38:36<br>categories: 学习笔记<br>tags: </p><ul><li>node.js</li><li>express<br>部署域名<br>紧接着我们就可以把这些内容添加到Github页面上，然后生成我们自己的博客了。</li></ul><p>部署Github<br>首先你必须有一个github账号</p><p>然后新建一个仓库，这一有第一个坑，我之前用了hexoblog来作为项目名称，一直没能搭建成功，后来看到其他大牛的经验，才发现项目名一定要是用户名.github.io的形式(README.md可选可不选)</p><p>image-20180809153134467<br>然后在setting里添加生成页面的选项</p><p>image-20180809153304980<br>image-20180809153343362<br>这个时候github页面其实就生成好了，但是我们的内容还需要同步到github上，所以打开hexo文件夹里的配置文件config.yml，添加部署路径</p><p>image-20180809153610047<br>这里注意两小点：</p><p>属性和内容之间一定要有一个空格，配置文件有自己的格式规范<br>如果你之前没有用git关联过自己的github库，需要配置SSH等参数，否则无法成功，这部分搜git就有很多相关教程<br>我们再用hexo g &amp;&amp; hexo deploy就能将内容推送到github上了，在github页面上也能看到自己的内容了</p><p>image-20180809153933270<br>部署自己的域名<br>首先我们需要获取一个域名，我是在阿里云上购买了，上面可以根据自己想要的内容搜，比如我用了自己的名字，推荐给你的域名根据后缀不同会有价格上的区别，我选了一个不太贵的；</p><p>购买域名之后需要实名认证，这是另一个坑，我之前不知道实名认证审核完成前域名无法用，一直以为自己搭建失败了；</p><p>认证成功后需要解析域名</p><p>image-20180809154942783<br>image-20180809155013659<br>记录类型选CNAME，记录值是自己github生成页面的地址。</p><p>在博客的页面添加CNAME文件，并在里面记录自己域名的地址，将这个文件放在public文件夹下</p><p>这里还有一个小坑，CNAME文件经常被覆盖，导致我们重新部署博客后，链接就不可用了，这里可以下载一个叫hexo-generator-cname的插件，这样它会自动搞定CNAME的问题，只需要第一次手动将域名添加到文件里即可</p><p>npm i hexo-generator-cname –save<br>最后hexo g &amp;&amp; hexo deploy就可以了</p><p>NexT主题<br>hexo有很多开源的主题，我选了NexT，开始只是觉得很简洁清爽，后来发现它的功能挺齐全的，提前解决了很多搭建过程中会遇到的问题。这里强烈推荐一下。</p><p>首先，NexT也有中文文档，然后我们就可以开始了。</p><p>安装<br>我是用的git clone的方法，文档中还有其他方法</p><p>$ git clone <a href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="noopener">https://github.com/iissnan/hexo-theme-next</a> themes/next<br>设置主题<br>在hexo根目录下的配置文件config.yml里设置主题</p><p>theme: next<br>配置主题<br>接下来我们就可以来按需配置主题内容了，所有内容都在themes/next文件夹下的config.yml文件里修改。</p><p>官方文档里写的是有些配置需要将一部分代码添加到配置文件中，但其实不用，我们逐行看配置文件就会发现，有很多功能都已经放在配置文件里了，只是注释掉了，我们只需要取消注释，把需要的相关信息补全即可使用</p><p>菜单栏 menu<br>原生菜单栏有主页、关于、分类、标签等数个选项，但是在配置文件中是注释掉的状态，这里我们自行修改注释就行</p><p>menu:<br>  home: / || home</p><h1 id="about-about-user"><a href="#about-about-user" class="headerlink" title="about: /about/ || user"></a>about: /about/ || user</h1><p>  tags: /tags/ || tags<br>  categories: /categories/ || th<br>  archives: /archives/ || archive</p><h1 id="schedule-schedule-calendar"><a href="#schedule-schedule-calendar" class="headerlink" title="schedule: /schedule/ || calendar"></a>schedule: /schedule/ || calendar</h1><h1 id="sitemap-sitemap-xml-sitemap"><a href="#sitemap-sitemap-xml-sitemap" class="headerlink" title="sitemap: /sitemap.xml || sitemap"></a>sitemap: /sitemap.xml || sitemap</h1><h1 id="commonweal-404-heartbeat"><a href="#commonweal-404-heartbeat" class="headerlink" title="commonweal: /404/ || heartbeat"></a>commonweal: /404/ || heartbeat</h1><p>注意点：</p><p>如果事先没有通过hexo new page <pagename>来创建页面的话，即使在配置文件中取消注释，页面也没法显示<br>我们也可以添加自己想要添加的页面，不用局限在配置文件里提供的选择里<br>||后面是fontAwesome里的文件对应的名称<br>menu_icons记得选enable: true（默认应该是true）<br>我在这部分添加了两个自定义的页面，后面在第三方插件部分我会再提到。</pagename></p><p>menu:<br>  home: / || home</p><h1 id="about-about-user-1"><a href="#about-about-user-1" class="headerlink" title="about: /about/ || user"></a>about: /about/ || user</h1><p>  tags: /tags/ || tags<br>  categories: /categories/ || th<br>  读书: /books || book<br>  电影: /movies || film<br>  archives: /archives/ || archive</p><h1 id="schedule-schedule-calendar-1"><a href="#schedule-schedule-calendar-1" class="headerlink" title="schedule: /schedule/ || calendar"></a>schedule: /schedule/ || calendar</h1><h1 id="sitemap-sitemap-xml-sitemap-1"><a href="#sitemap-sitemap-xml-sitemap-1" class="headerlink" title="sitemap: /sitemap.xml || sitemap"></a>sitemap: /sitemap.xml || sitemap</h1><h1 id="commonweal-404-heartbeat-1"><a href="#commonweal-404-heartbeat-1" class="headerlink" title="commonweal: /404/ || heartbeat"></a>commonweal: /404/ || heartbeat</h1><p>主题风格 schemes<br>主题提供了4个，我们把想要选择的取消注释，其他三个保持注释掉的状态即可。</p><p>Muse</p><p>image-20180809164700600<br>Mist</p><p>image-20180809164749052<br>Pisces</p><p>image-20180809164925685<br>Gemini</p><p>image-20180809165023401<br>选择主题后也可以自定义，不过我还没摸清楚有哪些地方可以自定义，等弄清楚了我再来更新。</p><p>底部建站时间和图标修改<br>修改主题的配置文件：</p><p>footer:</p><h1 id="Specify-the-date-when-the-site-was-setup"><a href="#Specify-the-date-when-the-site-was-setup" class="headerlink" title="Specify the date when the site was setup."></a>Specify the date when the site was setup.</h1><h1 id="If-not-defined-current-year-will-be-used"><a href="#If-not-defined-current-year-will-be-used" class="headerlink" title="If not defined, current year will be used."></a>If not defined, current year will be used.</h1><p>  since: 2018</p><h1 id="Icon-between-year-and-copyright-info"><a href="#Icon-between-year-and-copyright-info" class="headerlink" title="Icon between year and copyright info."></a>Icon between year and copyright info.</h1><p>  icon: snowflake-o</p><h1 id="If-not-defined-will-be-used-author-from-Hexo-main-config"><a href="#If-not-defined-will-be-used-author-from-Hexo-main-config" class="headerlink" title="If not defined, will be used author from Hexo main config."></a>If not defined, will be used <code>author</code> from Hexo main config.</h1><p>  copyright:</p><h1 id="————————————————————"><a href="#————————————————————" class="headerlink" title="————————————————————-"></a>————————————————————-</h1><h1 id="Hexo-link-Powered-by-Hexo"><a href="#Hexo-link-Powered-by-Hexo" class="headerlink" title="Hexo link (Powered by Hexo)."></a>Hexo link (Powered by Hexo).</h1><p>  powered: false</p><p>  theme:</p><pre><code># Theme &amp; scheme info link (Theme - NexT.scheme).enable: false# Version info of NexT after scheme info (vX.X.X).# version: false</code></pre><p>我在这部分做了这样几件事：</p><p>把用户的图标从小人user改成了雪花snowflake-o<br>copyright留空，显示成页面author即我的名字<br>powered: false把hexo的授权图片取消了<br>theme: enable:false 把主题的内容也取消了<br>这样底部信息比较简单。</p><p>image-20180809172835606<br>个人社交信息 social<br>在social里我们可以自定义自己想要在个人信息部分展现的账号，同时给他们加上图标。</p><p>social:<br>  GitHub: <a href="https://github.com/XuQuan-nikkkki" target="_blank" rel="noopener">https://github.com/XuQuan-nikkkki</a> || github<br>  E-Mail: mailto:<a href="mailto:xuquan1225@hotmail.com" target="_blank" rel="noopener">xuquan1225@hotmail.com</a> || envelope</p><p>  #Google: <a href="https://plus.google.com/yourname" target="_blank" rel="noopener">https://plus.google.com/yourname</a> || google</p><p>  #Twitter: <a href="https://twitter.com/yourname" target="_blank" rel="noopener">https://twitter.com/yourname</a> || twitter</p><p>  #FB Page: <a href="https://www.facebook.com/yourname" target="_blank" rel="noopener">https://www.facebook.com/yourname</a> || facebook<br>注意点：</p><p>||后面对应的名称是fontAwesome里图标的名称，如果我们选择的账号没有对应的图标（如豆瓣、知乎），我们可以在fontAwesome库里去选择自己喜欢的图标<br>建议不要找太新的fontAwesome图标，主题关联的库版本没有那么新，很可能显示不了或者显示一个地球<br>网站动画效果<br>为了网站响应速度我们可以把网站的动画关掉</p><p>motion:<br>  enable: false<br>但我觉得页面比较素，所以开了动画，选择了canvas-nest这一个，主题自带四种效果，可以选自己喜欢的。</p><p>motion:<br>  enable: true<br>  async: true</p><h1 id="Canvas-nest"><a href="#Canvas-nest" class="headerlink" title="Canvas-nest"></a>Canvas-nest</h1><p>canvas_nest: true</p><h1 id="three-waves"><a href="#three-waves" class="headerlink" title="three_waves"></a>three_waves</h1><p>three_waves: false</p><h1 id="canvas-lines"><a href="#canvas-lines" class="headerlink" title="canvas_lines"></a>canvas_lines</h1><p>canvas_lines: false</p><h1 id="canvas-sphere"><a href="#canvas-sphere" class="headerlink" title="canvas_sphere"></a>canvas_sphere</h1><p>canvas_sphere: false<br>评论系统<br>NexT原生支持多说、Disqus、hypercomments等多种评论系统。我选择了Disqus。</p><p>方法也非常简单。直接去Disqus注册，注册完了在配置的时候会给你一个名为shortname的ID，将这个ID填在配置文件里即可。</p><h1 id="Disqus"><a href="#Disqus" class="headerlink" title="Disqus"></a>Disqus</h1><p>disqus:<br>  enable: true<br>  shortname: xuquan<br>  count: true<br>统计文章字数和阅读时间<br>post_wordcount:<br>  item_text: true<br>  wordcount: true  # 文章字数<br>  min2read: true   # 阅读时间<br>  totalcount: true  # 总共字数<br>  separated_meta: true<br>统计阅读次数<br>这里我用的是leancloud的服务，具体方法参考NexT上的教程,添加完之后效果如下：</p><p>image-20180809175133462<br>第三方插件<br>Hexo-admin<br>Hexo-admin插件允许我们直接在本地页面上修改文章内容。</p><p>下载</p><p>npm i hexo-admin –save<br>登录<a href="http://localhost:4000/admin即可看到我们所有的文章内容，并且在可视化界面中操作文章内容" target="_blank" rel="noopener">http://localhost:4000/admin即可看到我们所有的文章内容，并且在可视化界面中操作文章内容</a></p><p>Hexo-douban<br>hexo-douban插件可以在博客中添加豆瓣电影、读书和游戏页面，关联我们自己的账号。</p><p>下载</p><p>npm install hexo-douban –save<br>配置</p><p>在hexo根目录下的config.yml文件中添加如下内容</p><p>douban:<br>  user:<br>  builtin: false<br>  book:<br>    title: ‘This is my book title’<br>    quote: ‘This is my book quote’<br>  movie:<br>    title: ‘This is my movie title’<br>    quote: ‘This is my movie quote’<br>  game:<br>    title: ‘This is my game title’<br>    quote: ‘This is my game quote’<br>  timeout: 10000<br>title和quote后面的内容会分别作为电影/读书/游戏页面的标题和副标题（引言）呈现在博客里。</p><p>user就写我们豆瓣的id，可以在“我的豆瓣”页面中找到，builtin指是否将生成页面功能嵌入hexo s和hexo g中，建议选false，因为true会导致页面每次启动本地服务器都需要很长时间生成豆瓣页面，长到怀疑人生。</p><p>生成页面</p><p>hexo douban   #生成读书、电影、游戏三个页面<br>hexo douban -b  #生成读书页面<br>hexo douban -m  #生成电影页面<br>hexo douban -g  #生成游戏页面<br>在博客中生成页面</p><p>这里就需要用到我们前面提过的hexo new命令了。</p><p>hexo new page books<br>hexo new page movies<br>hexo new page games<br>在博客中添加页面</p><p>在menu部分添加我们需要添加的页面名称和相对路径</p><p>menu:<br>  Home: /<br>  Archives: /archives<br>  Books: /books     #This is your books page<br>  Movies: /movies   #This is your movies page<br>  Games: /games   #This is your games page<br>部署到博客</p><p>hexo g &amp;&amp; hexo deploy<br>我踩过的坑<br>iPic图片上传<br>hexo博客发布Typora写好的内容也会出现图片无法同步的问题，网上有大佬给出的解决方案是使用hexo-asset-image插件，这样在创建博客时会有一个与.md文件同名的文件夹，将图片同步到文件夹内即可。</p><p>但时间下来还是比较麻烦，因为Typora并没有自定义图片路径的功能，它会放在与文件相关的asset文件夹内。</p><p>我找到的最终方案是使用Typora自带的一个功能：图片上传iPic图床。这样在添加图片的时候，图片链接就自动更换成了图床的地址，这时同步到博客就没有问题了。</p><p>评论系统<br>因为多说已经停止服务了，最开始看到有人说Disqus得翻墙，就选了一个韩国的评论服务，叫来必力，但事实证明墙外就没有稳定的服务，在我挂VPN的情况下也要加载好半天，后来就还是换成了Disqus，具体配置方法看前文。</p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>KVM源代码分析4:内存虚拟化</title>
      <link href="/2014/12/11/kvm-src-4-mem/"/>
      <url>/2014/12/11/kvm-src-4-mem/</url>
      
        <content type="html"><![CDATA[<p>代码版本：<a href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git</a> v3.16.37</p><p>在虚拟机的创建与运行中pc_init_pci负责(“KVM源代码分析2:虚拟机的创建与运行”)，内存初始化也是在这里完成的，还是一步步从qemu说起，在vl.c的main函数中有ram_size参数，由qemu入参标识QEMU_OPTION_m设定，顾名思义就是虚拟机内存的大小，通过machine-&gt;init一步步传递给pc_init1函数。在这里分出了above_4g_mem_size和below_4g_mem_size，即高低端内存（也不一定是32bit机器..），然后开始初始化内存，即pc_memory_init，内存通过memory_region_init_ram下面的qemu_ram_alloc分配，使用qemu_ram_alloc_from_ptr。</p><p>插播qemu对内存条的模拟管理，是通过RAMBlock和ram_list管理的，RAMBlock就是每次申请的内存池，ram_list则是RAMBlock的链表，他们结构如下：</p><pre class="lang:c decode:1 hljs cpp">typedefstruct RAMBlock {//对应宿主的内存地址    uint8_t *host;//block在ramlist中的偏移    ram_addr_t offset;//block长度    ram_addr_t length;    uint32_t flags;//block名字    char idstr[256];    QLIST_ENTRY(RAMBlock) next;\#if defined(__linux__) && !defined(TARGET_S390X)    int fd;\#endif} RAMBlock;typedef struct RAMList {//看代码理解就是list的head，但是不知道为啥叫dirty...    uint8_t *phys_dirty;    QLIST_HEAD(ram, RAMBlock) blocks;} RAMList;</pre><p>下面再回到qemu_ram_alloc_from_ptr函数，使用find_ram_offset赋值给new block的offset，find_ram_offset具体工作模型已经在”KVM源代码分析2:虚拟机的创建与运行”，不赘述。然后是一串判断，在kvm_enabled的情况下使用new_block-&gt;host = kvm_vmalloc(size)，最终内存是qemu_vmalloc分配的，使用qemu_memalign干活。</p><pre class="lang:c decode:1 hljs cpp">void \*qemu_memalign(size_t alignment, size_t size){    void *ptr;//使用posix进行内存针对页大小对齐\#if defined(_POSIX_C_SOURCE) && !defined(__sun__)    int ret;    ret = posix_memalign(&ptr, alignment, size);    if (ret != 0) {        fprintf(stderr, "Failed to allocate %zu B: %sn",                size, strerror(ret));        abort();    }\#elif defined(CONFIG_BSD)    ptr = qemu_oom_check(valloc(size));\#else//所谓检查oom就是看memalign对应malloc申请内存是否成功    ptr = qemu_oom_check(memalign(alignment, size));\#endif    trace_qemu_memalign(alignment, size, ptr);    return ptr;}</pre><p>以上qemu_vmalloc进行内存申请就结束了。在qemu_ram_alloc_from_ptr函数末尾则是将block添加到链表，realloc整个ramlist，用memset初始化整个ramblock，madvise对内存使用限定。<br>然后一层层的退回到pc_memory_init函数。</p><p>此时pc.ram已经分配完成，ram_addr已经拿到了<a href="http://www.oenhan.com/kernel-program-exec" title="从一次内存泄露看程序在内核中的执行过程" target="_blank" rel="noopener">分配的内存</a>地址，MemoryRegion ram初始化完成。下面则是对已有的ram进行分段，即ram-below-4g和ram-above-4g，也就是高端内存和低端内存。用memory_region_init_alias初始化子MemoryRegion，然后将memory_region_add_subregion添加关联起来，memory_region_add_subregion具体细节“KVM源码分析2”中已经说了，参考对照着看吧，中间很多映射代码过程也只是qemu遗留的软件实现，没看到具体存在的意义，直接看到kvm_set_user_memory_region函数，内核真正需要kvm_vm_ioctl传递过去的参数是什么， struct kvm_userspace_memory_region mem而已，也就是</p><pre class="lang:c decode:1 hljs cpp">struct kvm_userspace_memory_region {__u32 slot;__u32 flags;__u64 guest_phys_addr;__u64 memory_size; /* bytes */__u64 userspace_addr; /* start of the userspace allocated memory */};</pre><p>kvm_vm_ioctl进入到内核是在KVM_SET_USER_MEMORY_REGION参数中，即执行kvm_vm_ioctl_set_memory_region，然后一直向下，到<strong>kvm_set_memory_region函数，check_memory_region_flags检查mem-&gt;flags是否合法，而当前flag也就使用了两位，KVM_MEM_LOG_DIRTY_PAGES和KVM_MEM_READONLY，从qemu传递过来只能是KVM_MEM_LOG_DIRTY_PAGES,下面是对mem中各参数的合规检查，(mem-&gt;memory_size &amp; (PAGE_SIZE - 1))要求以页为单位，(mem-&gt;guest_phys_addr &amp; (PAGE_SIZE - 1))要求guest_phys_addr页对齐，而((mem-&gt;userspace_addr &amp; (PAGE_SIZE - 1)) || !access_ok(VERIFY_WRITE,(void </strong>user *)(unsigned long)mem-&gt;userspace_addr,mem-&gt;memory_size))则保证host的线性地址页对齐而且该地址域有写权限。<br>id_to_memslot则是根据qemu的内存槽号得到kvm结构下的内存槽号，转换关系来自id_to_index数组，那映射关系怎么来的，映射关系是一一对应的，在kvm_create_vm “KVM源代码分析2:虚拟机的创建与运行”中，kvm_init_memslots_id初始化对应关系，即slots-&gt;id_to_index[i] = slots-&gt;memslots[i].id = i，当前映射是没有意义的，估计是为了后续扩展而存在的。<br>扩充了new的kvm_memory_slot，下面直接在代码中注释更方便：</p><pre class="lang:c decode:1 hljs cs">//映射内存有大小，不是删除内存条if (npages) {//内存槽号没有虚拟内存条，意味内存新创建if (!old.npages)        change = KVM_MR_CREATE;    else { /* Modify an existing slot. *///修改已存在的内存修改标志或者平移映射地址//下面是不能处理的状态（内存条大小不能变，物理地址不能变，不能修改只读）        if ((mem->userspace_addr != old.userspace_addr) ||            (npages != old.npages) ||            ((new.flags ^ old.flags) & KVM_MEM_READONLY))            goto out;//guest地址不同，内存条平移        if (base_gfn != old.base_gfn)            change = KVM_MR_MOVE;        else if (new.flags != old.flags)//修改属性            change = KVM_MR_FLAGS_ONLY;        else { /* Nothing to change. */            r = 0;            goto out;        }    }} else if (old.npages) {//申请插入的内存为0，而内存槽上有内存，意味删除    change = KVM_MR_DELETE;} else /* Modify a non-existent slot: disallowed. */    goto out;</pre><p>另外看kvm_mr_change就知道memslot的变动值了：</p><pre class="lang:c decode:1 hljs cpp">enum kvm_mr_change {    KVM_MR_CREATE,    KVM_MR_DELETE,    KVM_MR_MOVE,    KVM_MR_FLAGS_ONLY,};</pre><p>在往下是一段检查</p><pre class="lang:c decode:1 hljs php">if ((change == KVM_MR_CREATE) || (change == KVM_MR_MOVE)) {    /* Check for overlaps */    r = -EEXIST;    kvm_for_each_memslot(slot, kvm->memslots) {        if ((slot->id >= KVM_USER_MEM_SLOTS) ||//下面排除掉准备操作的内存条，在KVM_MR_MOVE中是有交集的            (slot->id == mem->slot))            continue;//下面就是当前已有的slot与new在guest线性区间上有交集        if (!((base_gfn + npages <= slot-="">base_gfn) ||              (base_gfn >= slot->base_gfn + slot->npages)))            goto out;//out错误码就是EEXIST    }}</=></pre><p>如果是新插入内存条，代码则走入kvm_arch_create_memslot函数，里面主要是一个循环，KVM_NR_PAGE_SIZES是分页的级数，此处是3，第一次循环，lpages = gfn_to_index(slot-&gt;base_gfn + npages - 1,slot-&gt;base_gfn, level) + 1，lpages就是一级页表所需要的page数，大致是npages&gt;&gt;0<em>9,然后为slot-&gt;arch.rmap[i]申请了内存空间，此处可以猜想，rmap就是一级页表了，继续看，lpages约为npages&gt;&gt;1</em>9,此处又多为lpage_info申请了同等空间，然后对lpage_info初始化赋值，现在看不到lpage_info的具体作用，看到后再补上。整体上看kvm_arch_create_memslot做了一个3级的软件页表。<br>如果有脏页,并且脏页位图为空,则分配<a href="http://www.oenhan.com/linux-cache-writeback" target="_blank" rel="noopener">脏页位图</a>, kvm_create_dirty_bitmap实际就是”页数/8”.</p><pre class="lang:c decode:1 hljs cpp">if ((new.flags & KVM_MEM_LOG_DIRTY_PAGES) && !new.dirty_bitmap) {        if (kvm_create_dirty_bitmap(&new) < 0)            goto out_free;    }</pre><p>当内存条的改变是KVM_MR_DELETE或者KVM_MR_MOVE,先申请一个slots,把kvm-&gt;memslots暂存到这里,首先通过id_to_memslot获取准备插入的内存条对应到kvm的插槽是slot,无论删除还是移动,将其先标记为KVM_MEMSLOT_INVALID,然后是install_new_memslots,其实就是更新了一下slots-&gt;generation的值。</p><p>内存的添加说完了，看一下<a href="http://www.oenhan.com/kernel-program-exec" target="_blank" rel="noopener">EPT页表</a>的映射，在kvm_arch_vcpu_setup中有kvm_mmu_setup，是mmu的初始化，EPT的初始化是init_kvm_tdp_mmu，所谓的初始化就是填充了vcpu-&gt;arch.mmu结构体，里面有很多回调函数都会用到，最终的是tdp_page_fault。</p><pre class="hljs php">context->page_fault = tdp_page_fault;context->sync_page = nonpaging_sync_page;context->invlpg = nonpaging_invlpg;context->update_pte = nonpaging_update_pte;context->shadow_root_level = kvm_x86_ops->get_tdp_level();context->root_hpa = INVALID_PAGE;context->direct_map = true;context->set_cr3 = kvm_x86_ops->set_tdp_cr3;context->get_cr3 = get_cr3;context->get_pdptr = kvm_pdptr_read;context->inject_page_fault = kvm_inject_page_fault;</pre><p>当guest访问物理内存时发生vm-exit，进入vmx_handle_exit函数，根据EXIT_REASON_EPT_VIOLATION走到handle_ept_violation函数，exit_qualification = vmcs_readl(EXIT_QUALIFICATION)获取vm-exit的退出原因，进入kvm_mmu_page_fault函数：vcpu-&gt;arch.mmu.page_fault(vcpu, cr2, error_code, false)，即是tdp_page_fault，handle_mmio_page_fault的流程不提。</p><pre class="hljs cpp">//填充kvm mmu专用的slabr = mmu_topup_memory_caches(vcpu);//获取gfn使用的level，即hugepage的问题force_pt_level = mapping_level_dirty_bitmap(vcpu, gfn);if (likely(!force_pt_level)) {    level = mapping_level(vcpu, gfn);    gfn &= ~(KVM_PAGES_PER_HPAGE(level) - 1);} else    level = PT_PAGE_TABLE_LEVEL;//顾名思义，快速处理一个简单的page fault//即present同时有写权限的非mmio page fault//参考page_fault_can_be_fast函数//一部分处理没有写权限的page fault//一部分处理 TLB lazy//fast_pf_fix_direct_spte也就是将pte获取的写权限if (fast_page_fault(vcpu, gpa, level, error_code))    return 0;//下面函数主要就一件事情，gfn_to_pfnif (try_async_pf(vcpu, prefault, gfn, gpa, &pfn, write, &map_writable))      return 0;//direct map就是映射ept页表的过程r = __direct_map(vcpu, gpa, write, map_writable,      level, gfn, pfn, prefault);</pre><p>在try_async_pf中就是gfn转换成hva，然后hva转换成pfn的过程，gfn转换到hva:</p><pre class="hljs objectivec">static pfn_t__gfn_to_pfn_memslot(struct kvm_memory_slot *slot, gfn_t gfn, bool atomic,             bool *async, bool write_fault, bool *writable){    unsigned long addr = __gfn_to_hva_many(slot, gfn, NULL, write_fault);    if (addr == KVM_HVA_ERR_RO_BAD)        return KVM_PFN_ERR_RO_FAULT;    if (kvm_is_error_hva(addr))        return KVM_PFN_NOSLOT;    /* Do not map writable pfn in the readonly memslot. */    if (writable && memslot_is_readonly(slot)) {        *writable = false;        writable = NULL;    }    return hva_to_pfn(addr, atomic, async, write_fault,              writable);}</pre><p>gfn2hva本质就是</p><pre class="hljs cpp">staticinline unsigned long__gfn_to_hva_memslot(struct kvm_memory_slot *slot, gfn_t gfn){    return slot->userspace_addr + (gfn - slot->base_gfn) * PAGE_SIZE;}</pre><p>而hva_to_pfn则就是host的线性区进行地址转换的问题了，不提。</p><pre class="hljs php">static int __direct_map(struct kvm_vcpu *vcpu, gpa_t v, int write,            int map_writable, int level, gfn_t gfn, pfn_t pfn,            bool prefault){    struct kvm_shadow_walk_iterator iterator;    struct kvm_mmu_page *sp;    int emulate = 0;    gfn_t pseudo_gfn;    if (!VALID_PAGE(vcpu->arch.mmu.root_hpa))        return0;//遍历ept四级页表    for_each_shadow_entry(vcpu, (u64)gfn << PAGE_SHIFT, iterator) {//如果是最后一级，level是hugepage下的level        if (iterator.level == level) {//设置pte，页表下一级的page地址就是pfn写入到pte            mmu_set_spte(vcpu, iterator.sptep, ACC_ALL,                     write, &emulate, level, gfn, pfn,                     prefault, map_writable);            direct_pte_prefetch(vcpu, iterator.sptep);            ++vcpu->stat.pf_fixed;            break;        }        drop_large_spte(vcpu, iterator.sptep);//mmu page不在位的情况，也就是缺页        if (!is_shadow_present_pte(*iterator.sptep)) {            u64 base_addr = iterator.addr;//获取指向的具体mmu page entry的index            base_addr &= PT64_LVL_ADDR_MASK(iterator.level);            pseudo_gfn = base_addr >> PAGE_SHIFT;//获取mmu page            sp = kvm_mmu_get_page(vcpu, pseudo_gfn, iterator.addr,                          iterator.level - 1,                          1, ACC_ALL, iterator.sptep);//将当前的mmu page的地址写入到上一级别mmu page的pte中            link_shadow_page(iterator.sptep, sp, true);        }    }    return emulate;}static struct kvm_mmu_page *kvm_mmu_get_page(struct kvm_vcpu *vcpu,                         gfn_t gfn,                         gva_t gaddr,                         unsigned level,                         int direct,                         unsigned access,                         u64 *parent_pte){    union kvm_mmu_page_role role;    unsigned quadrant;    struct kvm_mmu_page *sp;    bool need_sync = false;    role = vcpu->arch.mmu.base_role;    role.level = level;    role.direct = direct;    if (role.direct)        role.cr4_pae = 0;    role.access = access;    if (!vcpu->arch.mmu.direct_map        && vcpu->arch.mmu.root_level <= pt32_root_level)="" {="" quadrant="gaddr">> (PAGE_SHIFT + (PT64_PT_BITS * level));        quadrant &= (1 << ((PT32_PT_BITS - PT64_PT_BITS) * level)) - 1;        role.quadrant = quadrant;    }//根据一个hash索引来的    for_each_gfn_sp(vcpu->kvm, sp, gfn) {//检查整个mmu ept是否被失效了        if (is_obsolete_sp(vcpu->kvm, sp))            continue;        if (!need_sync && sp->unsync)            need_sync = true;        if (sp->role.word != role.word)            continue;        if (sp->unsync && kvm_sync_page_transient(vcpu, sp))            break;        mmu_page_add_parent_pte(vcpu, sp, parent_pte);        if (sp->unsync_children) {            kvm_make_request(KVM_REQ_MMU_SYNC, vcpu);            kvm_mmu_mark_parents_unsync(sp);        } else if (sp->unsync)            kvm_mmu_mark_parents_unsync(sp);        __clear_sp_write_flooding_count(sp);        trace_kvm_mmu_get_page(sp, false);        return sp;    }    ++vcpu->kvm->stat.mmu_cache_miss;    sp = kvm_mmu_alloc_page(vcpu, parent_pte, direct);    if (!sp)        return sp;    sp->gfn = gfn;    sp->role = role;//新的mmu page加入hash索引，所以前面的for循环中才能知道gfn对应的mmu有没有//被分配    hlist_add_head(&sp->hash_link,        &vcpu->kvm->arch.mmu_page_hash[kvm_page_table_hashfn(gfn)]);    if (!direct) {        if (rmap_write_protect(vcpu->kvm, gfn))            kvm_flush_remote_tlbs(vcpu->kvm);        if (level > PT_PAGE_TABLE_LEVEL && need_sync)            kvm_sync_pages(vcpu, gfn);        account_shadowed(vcpu->kvm, gfn);    }    sp->mmu_valid_gen = vcpu->kvm->arch.mmu_valid_gen;    init_shadow_page_table(sp);    trace_kvm_mmu_get_page(sp, true);    return sp;}</=></pre><p>这样看每次缺页都会分配新的mmu page，虚拟机每次启动是根据guest不停的进行EXIT_REASON_EPT_VIOLATION，整个页表就建立起来了。</p>]]></content>
      
      
      <categories>
          
          <category> KVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KVM源代码分析3:CPU虚拟化</title>
      <link href="/2014/12/11/kvm-src-3-cpu/"/>
      <url>/2014/12/11/kvm-src-3-cpu/</url>
      
        <content type="html"><![CDATA[<p>在<a href="http://www.oenhan.com/kvm-src-2-vm-run" title="KVM源代码分析2:虚拟机的创建与运行" target="_blank" rel="noopener">虚拟机的创建与运行</a>章节里面笼统的介绍了KVM在qemu中的创建和运行，基本的qemu代码流程已经梳理清楚，后续主要写一些硬件虚拟化的原理和代码流程，主要写原理和qemu控制KVM运行的的ioctl接口，后续对内核代码的梳理也从这些接口下手。</p><p>QEMU：git://git.qemu.org/qemu.git v2.4.0</p><p>KVM：<a href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git</a> v4.2</p><h4 id="1-VT-x-技术"><a href="#1-VT-x-技术" class="headerlink" title="1.VT-x 技术"></a>1.VT-x 技术</h4><p>Intel处理器支持的虚拟化技术即是VT-x，之所以CPU支持硬件虚拟化是因为软件虚拟化的效率太低。</p><p>处理器虚拟化的本质是分时共享，主要体现在状态恢复和资源隔离，实际上每个VM对于VMM看就是一个task么，之前Intel处理器在虚拟化上没有提供默认的硬件支持，传统 x86 处理器有4个特权级，Linux使用了0,3级别，0即内核，3即用户态，（更多参考<a href="http://blog.csdn.net/drshenlei/article/details/4265101" target="_blank" rel="noopener">CPU的运行环、特权级与保护</a>）而在虚拟化架构上，虚拟机监控器的运行级别需要内核态特权级，而CPU特权级被传统OS占用，所以Intel设计了VT-x，提出了VMX模式，即VMX root operation 和 VMX non-root operation，虚拟机监控器运行在VMX root operation，虚拟机运行在VMX non-root operation。每个模式下都有相对应的0~3特权级。</p><p>为什么引入这两种特殊模式，在传统x86的系统中，CPU有不同的特权级，是为了划分不同的权限指令，某些指令只能由系统软件操作，称为特权指令，这些指令只能在最高特权级上才能正确执行，反之则会触发异常，处理器会陷入到最高特权级，由系统软件处理。还有一种需要操作特权资源（如访问<a href="http://www.oenhan.com/rwsem-realtime-task-hung" title="读写信号量与实时进程阻塞挂死问题" target="_blank" rel="noopener">中断寄存器</a>）的指令，称为敏感指令。OS运行在特权级上，屏蔽掉用户态直接执行的特权指令，达到控制所有的硬件资源目的；而在虚拟化环境中，VMM控制所有所有硬件资源，VM中的OS只能占用一部分资源，OS执行的很多特权指令是不能真正对硬件生效的，所以原特权级下有了root模式，OS指令不需要修改就可以正常执行在特权级上，但这个特权级的所有敏感指令都会传递到root模式处理，这样达到了VMM的目的。</p><p>在<a href="http://www.oenhan.com/kvm-src-1" target="_blank" rel="noopener">KVM源代码分析1:基本工作原理</a>章节中也说了kvm分3个模式，对应到VT-x 中即是客户模式对应vmx非root模式，内核模式对应VMX root模式下的0特权级，用户模式对应vmx root模式下的3特权级。</p><p>如下图<br><img src="/2014/12/11/kvm-src-3-cpu/kvm_vmx_intel-1.jpg" alt=""></p><p>在非根模式下敏感指令引发的陷入称为VM-Exit，VM-Exit发生后，CPU从非根模式切换到根模式；对应的，VM-Entry则是从根模式到非根模式，通常意味着调用VM进入运行态。VMLAUCH/VMRESUME命令则是用来发起VM-Entry。</p><h4 id="2-VMCS寄存器"><a href="#2-VMCS寄存器" class="headerlink" title="2.VMCS寄存器"></a>2.VMCS寄存器</h4><p>VMCS保存虚拟机的相关CPU状态，每个VCPU都有一个VMCS（内存的），每个物理CPU都有VMCS对应的<a href="http://www.oenhan.com/gdb-principle" title="gdb工作原理和内核实现" target="_blank" rel="noopener">寄存器</a>（物理的），当CPU发生VM-Entry时，CPU则从VCPU指定的内存中读取VMCS加载到物理CPU上执行，当发生VM-Exit时，CPU则将当前的CPU状态保存到VCPU指定的内存中，即VMCS，以备下次VMRESUME。</p><p>VMLAUCH指VM的第一次VM-Entry，VMRESUME则是VMLAUCH之后后续的VM-Entry。VMCS下有一些控制域：</p><p><colgroup></colgroup></p><p><col width="51*"></p><p><col width="51*"></p><p><col width="51*"></p><p><col width="51*"></p><p><col width="51*"> <br>col 1                  | col 2                                                    | col 3<br>———————- | ——————————————————– | —————————————————————–<br> VM-execution controls |  Determines what operations cause VM exits               |  CR0, CR3, CR4, Exceptions, IO Ports, Interrupts, Pin Events, etc<br>Guest-state area       |  Saved on VM exits，Reloaded on VM entry                  |  EIP, ESP, EFLAGS, IDTR, Segment Regs, Exit info, etc<br> Host-state area       |  Loaded on VM exits                                      |  CR3, EIP set to monitor entry point, EFLAGS hardcoded, etc<br> VM-exit controls      |  Determines which state to save, load, how to transition |  Example: MSR save-load list<br> VM-entry controls     |  Determines which state to load, how to transition       |  Including injecting events (interrupts, exceptions) on entry    </p><p>关于具体控制域的细节，还是翻Intel手册吧。</p><h4 id="3-VM-Entry-VM-Exit"><a href="#3-VM-Entry-VM-Exit" class="headerlink" title="3.VM-Entry/VM-Exit"></a>3.VM-Entry/VM-Exit</h4><p>VM-Entry是从根模式切换到非根模式，即VMM切换到guest上，这个状态由VMM发起，发起之前先保存VMM中的关键寄存器内容到VMCS中，然后进入到VM-Entry，VM-Entry附带参数主要有3个：1.guest是否处于64bit模式，2.MSR VM-Entry控制，3.注入事件。1应该只在VMLAUCH有意义，3更多是在VMRESUME，而VMM发起VM-Entry更多是因为3，2主要用来每次更新MSR。</p><p>VM-Exit是CPU从非根模式切换到根模式，从guest切换到VMM的操作，VM-Exit触发的原因就很多了，执行敏感指令，<a href="http://www.oenhan.com/rwsem-realtime-task-hung" title="读写信号量与实时进程阻塞挂死问题" target="_blank" rel="noopener">发生中断</a>，模拟特权资源等。</p><p>运行在非根模式下的敏感指令一般分为3个方面：</p><p>1.行为没有变化的，也就是说该指令能够正确执行。</p><p>2.行为有变化的，直接产生VM-Exit。</p><p>3.行为有变化的，但是是否产生VM-Exit受到VM-Execution控制域控制。</p><p>主要说一下”受到VM-Execution控制域控制”的敏感指令，这个就是针对性的硬件优化了，一般是1.产生VM-Exit；2.不产生VM-Exit，同时调用优化函数完成功能。典型的有“RDTSC指令”。除了大部分是优化性能的，还有一小部分是直接VM-Exit执行指令结果是异常的，或者说在<a href="http://www.oenhan.com/kvm-src-1" title="KVM源代码分析1:基本工作原理" target="_blank" rel="noopener">虚拟化</a>场景下是不适用的，典型的就是TSC offset了。</p><p>VM-Exit发生时退出的相关信息，如退出原因、触发中断等，这些内容保存在VM-Exit信息域中。</p><h4 id="4-KVM-CREATE-VM"><a href="#4-KVM-CREATE-VM" class="headerlink" title="4.KVM_CREATE_VM"></a>4.KVM_CREATE_VM</h4><p>创建VM就写这里吧，kvm_dev_ioctl_create_vm函数是主干，在kvm_create_vm中，主要有两个函数，kvm_arch_init_vm和hardware_enable_all，需要注意，但是更先一步的是KVM结构体，下面的struct是精简后的版本。</p><pre class="lang:c decode:1 hljs cpp">struct kvm {    struct mm_struct *mm; /* userspace tied to this vm */    struct kvm_memslots *memslots;  /*qemu模拟的内存条模型*/    struct kvm_vcpu *vcpus[KVM_MAX_VCPUS]; /* 模拟的CPU */    atomic_t online_vcpus;    int last_boosted_vcpu;    struct list_head vm_list;  //HOST上VM管理链表，    struct kvm_io_bus *buses[KVM_NR_BUSES];    struct kvm_vm_stat stat;    struct kvm_arch arch; //这个是host的arch的一些参数    atomic_t users_count;    long tlbs_dirty;    struct list_head devices;};</pre><p>kvm_arch_init_vm基本没有特别动作，初始化了KVM-&gt;arch，以及更新了kvmclock函数，这个另外再说。<br>而hardware_enable_all，针对于每个CPU执行“on_each_cpu(hardware_enable_nolock, NULL, 1）”，在hardware_enable_nolock中先把cpus_hardware_enabled置位，进入到kvm_arch_hardware_enable中，有hardware_enable和TSC初始化规则，主要看hardware_enable，crash_enable_local_vmclear清理<a href="http://www.oenhan.com/reiserfs_check_can_fit_pages_for_8tb" title="reiserfs分区空闲8TB写文件提示磁盘空间不足" target="_blank" rel="noopener">位图</a>，判断MSR_IA32_FEATURE_CONTROL寄存器是否满足虚拟环境，不满足则将条件写入到寄存器内，CR4将X86_CR4_VMXE置位，另外还有kvm_cpu_vmxon打开VMX操作模式，外层包了vmm_exclusive的判断，它是kvm_intel.ko的外置参数，默认唯一，可以让用户强制不使用VMM硬件支持。</p><h4 id="5-KVM-CREATE-VCPU"><a href="#5-KVM-CREATE-VCPU" class="headerlink" title="5.KVM_CREATE_VCPU"></a>5.KVM_CREATE_VCPU</h4><p>kvm_vm_ioctl_create_vcpu主要有三部分，kvm_arch_vcpu_create，kvm_arch_vcpu_setup和kvm_arch_vcpu_postcreate，重点自然是kvm_arch_vcpu_create。老样子，在这之前先看一下VCPU的结构体。</p><pre class="lang:c decode:1 hljs cpp">struct kvm_vcpu {    struct kvm *kvm;  //归属的KVM\#ifdef CONFIG_PREEMPT_NOTIFIERSstruct preempt_notifier preempt_notifier;\#endif    int cpu;    int vcpu_id;    int srcu_idx;    int mode;    unsigned long requests;    unsigned long guest_debug;    struct mutex mutex;    struct kvm_run *run;  //运行时的状态    int fpu_active;    int guest_fpu_loaded, guest_xcr0_loaded;    wait_queue_head_t wq; //队列    struct pid *pid;    int sigset_active;    sigset_t sigset;    struct kvm_vcpu_stat stat; //一些数据\#ifdef CONFIG_HAS_IOMEM    int mmio_needed;    int mmio_read_completed;    int mmio_is_write;    int mmio_cur_fragment;    int mmio_nr_fragments;    struct kvm_mmio_fragment mmio_fragments[KVM_MAX_MMIO_FRAGMENTS];\#endif\#ifdef CONFIG_KVM_ASYNC_PF    struct {        u32 queued;        struct list_head queue;        struct list_head done;        spinlock_t lock;    } async_pf;\#endif\#ifdef CONFIG_HAVE_KVM_CPU_RELAX_INTERCEPT    /*     \* Cpu relax intercept or pause loop exit optimization     \* in_spin_loop: set when a vcpu does a pause loop exit     \*  or cpu relax intercepted.     \* dy_eligible: indicates whether vcpu is eligible for directed yield.     \*/    struct {        bool in_spin_loop;        bool dy_eligible;    } spin_loop;\#endif    bool preempted;    struct kvm_vcpu_arch arch;  //当前VCPU虚拟的架构，默认介绍X86};</pre><p>借着看kvm_arch_vcpu_create，它借助kvm_x86_ops-&gt;vcpu_create即vmx_create_vcpu完成任务，vmx是X86硬件虚拟化层，从代码看，qemu用户态是一层，kernel 中KVM通用代码是一层，类似kvm_x86_ops是一层，针对各个不同硬件架构，而vcpu_vmx则是具体架构的虚拟化方案一层。首先是kvm_vcpu_init初始化，主要是填充结构体，可以注意的是vcpu-&gt;run分派了一页内存，下面有kvm_arch_vcpu_init负责填充x86 CPU结构体，下面就是kvm_vcpu_arch：</p><pre class="lang:c decode:1 hljs cpp">struct kvm_vcpu_arch {    /*     \* rip and regs accesses must go through     \* kvm_{register,rip}_{read,write} functions.     \*/unsignedlong regs[NR_VCPU_REGS];    u32 regs_avail;    u32 regs_dirty;//类似这些寄存器就是就是用来缓存真正的CPU值的unsignedlong cr0;    unsignedlong cr0_guest_owned_bits;    unsignedlong cr2;    unsignedlong cr3;    unsigned long cr4;    unsigned long cr4_guest_owned_bits;    unsigned long cr8;    u32 hflags;    u64 efer;    u64 apic_base;    struct kvm_lapic *apic;    /* kernel irqchip context */    unsigned long apic_attention;    int32_t apic_arb_prio;    int mp_state;    u64 ia32_misc_enable_msr;    bool tpr_access_reporting;    u64 ia32_xss;    /*     \* Paging state of the vcpu     \*     \* If the vcpu runs in guest mode with two level paging this still saves     \* the paging mode of the l1 guest. This context is always used to     \* handle faults.     \*/    struct kvm_mmu mmu; //内存管理，更多的是附带了直接操作函数    /*     \* Paging state of an L2 guest (used for nested npt)     \*     \* This context will save all necessary information to walk page tables     \* of the an L2 guest. This context is only initialized for page table     \* walking and not for faulting since we never handle l2 page faults on     \* the host.     \*/    struct kvm_mmu nested_mmu;    /*     \* Pointer to the mmu context currently used for     \* gva_to_gpa translations.     \*/    struct kvm_mmu *walk_mmu;    struct kvm_mmu_memory_cache mmu_pte_list_desc_cache;    struct kvm_mmu_memory_cache mmu_page_cache;    struct kvm_mmu_memory_cache mmu_page_header_cache;    struct fpu guest_fpu;    u64 xcr0;    u64 guest_supported_xcr0;    u32 guest_xstate_size;    struct kvm_pio_request pio;    void *pio_data;    u8 event_exit_inst_len;    struct kvm_queued_exception {        bool pending;        bool has_error_code;        bool reinject;        u8 nr;        u32 error_code;    } exception;    struct kvm_queued_interrupt {        bool pending;        bool soft;        u8 nr;    } interrupt;    int halt_request; /* real mode on Intel only */    int cpuid_nent;    struct kvm_cpuid_entry2 cpuid_entries[KVM_MAX_CPUID_ENTRIES];    int maxphyaddr;    /* emulate context *///下面是KVM的软件模拟模式，也就是没有vmx的情况，估计也没人用这一套    struct x86_emulate_ctxt emulate_ctxt;    bool emulate_regs_need_sync_to_vcpu;    bool emulate_regs_need_sync_from_vcpu;    int (*complete_userspace_io)(struct kvm_vcpu *vcpu);    gpa_t time;    struct pvclock_vcpu_time_info hv_clock;    unsigned int hw_tsc_khz;    struct gfn_to_hva_cache pv_time;    bool pv_time_enabled;    /* set guest stopped flag in pvclock flags field */    bool pvclock_set_guest_stopped_request;    struct {        u64 msr_val;        u64 last_steal;        u64 accum_steal;        struct gfn_to_hva_cache stime;        struct kvm_steal_time steal;    } st;    u64 last_guest_tsc;    u64 last_host_tsc;    u64 tsc_offset_adjustment;    u64 this_tsc_nsec;    u64 this_tsc_write;    u64 this_tsc_generation;    bool tsc_catchup;    bool tsc_always_catchup;    s8 virtual_tsc_shift;    u32 virtual_tsc_mult;    u32 virtual_tsc_khz;    s64 ia32_tsc_adjust_msr;    atomic_t nmi_queued;  /* unprocessed asynchronous NMIs */    unsigned nmi_pending; /* NMI queued after currently running handler */    bool nmi_injected;    /* Trying to inject an NMI this entry */    struct mtrr_state_type mtrr_state;    u64 pat;    unsigned switch_db_regs;    unsigned long db[KVM_NR_DB_REGS];    unsigned long dr6;    unsigned long dr7;    unsigned long eff_db[KVM_NR_DB_REGS];    unsigned long guest_debug_dr7;    u64 mcg_cap;    u64 mcg_status;    u64 mcg_ctl;    u64 *mce_banks;    /* Cache MMIO info */    u64 mmio_gva;    unsigned access;    gfn_t mmio_gfn;    u64 mmio_gen;    struct kvm_pmu pmu;    /* used for guest single stepping over the given code position */    unsigned long singlestep_rip;    /* fields used by HYPER-V emulation */    u64 hv_vapic;    cpumask_var_t wbinvd_dirty_mask;    unsigned long last_retry_eip;    unsigned long last_retry_addr;    struct {        bool halted;        gfn_t gfns[roundup_pow_of_two(ASYNC_PF_PER_VCPU)];        struct gfn_to_hva_cache data;        u64 msr_val;        u32 id;        bool send_user_only;    } apf;    /* OSVW MSRs (AMD only) */    struct {        u64 length;        u64 status;    } osvw;    struct {        u64 msr_val;        struct gfn_to_hva_cache data;    } pv_eoi;    /*     \* Indicate whether the access faults on its page table in guest     \* which is set when fix page fault and used to detect unhandeable     \* instruction.     \*/    bool write_fault_to_shadow_pgtable;    /* set at EPT violation at this point */    unsigned long exit_qualification;    /* pv related host specific info */    struct {        bool pv_unhalted;    } pv;};</pre><p>整个arch结构真是长，很适合凑篇幅，很多结构其他过程涉及到的再提吧，反正我也不知道。<br>kvm_arch_vcpu_init初始化了x86在虚拟化底层的实现函数，首先是pv和emulate_ctxt，这些不支持VMX下的模拟虚拟化，尤其是vcpu-&gt;arch.emulate_ctxt.ops = &amp;emulate_ops，emulate_ops初始化虚拟化模拟的对象函数。</p><pre class="lang:c decode:1 hljs bash">static struct x86_emulate_ops emulate_ops = {    .read_std            = kvm_read_guest_virt_system,    .write_std           = kvm_write_guest_virt_system,    .fetch               = kvm_fetch_guest_virt,    .read_emulated       = emulator_read_emulated,    .write_emulated      = emulator_write_emulated,    .cmpxchg_emulated    = emulator_cmpxchg_emulated,    .invlpg              = emulator_invlpg,    .pio_in_emulated     = emulator_pio_in_emulated,    .pio_out_emulated    = emulator_pio_out_emulated,    .get_segment         = emulator_get_segment,    .set_segment         = emulator_set_segment,    .get_cached_segment_base = emulator_get_cached_segment_base,    .get_gdt             = emulator_get_gdt,    .get_idt         = emulator_get_idt,    .set_gdt             = emulator_set_gdt,    .set_idt         = emulator_set_idt,    .get_cr              = emulator_get_cr,    .set_cr              = emulator_set_cr,    .cpl                 = emulator_get_cpl,    .get_dr              = emulator_get_dr,    .set_dr              = emulator_set_dr,    .set_msr             = emulator_set_msr,    .get_msr             = emulator_get_msr,    .halt                = emulator_halt,    .wbinvd              = emulator_wbinvd,    .fix_hypercall       = emulator_fix_hypercall,    .get_fpu             = emulator_get_fpu,    .put_fpu             = emulator_put_fpu,    .intercept           = emulator_intercept,    .get_cpuid           = emulator_get_cpuid,};</pre><p>x86_emulate_ops函数看看就好，实际上也很少有人放弃vmx直接软件模拟。后面又有mp_state，给pio_data分配了一个page，kvm_set_tsc_khz设置TSC，kvm_mmu_create则是初始化MMU的函数，里面的函数都是地址转换的重点，在内存虚拟化重点提到。kvm_create_lapic初始化lapic，初始化mce_banks结构，还有pv_time,xcr0,xstat,pmu等，类似x86硬件结构上需要存在的，OS底层需要看到的硬件名称都要有对应的软件结构。<br>回到vmx_create_vcpu，vmx的guest_msrs分配得到一个page，后面是vmcs的分配，vmx-&gt;loaded_vmcs-&gt;vmcs = alloc_vmcs()，alloc_vmcs为当前cpu执行alloc_vmcs_cpu，alloc_vmcs_cpu中alloc_pages_exact_node分配给vmcs，alloc_pages_exact_node调用__alloc_pages实现，原来以为vmcs占用了一个page，但此处从<a href="http://www.oenhan.com/size-512-slab-kmalloc" title="从size-512内存泄露看slab分配" target="_blank" rel="noopener">伙伴系统</a>申请了2^vmcs_config.order页，此处vmcs_config在setup_vmcs_config中初始化，vmcs_conf-&gt;order = get_order(vmcs_config.size)，而vmcs_conf-&gt;size = vmx_msr_high &amp; 0x1fff，又rdmsr(MSR_IA32_VMX_BASIC, vmx_msr_low, vmx_msr_high)，此处size由于与0x1fff与运算，大小必然小于4k，order则为0，然来绕去还是一个page大小。这么做估计是为了兼容vmcs_config中的size计算。<br>下面根据vmm_exclusive进行kvm_cpu_vmxon，进入vmx模式，初始化loaded_vmcs，然后用kvm_cpu_vmxoff退出vmx模式。<br>vmx_vcpu_load加载VCPU的信息，切换到指定cpu，进入到vmx模式，将loaded_vmcs的vmcs和当前cpu的vmcs绑定到一起。vmx_vcpu_setup则是初始化vmcs内容，主要是赋值计算，下面的vmx_vcpu_put则是vmx_vcpu_load的反运算。下面还有一些apic，nested，pml就不说了。<br>vmx_create_vcpu结束就直接回到kvm_vm_ioctl_create_vcpu函数，下面是kvm_arch_vcpu_setup，整个就一条线到kvm_arch_vcpu_load函数，主要有kvm_x86_ops-&gt;vcpu_load(vcpu, cpu)和tsc处理，vcpu_load就是vmx_vcpu_load，刚说了，就是进入vcpu模式下准备工作。<br>kvm_arch_vcpu_setup后面是create_vcpu_fd为proc创建控制fd，让qemu使用。kvm_arch_vcpu_postcreate则是马后炮般，重新vcpu_load，写msr，tsc。<br>如此整个vcpu就创建完成了。</p><p>6.KVM_RUN</p><p>KVM run涉及内容也不少，先写完内存虚拟化之后再开篇专门写RUN流程。</p><p>下一篇：</p><p><a href="http://www.oenhan.com/kvm-src-4-mem" target="_blank" rel="noopener">KVM源代码分析4:内存虚拟化</a></p><p>———-完———-</p><p>——————–下面未编辑的留存————————————-<br>给vmcs分配空间并初始化，在alloc_vmcs_cpu分配一个<a href="http://www.oenhan.com/linux-kernel-khugepaged" title="hugepage内存管理机制" target="_blank" rel="noopener">页大小内存</a>，用来保存vm和vmm信息。</p><pre class="lang:c decode:1 hljs php">    vmx->vmcs = alloc_vmcs();    if (!vmx->vmcs)        goto free_msrs;    vmcs_init(vmx->vmcs);</pre><p>执行vm entry的时候将vmm状态保存到vmcs的host area，并加载对应vm的vmcs guest area信息到CPU中，vm exit的时候则反之，vmcs具体结构分配由硬件实现，程序员只需要通过VMWRITE和VMREAD指令去访问。</p><p>vmx执行完后，回到kvm_vm_ioctl_create_vcpu函数。kvm_arch_vcpu_reset对vcpu的结构进行初始化，后面一些就是检查vcpu的合法性，最后和kvm串接到一起。</p><p>vcpu的创建到此结束，下面说一下vcpu的运行。</p><p>VCPU一旦创建成功，后续的控制基本上从kvm_vcpu_ioctl开始，控制开关有KVM_RUN，KVM_GET_REGS，KVM_SET_REGS，KVM_GET_SREGS，KVM_SET_SREGS，KVM_GET_MP_STATE，KVM_SET_MP_STATE，KVM_TRANSLATE，KVM_SET_GUEST_DEBUG，KVM_SET_SIGNAL_MASK等，如果不清楚具体开关作用，可以直接到qemu搜索对应开关代码，一目了然。</p><p>KVM_RUN的实现函数是kvm_arch_vcpu_ioctl_run，进行安全检查之后进入__vcpu_run中，在while循环里面调用vcpu_enter_guest进入guest模式，首先处理vcpu-&gt;requests，对应的request做处理，kvm_mmu_reload加载mmu，通过kvm_x86_ops-&gt;prepare_guest_switch(vcpu)准备陷入到guest，prepare_guest_switch实现是vmx_save_host_state，顾名思义，就是保存host的当前状态。</p><pre class="lang:c decode:1 hljs php">kvm_x86_ops->prepare_guest_switch(vcpu);    if (vcpu->fpu_active)        kvm_load_guest_fpu(vcpu);    kvm_load_guest_xcr0(vcpu);    vcpu->mode = IN_GUEST_MODE;    /* We should set ->mode before check ->requests,     \* see the comment in make_all_cpus_request.     \*/    smp_mb();    local_irq_disable();</pre><p>然后加载guest的寄存器等信息，fpu，xcr0,将vcpu模式设置为guest状态，屏蔽中断响应，准备进入guest。但仍进行一次检查，vcpu-&gt;mode和vcpu-&gt;requests等，如果有问题，则恢复host状态。</p><p>kvm_guest_enter做了两件事：account_system_vtime计算虚拟机<a href="http://www.oenhan.com/glibc_pthread_cond_timedwait_disable" title="Glibc更新导致pthread_cond_timedwait失效" target="_blank" rel="noopener">系统时间</a>；rcu_virt_note_context_switch对rcu锁数据进行保护，完成上下文切换。</p><p>准备工作搞定，kvm_x86_ops-&gt;run(vcpu)，开始运行guest，由vmx_vcpu_run实现。</p><pre class="lang:c decode:1 hljs php">if (vmx->emulation_required && emulate_invalid_guest_state)        return;    if (test_bit(VCPU_REGS_RSP, (unsigned long *)&vcpu->arch.regs_dirty))        vmcs_writel(GUEST_RSP, vcpu->arch.regs[VCPU_REGS_RSP]);    if (test_bit(VCPU_REGS_RIP, (unsigned long *)&vcpu->arch.regs_dirty))        vmcs_writel(GUEST_RIP, vcpu->arch.regs[VCPU_REGS_RIP]);</pre><p>判断模拟器，RSP，RIP寄存器值。</p><p>主要功能在这段内联汇编上</p><pre class="lang:c decode:1 hljs cpp">asm(                /* Store host registers */        "push %%"R"dx; push %%"R"bp;"        "push %%"R"cx nt" /* placeholder for guest rcx */        "push %%"R"cx nt"//如果vcpu host rsp和环境不等，则将其拷贝到vpu上        "cmp %%"R"sp, %c[host_rsp](%0) nt""je 1f nt""mov %%"R"sp, %c[host_rsp](%0) nt"        __ex(ASM_VMX_VMWRITE_RSP_RDX) "nt"//__kvm_handle_fault_on_reboot write host rsp"1: nt"/* Reload cr2 if changed */        "mov %c[cr2](%0), %%"R"ax nt"        "mov %%cr2, %%"R"dx nt"                //环境上cr2值和vpu上的值不同，则将vpu上值拷贝到环境上        "cmp %%"R"ax, %%"R"dx nt"        "je 2f nt"        "mov %%"R"ax, %%cr2 nt"        "2: nt"        /* Check if vmlaunch of vmresume is needed */        "cmpl $0, %c[launched](%0) nt"        /* Load guest registers.  Don't clobber flags. */        "mov %c[rax](%0), %%"R"ax nt"        "mov %c[rbx](%0), %%"R"bx nt"        "mov %c[rdx](%0), %%"R"dx nt"        "mov %c[rsi](%0), %%"R"si nt"        "mov %c[rdi](%0), %%"R"di nt"        "mov %c[rbp](%0), %%"R"bp nt"\#ifdef CONFIG_X86_64        "mov %c[r8](%0),  %%r8  nt"        "mov %c[r9](%0),  %%r9  nt"        "mov %c[r10](%0), %%r10 nt"        "mov %c[r11](%0), %%r11 nt"        "mov %c[r12](%0), %%r12 nt"        "mov %c[r13](%0), %%r13 nt"        "mov %c[r14](%0), %%r14 nt"        "mov %c[r15](%0), %%r15 nt"\#endif        "mov %c[rcx](%0), %%"R"cx nt" /* kills %0 (ecx) */        /* Enter guest mode */                //此处和cmpl $0, %c[launched](%0)是对应的，此处选择进入guest的两种模式                //RESUME和LAUNCH，通过__ex  __kvm_handle_fault_on_reboot执行        "jne .Llaunched nt"        __ex(ASM_VMX_VMLAUNCH) "nt"        "jmp .Lkvm_vmx_return nt"        ".Llaunched: " __ex(ASM_VMX_VMRESUME) "nt"                 //退出vmx，保存guest信息，加载host信息        ".Lkvm_vmx_return: "        /* Save guest registers, load host registers, keep flags */        "mov %0, %c[wordsize](%%"R"sp) nt"        "pop %0 nt"        "mov %%"R"ax, %c[rax](%0) nt"        "mov %%"R"bx, %c[rbx](%0) nt"        "pop"Q" %c[rcx](%0) nt"        "mov %%"R"dx, %c[rdx](%0) nt"        "mov %%"R"si, %c[rsi](%0) nt"        "mov %%"R"di, %c[rdi](%0) nt"        "mov %%"R"bp, %c[rbp](%0) nt"\#ifdef CONFIG_X86_64        "mov %%r8,  %c[r8](%0) nt"        "mov %%r9,  %c[r9](%0) nt"        "mov %%r10, %c[r10](%0) nt"        "mov %%r11, %c[r11](%0) nt"        "mov %%r12, %c[r12](%0) nt"        "mov %%r13, %c[r13](%0) nt"        "mov %%r14, %c[r14](%0) nt"        "mov %%r15, %c[r15](%0) nt"\#endif        "mov %%cr2, %%"R"ax   nt"        "mov %%"R"ax, %c[cr2](%0) nt"        "pop  %%"R"bp; pop  %%"R"dx nt"        "setbe %c[fail](%0) nt"          : : "c"(vmx), "d"((unsigned long)HOST_RSP),//下面加了前面寄存器的指针值，对应具体结构的值        [launched]"i"(offsetof(struct vcpu_vmx, launched)),        [fail]"i"(offsetof(struct vcpu_vmx, fail)),        [host_rsp]"i"(offsetof(struct vcpu_vmx, host_rsp)),        [rax]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_RAX])),        [rbx]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_RBX])),        [rcx]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_RCX])),        [rdx]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_RDX])),        [rsi]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_RSI])),        [rdi]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_RDI])),        [rbp]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_RBP])),\#ifdef CONFIG_X86_64        [r8]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_R8])),        [r9]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_R9])),        [r10]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_R10])),        [r11]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_R11])),        [r12]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_R12])),        [r13]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_R13])),        [r14]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_R14])),        [r15]"i"(offsetof(struct vcpu_vmx, vcpu.arch.regs[VCPU_REGS_R15])),\#endif        [cr2]"i"(offsetof(struct vcpu_vmx, vcpu.arch.cr2)),        [wordsize]"i"(sizeof(ulong))          : "cc", "memory"        , R"ax", R"bx", R"di", R"si"\#ifdef CONFIG_X86_64        , "r8", "r9", "r10", "r11", "r12", "r13", "r14", "r15"\#endif</pre><p>以上代码相对容易理解的，根据注释大致清楚了具体作用。</p><p>然后就是恢复系统NMI等中断:</p><pre class="lang:c decode:1 hljs bash">vmx_complete_atomic_exit(vmx);vmx_recover_nmi_blocking(vmx);vmx_complete_interrupts(vmx);</pre><p>回到vcpu_enter_guest，通过hw_breakpoint_restore恢复<a href="http://www.oenhan.com/jprobe-hw-breakpoint" title="内核调试方法:Jprobe与硬件断点" target="_blank" rel="noopener">硬件断点</a>。</p><pre class="lang:c decode:1 hljs php">if (hw_breakpoint_active())        hw_breakpoint_restore();    kvm_get_msr(vcpu, MSR_IA32_TSC, &vcpu->arch.last_guest_tsc);//设置vcpu模式，恢复host相关内容    vcpu->mode = OUTSIDE_GUEST_MODE;    smp_wmb();    local_irq_enable();    ++vcpu->stat.exits;    /*     \* We must have an instruction between local_irq_enable() and     \* kvm_guest_exit(), so the timer interrupt isn't delayed by     \* the interrupt shadow.  The stat.exits increment will do nicely.     \* But we need to prevent reordering, hence this barrier():     \*/    barrier();//刷新系统时间    kvm_guest_exit();    preempt_enable();    vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);    /*     \* Profile KVM exit RIPs:     \*/    if (unlikely(prof_on == KVM_PROFILING)) {        unsigned long rip = kvm_rip_read(vcpu);        profile_hit(KVM_PROFILING, (void *)rip);    }    kvm_lapic_sync_from_vapic(vcpu);//处理vmx退出    r = kvm_x86_ops->handle_exit(vcpu);</pre><p>handle_exit退出函数由vmx_handle_exit实现，主要设置vcpu-&gt;run-&gt;exit_reason，让外部感知退出原因，并对应处理。对于vpu而言，handle_exit只是意味着一个传统linux一个时间片的结束，后续的工作都是由handle完成的，handle_exit对应的函数集如下：</p><pre class="lang:c decode:1 hljs objectivec">staticint (*kvm_vmx_exit_handlers[])(struct kvm_vcpu *vcpu) = {    [EXIT_REASON_EXCEPTION_NMI]           = handle_exception,    [EXIT_REASON_EXTERNAL_INTERRUPT]      = handle_external_interrupt,    [EXIT_REASON_TRIPLE_FAULT]            = handle_triple_fault,    [EXIT_REASON_NMI_WINDOW]          = handle_nmi_window,    [EXIT_REASON_IO_INSTRUCTION]          = handle_io,    [EXIT_REASON_CR_ACCESS]               = handle_cr,    [EXIT_REASON_DR_ACCESS]               = handle_dr,    [EXIT_REASON_CPUID]                   = handle_cpuid,    [EXIT_REASON_MSR_READ]                = handle_rdmsr,    [EXIT_REASON_MSR_WRITE]               = handle_wrmsr,    [EXIT_REASON_PENDING_INTERRUPT]       = handle_interrupt_window,    [EXIT_REASON_HLT]                     = handle_halt,    [EXIT_REASON_INVD]              = handle_invd,    [EXIT_REASON_INVLPG]              = handle_invlpg,    [EXIT_REASON_VMCALL]                  = handle_vmcall,    [EXIT_REASON_VMCLEAR]                  = handle_vmx_insn,    [EXIT_REASON_VMLAUNCH]                = handle_vmx_insn,    [EXIT_REASON_VMPTRLD]                 = handle_vmx_insn,    [EXIT_REASON_VMPTRST]                 = handle_vmx_insn,    [EXIT_REASON_VMREAD]                  = handle_vmx_insn,    [EXIT_REASON_VMRESUME]                = handle_vmx_insn,    [EXIT_REASON_VMWRITE]                 = handle_vmx_insn,    [EXIT_REASON_VMOFF]                   = handle_vmx_insn,    [EXIT_REASON_VMON]                    = handle_vmx_insn,    [EXIT_REASON_TPR_BELOW_THRESHOLD]     = handle_tpr_below_threshold,    [EXIT_REASON_APIC_ACCESS]             = handle_apic_access,    [EXIT_REASON_WBINVD]                  = handle_wbinvd,    [EXIT_REASON_XSETBV]                  = handle_xsetbv,    [EXIT_REASON_TASK_SWITCH]             = handle_task_switch,    [EXIT_REASON_MCE_DURING_VMENTRY]      = handle_machine_check,    [EXIT_REASON_EPT_VIOLATION]          = handle_ept_violation,    [EXIT_REASON_EPT_MISCONFIG]           = handle_ept_misconfig,    [EXIT_REASON_PAUSE_INSTRUCTION]       = handle_pause,    [EXIT_REASON_MWAIT_INSTRUCTION]          = handle_invalid_op,    [EXIT_REASON_MONITOR_INSTRUCTION]     = handle_invalid_op,};</pre><p>有handle_task_switch进行<a href="http://www.oenhan.com/rwsem-realtime-task-hung" title="读写信号量与实时进程阻塞挂死问题" target="_blank" rel="noopener">任务切换</a>，handle_io处理qemu的外部模拟IO等，具体处理内容后面在写。</p><p>再次退回到__vcpu_run函数，在while (r &gt; 0)中，循环受vcpu_enter_guest返回值控制，只有运行异常的时候才退出循环，否则通过kvm_resched一直运行下去。</p><pre class="lang:c decode:1 hljs php">if (need_resched()) {            srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);            kvm_resched(vcpu);            vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);        }</pre><p>再退就到了kvm_arch_vcpu_ioctl_run函数，此时kvm run的执行也结束。</p><p>KVM cpu虚拟化的理解基本如上，涉及到的具体细节有时间后开篇另说。</p><p>KVM源代码分析未完待续</p>]]></content>
      
      
      <categories>
          
          <category> KVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KVM源代码分析2:虚拟机的创建与运行</title>
      <link href="/2014/12/11/kvm-src-2-vm-run/"/>
      <url>/2014/12/11/kvm-src-2-vm-run/</url>
      
        <content type="html"><![CDATA[<p>原文链接：<a href="http://oenhan.com/kvm-src-2-vm-run" target="_blank" rel="noopener">http://oenhan.com/kvm-src-2-vm-run</a></p><p>前段时间挖了一个坑，<a href="http://www.oenhan.com/kvm-src-1" target="_blank" rel="noopener">KVM源代码分析1:基本工作原理</a>，准备写一下kvm的代码机制，结果一直没时间填土，现在还一下旧账，争取能温故而知新。 基本原理里面提到kvm虚拟化由用户态程序Qemu和<a href="http://www.oenhan.com/size-512-slab-kmalloc" title="从size-512内存泄露看slab分配" target="_blank" rel="noopener">内核态驱动</a>kvm配合完成，qemu负责HOST用户态层面进程管理，IO处理等，KVM负责把qemu的部分指令在硬件上直接实现，从<a href="http://www.oenhan.com/sort-optimal-solution" title="比较排序的最优解" target="_blank" rel="noopener">虚拟机</a>的创建和运行上看，qemu的代码占了流程上的主要部分。下面的代码主要主要针对与qemu，KVM部分另外开篇再说。</p><p>代码：</p><p>QEMU：git://git.qemu.org/qemu.git v2.4.0</p><p>KVM：<a href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git" target="_blank" rel="noopener">https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git</a> v4.2</p><p>QEMU和KVM是通过IOCTL进行配合的，直接抓住这个线看有kvm_ioctl、kvm_vm_ioctl、kvm_vcpu_ioctl、kvm_device_ioctl等，他们还都在一个C文件里面。</p><p>使用kvm_ioctl很少了，直接看调用的代码，有KVM_GET_VCPU_MMAP_SIZE，KVM_CHECK_EXTENSION，KVM_GET_API_VERSION，KVM_CREATE_VM，KVM_GET_SUPPORTED_CPUID等等，需要记住只有KVM_CREATE_VM。</p><p>而调用kvm_vm_ioctl的函数真是海了去了，需要看的是KVM_SET_USER_MEMORY_REGION，KVM_CREATE_VCPU，KVM_CREATE_DEVICE。</p><p>所有寄存器的交换信息都是通过kvm_vcpu_ioctl，需要记住的操作只有，KVM_RUN。</p><p>所有看QEMU和KVM的配合流程如下：</p><p><img src="/2014/12/11/kvm-src-2-vm-run/qemu_create_kvm_vm-1.png" alt=""></p><p>接下来参考上图分析qemu代码流程： 从vl.c代码的main函数开始。 atexit(qemu_run_exit_notifiers)注册了qemu的退出<a href="http://www.oenhan.com/5w2h" title="5W2H:技术活动逻辑方法" target="_blank" rel="noopener">处理函数</a>，后面在具体看qemu_run_exit_notifiers函数。 module_call_init则开始初始化qemu的各个模块，陆陆续续的有以下参数：</p><pre class="lang:c decode:1 hljs cpp">typedef enum {    MODULE_INIT_BLOCK,    MODULE_INIT_MACHINE,    MODULE_INIT_QAPI,    MODULE_INIT_QOM,    MODULE_INIT_MAX} module_init_type;</pre><p>最开始初始化的MODULE_INIT_QOM，QOM是qemu实现的一种<a href="http://www.oenhan.com/ext3-jbd-journal" title="journal block device代码分析" target="_blank" rel="noopener">模拟设备</a>，具体可以参考<a href="http://wiki.qemu.org/Features/QOM，代码下面的不远处就MODULE_INIT_MACHINE的初始化，这两条语句放到一起看，直接说一下module_call_init的机制。" target="_blank" rel="noopener">http://wiki.qemu.org/Features/QOM，代码下面的不远处就MODULE_INIT_MACHINE的初始化，这两条语句放到一起看，直接说一下module_call_init的机制。</a> module_call_init实际设计的一个函数链表，ModuleTypeList ，链表关系如下图<br><img src="/2014/12/11/kvm-src-2-vm-run/qemu_module_init-1.png" alt=""></p><p>它把相关的函数注册到对应的数组链表上，通过执行init项目完成所有设备的初始化。module_call_init就是执行e-&gt;init()完成功能的，而e-&gt;init是什么时候通过register_module_init注册到ModuleTypeList上的ModuleEntry，是module_init注册的，而调用module_init的有</p><pre class="lang:c decode:1 hljs cpp">\#define block_init(function) module_init(function, MODULE_INIT_BLOCK)\#define machine_init(function) module_init(function, MODULE_INIT_MACHINE)\#define qapi_init(function) module_init(function, MODULE_INIT_QAPI)\#define type_init(function) module_init(function, MODULE_INIT_QOM)</pre><p>那么执行machine_init则是挂到了MODULE_INIT_MACHINE，type_init则将函数挂载了MODULE_INIT_QOM。那么排查一下是，我们只关注PC的注册，那么就是machine_init(pc_machine_init_##suffix)，源自DEFINE_PC_MACHINE(suffix, namestr, initfn, optsfn)宏，而DEFINE_I440FX_MACHINE有</p><pre class="lang:c decode:1 hljs cpp">\#define DEFINE_I440FX_MACHINE(suffix, name, compatfn, optionfn)staticvoid pc_init_\##suffix(MachineState *machine)    {        void (*compat)(MachineState *m) = (compatfn);        if (compat) {            compat(machine);        }        pc_init1(machine);    }    DEFINE_PC_MACHINE(suffix, name, pc_init_\##suffix, optionfn)\#define DEFINE_PC_MACHINE(suffix, namestr, initfn, optsfn)    static void pc_machine_\##suffix##_class_init(ObjectClass *oc, void *data)    {        MachineClass *mc = MACHINE_CLASS(oc);        optsfn(mc);        mc->name = namestr;        mc->init = initfn;    }    static const TypeInfo pc_machine_type_\##suffix = {        .name       = namestr TYPE_MACHINE_SUFFIX,        .parent     = TYPE_PC_MACHINE,        .class_init = pc_machine_\##suffix##_class_init,    };    static void pc_machine_init_\##suffix(void)    {        type_register(&pc_machine_type_\##suffix);    }    machine_init(pc_machine_init_\##suffix)</pre><p>DEFINE_PC_MACHINE注册的函数pc_init_##suffix在DEFINE_I440FX_MACHINE中定义，怎么组合都无关，pc_init1(machine)函数一定要执行，本质就是pc_init1赋值给了mc-&gt;init，其他爱看不看吧。<br>而module_init的宏是</p><pre class="lang:c decode:1 hljs cpp">\#define module_init(function, type)static void __attribute__((constructor)) do_qemu_init_ \## function(void){    register_dso_module_init(function, type);}\#else/* This should not be used directly.  Use block_init etc. instead.  */\#define module_init(function, type)static void __attribute__((constructor)) do_qemu_init_ \## function(void){    register_module_init(function, type);}</pre><p>它前面的修饰是<strong>attribute</strong>((constructor)),这个导致machine_init或者type_init等会在main()之前就被执行。所有type_init(kvm_type_init）-&gt; kvm_accel_type -&gt; kvm_accel_class_init -&gt; kvm_init依次完成了函数注册，所有说module_call_init(MODULE_INIT_QOM)函数已经完成了kvm_init的执行，所有这样就清楚KVM调用关系了。<br>如此就先去看kvm_init函数，前面主要干了一件事，填充KVMState *s结构体，然后通过kvm_ioctl(s, KVM_GET_API_VERSION, 0)判断内核KVM驱动和当前QEMU版本是否兼容，下面则是执行kvm_ioctl(s, KVM_CREATE_VM, type)进行虚拟机的创建活动，创建了KVM虚拟机，获取虚拟机<a href="http://www.oenhan.com/kernel-deadlock-check" title="Linux内核死锁检测机制" target="_blank" rel="noopener">句柄</a>。具体KVM_CREATE_VM在内核态做了什么，ioctl的工作等另外再说，现在假定KVM_CREATE_VM所代表的虚拟机创建成功，下面通过检查kvm_check_extension结果填充KVMState，kvm_arch_init初始化KVMState，其中有IDENTITY_MAP_ADDR，TSS_ADDR，NR_MMU_PAGES等，cpu_register_phys_memory_client注册qemu对<a href="http://www.oenhan.com/size-512-slab-kmalloc" title="从size-512内存泄露看slab分配" target="_blank" rel="noopener">内存管理</a>的函数集，kvm_create_irqchip创建kvm中断管理内容，通过kvm_vm_ioctl(s, KVM_CREATE_IRQCHIP)实现，具体内核态的工作内容后面分析。到此kvm_init的工作就完成了，最主要的工作就是创建的虚拟机。</p><p>这样绕了这么大圈，重新回到vl.c上面来，前面刚说了module_call_init(MODULE_INIT_MACHINE)本质就是把pc_init1赋值给了mc-&gt;init，然后machine_class = find_default_machine()，如此可以看到machine_class的init函数一定会执行pc_init1。</p><p>下面涉及对OPT入参的解析过程略过不提。 qemu准备<a href="http://www.oenhan.com/cgroups-src-1" title="Cgroups源码分析1:基本概念与框架" target="_blank" rel="noopener">模拟的机器</a>的类型从下面语句获得:</p><pre class="lang:c decode:1 hljs nginx">current_machine = MACHINE(object_new(object_class_get_name(                          OBJECT_CLASS(machine_class))));</pre><p>machine_class则是通过入参传入的</p><pre class="lang:c decode:1 hljs bash">case QEMU_OPTION_machine:                olist = qemu_find_opts("machine");                opts = qemu_opts_parse_noisily(olist, optarg, true);                if (!opts) {                    exit(1);                }                break;</pre><p>man qemu</p><pre class="lang:shell decode:1 hljs sql">       -machine [type=]name[,prop=value[,...]]           Select the emulated machine by name.           Use "-machine help" to list available machines</pre><p>下面有cpu_exec_init_all就是执行了qemu的内存结构体的初始化而已，cpudef_init则提供了VCPU的不同型号的模拟，qemu_set_log设置日志输出，kvm对外的日志是从这里配置的。中间的乱七八糟的就忽略掉即可，然后直接到了machine_class-&gt;init(current_machine)函数，其实就是执行了pc_init1。暂且记下来，先看下面的，cpu_synchronize_all_post_init就是内核和qemu数据不一致同步一下。下面的函数没有重要的了，只有vm_start()函数需要记一下，后面会用到。</p><p>现在进入pc_init1函数：</p><p>在pc_init1中重点看两个函数，pc_cpus_init和pc_memory_init，顾名思义，CPU和内存的初始化，中断，vga等函数的初始化先忽略掉，先看这两个。<br>pc_cpus_init入参是cpu_model，前面说过这是具体的CPU模型，所有X86的CPU模型都在builtin_x86_defs中定义，取其中一个看看</p><pre class="lang:c decode:1 hljs objectivec">    {        .name = "SandyBridge",        .level = 0xd,        .vendor = CPUID_VENDOR_INTEL,        .family = 6,        .model = 42,        .stepping = 1,        .features[FEAT_1_EDX] =            CPUID_VME | CPUID_SSE2 | CPUID_SSE | CPUID_FXSR | CPUID_MMX |            CPUID_CLFLUSH | CPUID_PSE36 | CPUID_PAT | CPUID_CMOV | CPUID_MCA |            CPUID_PGE | CPUID_MTRR | CPUID_SEP | CPUID_APIC | CPUID_CX8 |            CPUID_MCE | CPUID_PAE | CPUID_MSR | CPUID_TSC | CPUID_PSE |            CPUID_DE | CPUID_FP87,        .features[FEAT_1_ECX] =            CPUID_EXT_AVX | CPUID_EXT_XSAVE | CPUID_EXT_AES |            CPUID_EXT_TSC_DEADLINE_TIMER | CPUID_EXT_POPCNT |            CPUID_EXT_X2APIC | CPUID_EXT_SSE42 | CPUID_EXT_SSE41 |            CPUID_EXT_CX16 | CPUID_EXT_SSSE3 | CPUID_EXT_PCLMULQDQ |            CPUID_EXT_SSE3,        .features[FEAT_8000_0001_EDX] =            CPUID_EXT2_LM | CPUID_EXT2_RDTSCP | CPUID_EXT2_NX |            CPUID_EXT2_SYSCALL,        .features[FEAT_8000_0001_ECX] =            CPUID_EXT3_LAHF_LM,        .features[FEAT_XSAVE] =            CPUID_XSAVE_XSAVEOPT,        .features[FEAT_6_EAX] =            CPUID_6_EAX_ARAT,        .xlevel = 0x80000008,        .model_id = "Intel Xeon E312xx (Sandy Bridge)",    },</pre><p>你可以cat一个本地的/proc/cpuinfo，builtin_x86_defs定义的就是这些参数。<br>然后是for循环中针对每个CPU初始化，即pc_new_cpu，直接进入cpu_x86_create函数，<br>主要就是把CPUX86State填充了一下，涉及到CPUID和其他的feature。下面是x86_cpu_realize，即唤醒CPU，重点是qemu_init_vcpu，MCE忽略掉，走到qemu_kvm_start_vcpu，qemu创建VCPU，如下：</p><pre class="lang:c decode:1 hljs php">//创建VPU对于的qemu线程，线程函数是qemu_kvm_cpu_thread_fn    qemu_thread_create(cpu->thread, thread_name, qemu_kvm_cpu_thread_fn,                       cpu, QEMU_THREAD_JOINABLE);    //如果线程没有创建成功，则一直在此处循环阻塞。说明多核vcpu的创建是顺序的    while (!cpu->created) {        qemu_cond_wait(&qemu_cpu_cond, &qemu_global_mutex);    }</pre><p>线程创建完成，具体任务支线提，回到主流程上，qemu_init_vcpu执行完成后，下面就是cpu_reset，此处的作用是什么呢？答案是无用，本质是一个空函数，它的主要功能就是CPUClass的reset函数，reset在cpu_class_init里面注册的，注册的是cpu_common_reset，这是一个空函数，没有任何作用。cpu_class_init则是被cpu_type_info即TYPE_CPU使用，而cpu_type_info则由type_init(cpu_register_types)完成，type_init则是前面提到的和machine_init对应的注册关系。根据下句完成工作</p><pre class="lang:c decode:1 hljs cpp">\#define type_init(function) module_init(function, MODULE_INIT_QOM)</pre><p>从上面看，pc_cpus_init函数过程已经理顺了，下面看一下，vcpu所在的线程对应的qemu_kvm_cpu_thread_fn中：</p><pre class="lang:c decode:1 hljs objectivec">//初始化VCPU    r = kvm_init_vcpu(env);//初始化KVM中断    qemu_kvm_init_cpu_signals(env);//标志VCPU创建完成，和上面判断是对应的    cpu->created = true;    qemu_cond_signal(&qemu_cpu_cond);    while (1) {        if (cpu_can_run(env)) {          //CPU进入执行状态            r = kvm_cpu_exec(env);            if (r == EXCP_DEBUG) {                cpu_handle_guest_debug(env);            }        }        qemu_kvm_wait_io_event(env);    }</pre><p>CPU进入执行状态的时候我们看到其他的VCPU包括内存可能还没有初始化，关键是此处有一个开关，qemu_cpu_cond,打开这个开关才能进入到CPU执行状态，谁来打开这个开关，后面再说。先看kvm_init_vcpu，通过kvm_vm_ioctl，KVM_CREATE_VCPU创建VCPU，用KVM_GET_VCPU_MMAP_SIZE获取env-&gt;kvm_run对应的内存映射，kvm_arch_init_vcpu则填充对应的kvm_arch内容，具体内核部分，后面单独写。kvm_init_vcpu就是获取了vcpu，将相关内容填充了env。<br>qemu_kvm_init_cpu_signals则是将中断组合掩码传递给kvm_set_signal_mask，最终给内核KVM_SET_SIGNAL_MASK。kvm_cpu_exec此时还在阻塞过程中，先挂起来，看<a href="http://www.oenhan.com/size-512-slab-kmalloc" title="从size-512内存泄露看slab分配" target="_blank" rel="noopener">内存的初始化</a>。<br>内存初始化函数是pc_memory_init,memory_region_init_ram传入了高端内存和低端内存的值，memory_region_init负责填充mr，重点在qemu_ram_alloc，即qemu_ram_alloc_from_ptr，首先有RAMBlock，ram_list，那就直接借助find_ram_offset函数一起看一下qemu的内存分布模型。<br><img src="/2014/12/11/kvm-src-2-vm-run/qemu_memory_module-1.bmp" alt=""></p><p>qemu模拟了普通内存分布模型，内存的线性也是分块被使用的，每个块称为RAMBlock，由ram_list统领，RAMBlock.offset则是区块的线性地址，即相对于开始的偏移位，RAMBlock.length(size)则是区块的大小，find_ram_offset则是在线性区间内找到没有使用的一段空间，可以完全容纳新申请的ramblock length大小，代码就是进行了所有区块的遍历，找到满足新申请length的最小区间，把ramblock安插进去即可，返回的offset即是新分配区间的开始地址。<br>而RAMBlock的物理则是在RAMBlock.host,由kvm_vmalloc(size)分配真正物理内存，内部qemu_vmalloc使用qemu_memalign页<a href="http://www.oenhan.com/ubuntu-debuginfo-package" title="ubuntu下载debuginfo deb进行调试" target="_blank" rel="noopener">对齐分配</a>内存。后续的都是对RAMBlock的插入等处理。<br>从上面看，memory_region_init_ram已经将qemu内存模型和实际的物理内存初始化了。<br>vmstate_register_ram_global这个函数则是负责将前面提到的ramlist中的ramblock和memory region的初始地址对应一下，将mr-&gt;name填充到ramblock的idstr里面，就是让二者有确定的对应关系，如此mr就有了物理内存使用。<br>后面则是subregion的处理，memory_region_init_alias初始化，其中将ram传递给mr-&gt;owner确定了隶属关系，memory_region_add_subregion则是大头，memory_region_add_subregion_common前面的判断忽略，QTAILQ_INSERT_TAIL(&amp;mr-&gt;subregions, subregion, subregions_link)就是插入了链表而已，主要内容在memory_region_transaction_commit。<br>memory_region_transaction_commit中引入了新的结构address_spaces（AS），注释里面提到“AddressSpace: describes a mapping of addresses to #MemoryRegion objects”，就是内存地址的映射关系，因为内存有不同的应用类型，address_spaces以链表形式存在，commit函数则是对所有AS执行address_space_update_topology，先看AS在哪里注册的，就是前面提到的kvm_init里面，执行memory_listener_register，注册了address_space_memory和address_space_io两个，涉及的另外一个结构体则是MemoryListener，有kvm_memory_listener和kvm_io_listener，就是用于监控内存映射关系发生变化之后执行回调函数。<br>下面进入到address_space_update_topology函数，FlatView则是“Flattened global view of current active memory hierarchy”，address_space_get_flatview直接获取当前的，generate_memory_topology则根据前面已经变化的mr重新生成FlatView,然后通过address_space_update_topology_pass比较，简单说address_space_update_topology_pass就是两个FlatView逐条的FlatRange进行对比，以后一个FlatView为准，如果前面FlatView的FlatRange和后面的不一样，则对前面的FlatView的这条FlatRange进行处理，差别就是3种情况，如代码：</p><pre class="lang:c decode:1 hljs php">while (iold < old_view->nr || inew < new_view->nr) {        if (iold < old_view->nr) {            frold = &old_view->ranges[iold];        } else {            frold = NULL;        }        if (inew < new_view->nr) {            frnew = &new_view->ranges[inew];        } else {            frnew = NULL;        }        if (frold            && (!frnew                || int128_lt(frold->addr.start, frnew->addr.start)                || (int128_eq(frold->addr.start, frnew->addr.start)                    && !flatrange_equal(frold, frnew)))) {            /* In old but not in new, or in both but attributes changed. */            if (!adding) { //这个判断代码添加的无用，可以直接删除,                //address_space_update_topology里面的两个pass也可以删除一个                MEMORY_LISTENER_UPDATE_REGION(frold, as, Reverse, region_del);            }            ++iold;        } else if (frold && frnew && flatrange_equal(frold, frnew)) {            /* In both and unchanged (except logging may have changed) */            if (adding) {                MEMORY_LISTENER_UPDATE_REGION(frnew, as, Forward, region_nop);                if (frold->dirty_log_mask && !frnew->dirty_log_mask) {                    MEMORY_LISTENER_UPDATE_REGION(frnew, as, Reverse, log_stop);                } else if (frnew->dirty_log_mask && !frold->dirty_log_mask) {                    MEMORY_LISTENER_UPDATE_REGION(frnew, as, Forward, log_start);                }            }            ++iold;            ++inew;        } else {            /* In new */            if (adding) {                MEMORY_LISTENER_UPDATE_REGION(frnew, as, Forward, region_add);            }            ++inew;        }    }</pre><p>重点在MEMORY_LISTENER_UPDATE_REGION函数上，将变化的FlatRange构造一个MemoryRegionSection，然后遍历所有的memory_listeners，如果memory_listeners监控的内存区域和MemoryRegionSection一样，则执行第四个入参函数，如region_del函数，即kvm_region_del函数，这个是在kvm_init中初始化的。kvm_region_del主要是kvm_set_phys_mem函数，主要是将MemoryRegionSection有效值转换成KVMSlot形式，在kvm_set_user_memory_region中使用kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &amp;mem)传递给kernel。<br>我们看内存初始化真正需要做的是什么？就是qemu申请内存，把申请物理地址传递给kernel进行映射，那我们直接就可以KVMSlot申请内存，然后传递给kvm_vm_ioctl，这样也是OK的，之所以有这么多代码，因为qemu本身是一个软件虚拟机，mr涉及的地址已经是vm的地址，对于KVM是多余的，只是方便函数复用而已。<br>内存初始化之后还是pci等处理先跳过，如此pc_init就完成了，但是前面VM线程已经初始化成功，在qemu_kvm_cpu_thread_fn函数中等待运行：</p><pre class="lang:c decode:1 hljs bash">while (1) {        if (cpu_can_run(cpu)) {            r = kvm_cpu_exec(cpu);            if (r == EXCP_DEBUG) {                cpu_handle_guest_debug(cpu);            }        }        qemu_kvm_wait_io_event(cpu);    }</pre><p>判断条件就是cpu_can_run函数，即cpu-&gt;stop &amp;&amp; cpu-&gt;stopped &amp;&amp; current_run_state ！= running 都是false，而这几个参数都是由vm_start函数决定的</p><pre class="lang:c decode:1 hljs cpp">void vm_start(void){    if (!runstate_is_running()) {        cpu_enable_ticks();        runstate_set(RUN_STATE_RUNNING);        vm_state_notify(1, RUN_STATE_RUNNING);        resume_all_vcpus();        monitor_protocol_event(QEVENT_RESUME, NULL);    }}</pre><p>如此kvm_cpu_exec就真正进入执行阶段，即通过kvm_vcpu_ioctl传递KVM_RUN给内核。</p>]]></content>
      
      
      <categories>
          
          <category> KVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KVM源代码分析1:基本工作原理</title>
      <link href="/2014/12/11/kvm-src-1/"/>
      <url>/2014/12/11/kvm-src-1/</url>
      
        <content type="html"><![CDATA[<p>原文出自：<a href="http://oenhan.com/kvm-src-1" target="_blank" rel="noopener">http://oenhan.com/kvm-src-1</a><br>文章写作以及技术水平远远在我之上，感觉自己无力写出如此精炼的文章，膜拜并转发</p><h4 id="1-KVM模型结构"><a href="#1-KVM模型结构" class="headerlink" title="1.KVM模型结构"></a>1.KVM模型结构</h4><p>为什么有OS虚拟化？随着CPU计算能力的提高，单独的OS已不能充分利用CPU的计算能力，1.很多应用的执行需要单独占用一个OS环境，如安全测试等；2.而IAAS云计算厂商也是以OS为范围销售计算能力。那么在所有虚拟化方案中，都是由hypervisor取代原生的OS去控制具体硬件资源，而同时hypervisor将资源分配具体的VM，VM中运行的是没有修改过的OS，如果让VM中的OS能正常运行，hypervisor的任务就是模拟具体的硬件资源，让OS不能识别出是真是假。</p><p><img src="/2014/12/11/kvm-src-1/hypervisor-1.png" alt=""></p><p>当然上面的模型是Xen示例，OS对应用而言是硬件资源管理中心，那么hypervisor就是具体VM的OS了，KVM是就利用了这一点，利用现有的kernel代码，构建了一个hypervisor，这个样子<a href="http://www.oenhan.com/kernel-program-exec" target="_blank" rel="noopener">内存分配</a>，<a href="http://www.oenhan.com/task-group-sched" target="_blank" rel="noopener">进程调度</a>等就无需重写代码，如此hypervisor就是所谓的host，VM中的OS就是guest。</p><p>guest OS保证具体运行场景中的程序正常执行，而KVM的代码则部署在HOST上，Userspace对应的是QEMU，Kernel对应的是KVM Driver，KVM Driver负责模拟虚拟机的CPU运行，<a href="http://www.oenhan.com/size-512-slab-kmalloc" title="从size-512内存泄露看slab分配" target="_blank" rel="noopener">内存管理</a>，设备管理等；QEMU则模拟虚拟机的IO设备接口以及用户态控制接口。QEMU通过KVM等fd进行IOCTL控制KVM驱动的运行过程。</p><p><img src="/2014/12/11/kvm-src-1/kvm_arch_map-1.png" alt=""></p><p>如上图所示，guest自身有自己的用户模式和<a href="http://www.oenhan.com/iowait-wa-vmstat" title="iowait的形成原因和内核分析" target="_blank" rel="noopener">内核模式</a>；guest是在host中是作为一个用户态进程存在的，这个进程就是qemu，qemu本身就是一个虚拟化程序，只是纯软件虚拟化效率很低，它被KVM进行改造后，作为KVM的前端存在，用来进行<a href="http://www.oenhan.com/cpu-load-balance" title="Linux内核CPU负载均衡机制" target="_blank" rel="noopener">创建进程</a>或者IO交互等；而KVM Driver则是Linux内核模式，它提供KVM fd给qemu调用，用来进行cpu虚拟化，内存虚拟化等。QEMU通KVM提供的fd接口，通过ioctl系统调用创建和运行虚拟机。KVM Driver使得整个Linux成为一个虚拟机监控器，负责接收qemu模拟效率很低的命令。</p><h4 id="2-KVM工作原理"><a href="#2-KVM工作原理" class="headerlink" title="2.KVM工作原理"></a>2.KVM工作原理</h4><p><img src="/2014/12/11/kvm-src-1/kvm_process-1.png" alt=""></p><p>上图是一个执行过程图，首先启动一个虚拟化管理软件qemu，开始启动一个虚拟机，通过ioctl等系统调用向内核中申请指定的资源，搭建好虚拟环境，启动虚拟机内的OS，执行 VMLAUCH 指令，即进入了guest代码执行过程。如果 Guest OS 发生外部中断或者影子页表缺页之类的事件，暂停 Guest OS 的执行，退出QEMU即guest VM-exit，进行一些必要的处理，然后重新进入客户模式，执行guest代码；这个时候如果是io请求，则提交给用户态下的qemu处理，qemu处理后再次通过IOCTL反馈给KVM驱动。</p><h4 id="3-CPU虚拟化"><a href="#3-CPU虚拟化" class="headerlink" title="3.CPU虚拟化"></a>3.CPU虚拟化</h4><p>X86体系结构CPU虚拟化技术的称为 Intel VT-x 技术，引入了VMX，提供了两种处理器的工作环境。 VMCS 结构实现两种环境之间的切换。 VM Entry 使虚拟机进去guest模式，VM Exit 使虚拟机退出guest模式。</p><p>VMM调度guest执行时，qemu 通过 ioctl <a href="http://www.oenhan.com/kernel-program-exec" target="_blank" rel="noopener">系统调用</a>进入内核模式，在 KVM Driver中获得当前物理 CPU的引用。之后将guest状态从VMCS中读出， 并装入物理CPU中。执行 VMLAUCH 指令使得物理处理器进入非根操作环境，运行guest OS代码。</p><p>当 guest OS 执行一些特权指令或者外部事件时， 比如I/O访问，对控制寄存器的操作，MSR的读写等， 都会导致物理CPU发生 VMExit， 停止运行 Guest OS，将 Guest OS保存到VMCS中， Host 状态装入物理处理器中， 处理器进入根操作环境，KVM取得控制权，通过读取 VMCS 中 VM_EXIT_REASON 字段得到引起 VM Exit 的原因。 从而调用kvm_exit_handler 处理函数。 如果由于 I/O 获得信号到达，则退出到userspace模式的 Qemu 处理。处理完毕后，重新进入guest模式运行虚拟 CPU。</p><h4 id="4-Mem虚拟化"><a href="#4-Mem虚拟化" class="headerlink" title="4.Mem虚拟化"></a>4.Mem虚拟化</h4><p>OS对于物理内存主要有两点认识：1.物理地址从0开始；2.<a href="http://www.oenhan.com/kernel-program-exec" target="_blank" rel="noopener">内存地址</a>是连续的。VMM接管了所有内存，但guest OS的对内存的使用就存在这两点冲突了，除此之外，一个guest对内存的操作很有可能影响到另外一个guest乃至host的运行。VMM的内存虚拟化就要解决这些问题。</p><p>在OS代码中，应用也是占用所有的逻辑地址，同时不影响其他应用的关键点在于有线性地址这个中间层；解决方法则是添加了一个中间层：guest物理地址空间；guest看到是从0开始的guest物理地址空间（类比从0开始的线性地址），而且是连续的，虽然有些地址没有映射；同时guest物理地址映射到不同的host逻辑地址，如此保证了VM之间的安全性要求。</p><p>这样MEM虚拟化就是GVA-&gt;GPA-&gt;HPA的寻址过程，传统软件方法有影子页表，硬件虚拟化提供了EPT支持。</p><p>总体描述到此，后面代码里面见真相。</p>]]></content>
      
      
      <categories>
          
          <category> KVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2014/01/01/hello-world/"/>
      <url>/2014/01/01/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><h3 id="workflow"><a href="#workflow" class="headerlink" title="workflow"></a>workflow</h3><p>Refence: <a href="http://flowchart.js.org/" target="_blank" rel="noopener">http://flowchart.js.org/</a></p><p><div id="flowchart-0" class="flow-chart"></div></p><p><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.8/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.11.3/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: Start:>http://www.google.com[blank]e=>end:>http://www.google.comop1=>operation: My Operationsub1=>subroutine: My Subroutinecond=>condition: Yesor No?:>http://www.google.comio=>inputoutput: catch something...para=>parallel: parallel tasksst->op1->condcond(yes)->io->econd(no)->parapara(path1, bottom)->sub1(right)->op1para(path2, top)->op1&</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script></p>]]></content>
      
      
      
    </entry>
    
  
  
</search>
